{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, datetime as dt, requests\n",
    "import pandas as pd, matplotlib.pyplot as plt, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "#import regex as re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(\"C:\\\\Users\\\\jampa\\\\OneDrive\\\\Desktop\\\\UMass Study\\\\AF478\\\\all_data2.csv\")\n",
    "\n",
    "my_df['Date']=pd.to_datetime(my_df['Date'])\n",
    "my_df['year']=my_df['Date'].dt.year\n",
    "my_df['month']=my_df['Date'].dt.month\n",
    "my_df['day']=my_df['Date'].dt.day\n",
    "my_df.sort_values(by=['symbol','year','month','day'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.rename(columns = {'Adj Close':'adj_close'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>32.546494</td>\n",
       "      <td>35.765381</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>26.740847</td>\n",
       "      <td>62546380.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>30.713518</td>\n",
       "      <td>30.758226</td>\n",
       "      <td>28.478184</td>\n",
       "      <td>28.880545</td>\n",
       "      <td>24.537760</td>\n",
       "      <td>15234146.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>26.740847</td>\n",
       "      <td>-0.082387</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>28.657009</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>26.740847</td>\n",
       "      <td>6577870.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>24.537760</td>\n",
       "      <td>0.089784</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>30.400572</td>\n",
       "      <td>31.205294</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>24.309858</td>\n",
       "      <td>5975611.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>26.740847</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>29.998213</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>29.372318</td>\n",
       "      <td>24.955591</td>\n",
       "      <td>4843231.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>24.309858</td>\n",
       "      <td>0.026563</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216416</th>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>181.289993</td>\n",
       "      <td>182.039993</td>\n",
       "      <td>178.860001</td>\n",
       "      <td>179.649994</td>\n",
       "      <td>179.649994</td>\n",
       "      <td>1425900.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>182.119995</td>\n",
       "      <td>-0.013562</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216417</th>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>180.750000</td>\n",
       "      <td>183.179993</td>\n",
       "      <td>180.639999</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1552900.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>179.649994</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216418</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>182.460007</td>\n",
       "      <td>182.600006</td>\n",
       "      <td>180.509995</td>\n",
       "      <td>181.830002</td>\n",
       "      <td>181.830002</td>\n",
       "      <td>1088600.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216419</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>182.080002</td>\n",
       "      <td>184.850006</td>\n",
       "      <td>181.470001</td>\n",
       "      <td>184.600006</td>\n",
       "      <td>184.600006</td>\n",
       "      <td>1474600.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>181.830002</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216420</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>185.169998</td>\n",
       "      <td>190.143204</td>\n",
       "      <td>184.679993</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>1700303.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>184.600006</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4216421 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date        Open        High         Low       Close  \\\n",
       "0       1999-11-18   32.546494   35.765381   28.612303   31.473534   \n",
       "1       1999-11-19   30.713518   30.758226   28.478184   28.880545   \n",
       "2       1999-11-22   29.551144   31.473534   28.657009   31.473534   \n",
       "3       1999-11-23   30.400572   31.205294   28.612303   28.612303   \n",
       "4       1999-11-24   28.701717   29.998213   28.612303   29.372318   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "4216416 2023-12-05  181.289993  182.039993  178.860001  179.649994   \n",
       "4216417 2023-12-06  180.750000  183.179993  180.639999  182.000000   \n",
       "4216418 2023-12-07  182.460007  182.600006  180.509995  181.830002   \n",
       "4216419 2023-12-08  182.080002  184.850006  181.470001  184.600006   \n",
       "4216420 2023-12-11  185.169998  190.143204  184.679993  189.514999   \n",
       "\n",
       "          adj_close      Volume symbol  year  month  day  prev_price  \\\n",
       "0         26.740847  62546380.0      A  1999     11   18         NaN   \n",
       "1         24.537760  15234146.0      A  1999     11   19   26.740847   \n",
       "2         26.740847   6577870.0      A  1999     11   22   24.537760   \n",
       "3         24.309858   5975611.0      A  1999     11   23   26.740847   \n",
       "4         24.955591   4843231.0      A  1999     11   24   24.309858   \n",
       "...             ...         ...    ...   ...    ...  ...         ...   \n",
       "4216416  179.649994   1425900.0    ZTS  2023     12    5  182.119995   \n",
       "4216417  182.000000   1552900.0    ZTS  2023     12    6  179.649994   \n",
       "4216418  181.830002   1088600.0    ZTS  2023     12    7  182.000000   \n",
       "4216419  184.600006   1474600.0    ZTS  2023     12    8  181.830002   \n",
       "4216420  189.514999   1700303.0    ZTS  2023     12   11  184.600006   \n",
       "\n",
       "         daily_return  avrg_return_daily  std_return_daily  skew_return_daily  \\\n",
       "0                 NaN          -0.004237          0.063538          -0.225378   \n",
       "1           -0.082387          -0.004237          0.063538          -0.225378   \n",
       "2            0.089784          -0.004237          0.063538          -0.225378   \n",
       "3           -0.090909          -0.004237          0.063538          -0.225378   \n",
       "4            0.026563          -0.004237          0.063538          -0.225378   \n",
       "...               ...                ...               ...                ...   \n",
       "4216416     -0.013562           0.010151          0.013216          -0.984151   \n",
       "4216417      0.013081           0.010151          0.013216          -0.984151   \n",
       "4216418     -0.000934           0.010151          0.013216          -0.984151   \n",
       "4216419      0.015234           0.010151          0.013216          -0.984151   \n",
       "4216420      0.026625           0.010151          0.013216          -0.984151   \n",
       "\n",
       "           Sharpe  \n",
       "0       -0.066687  \n",
       "1       -0.066687  \n",
       "2       -0.066687  \n",
       "3       -0.066687  \n",
       "4       -0.066687  \n",
       "...           ...  \n",
       "4216416  0.768087  \n",
       "4216417  0.768087  \n",
       "4216418  0.768087  \n",
       "4216419  0.768087  \n",
       "4216420  0.768087  \n",
       "\n",
       "[4216421 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['prev_price']=my_df.groupby('symbol')['adj_close'].shift(1)\n",
    "my_df['daily_return']=(  my_df['adj_close']-my_df['prev_price'] )/ my_df['prev_price']\n",
    "\n",
    "my_df['avrg_return_daily'] = my_df.groupby(['symbol','year','month'])['daily_return'].transform('mean')\n",
    "my_df['std_return_daily'] = my_df.groupby(['symbol','year','month'])['daily_return'].transform('std')\n",
    "my_df['skew_return_daily'] = my_df.groupby(['symbol','year','month'])['daily_return'].transform('skew')\n",
    "my_df['Sharpe']=my_df['avrg_return_daily']/my_df['std_return_daily']\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=(my_df.groupby(['symbol','year','month']).last().reset_index()).drop(columns=['daily_return','Open','High','Low','Volume','day','prev_price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_price']=df.groupby('symbol')['adj_close'].shift(1)\n",
    "df['return']=(  df['adj_close']-df['prev_price'] )/df['prev_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['next_month_return']=df.groupby('symbol')['return'].shift(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>1999-11-30</td>\n",
       "      <td>30.177038</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>1.181711</td>\n",
       "      <td>0.479782</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>-0.143896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>47.344421</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>-0.006968</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>-0.173071</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>-0.143896</td>\n",
       "      <td>0.569405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>74.302574</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>1.181116</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>74.391991</td>\n",
       "      <td>63.205650</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.113234</td>\n",
       "      <td>3.366080</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.147837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201361</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>190.509995</td>\n",
       "      <td>190.054947</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>1.283727</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>187.640732</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>-0.086767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201362</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>173.979996</td>\n",
       "      <td>173.564438</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>-0.679612</td>\n",
       "      <td>-0.377698</td>\n",
       "      <td>190.054947</td>\n",
       "      <td>-0.086767</td>\n",
       "      <td>-0.095437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201363</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>0.012649</td>\n",
       "      <td>-0.546997</td>\n",
       "      <td>-0.353544</td>\n",
       "      <td>173.564438</td>\n",
       "      <td>-0.095437</td>\n",
       "      <td>0.125287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201364</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.931149</td>\n",
       "      <td>0.307381</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>0.125287</td>\n",
       "      <td>0.072706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201365</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>0.072706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201366 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol  year  month       Date       Close   adj_close  \\\n",
       "0           A  1999     11 1999-11-30   30.177038   25.639307   \n",
       "1           A  1999     12 1999-12-31   55.302216   46.986397   \n",
       "2           A  2000      1 2000-01-31   47.344421   40.225224   \n",
       "3           A  2000      2 2000-02-29   74.302574   63.129662   \n",
       "4           A  2000      3 2000-03-31   74.391991   63.205650   \n",
       "...       ...   ...    ...        ...         ...         ...   \n",
       "201361    ZTS  2023      8 2023-08-31  190.509995  190.054947   \n",
       "201362    ZTS  2023      9 2023-09-29  173.979996  173.564438   \n",
       "201363    ZTS  2023     10 2023-10-31  157.000000  157.000000   \n",
       "201364    ZTS  2023     11 2023-11-30  176.669998  176.669998   \n",
       "201365    ZTS  2023     12 2023-12-11  189.514999  189.514999   \n",
       "\n",
       "        avrg_return_daily  std_return_daily  skew_return_daily    Sharpe  \\\n",
       "0               -0.004237          0.063538          -0.225378 -0.066687   \n",
       "1                0.029614          0.061724           1.181711  0.479782   \n",
       "2               -0.006968          0.040263           0.382874 -0.173071   \n",
       "3                0.024397          0.059944           1.181116  0.407004   \n",
       "4                0.005110          0.113234           3.366080  0.045123   \n",
       "...                   ...               ...                ...       ...   \n",
       "201361           0.000684          0.016494           1.283727  0.041494   \n",
       "201362          -0.004461          0.011811          -0.679612 -0.377698   \n",
       "201363          -0.004472          0.012649          -0.546997 -0.353544   \n",
       "201364           0.005804          0.018882           0.931149  0.307381   \n",
       "201365           0.010151          0.013216          -0.984151  0.768087   \n",
       "\n",
       "        prev_price    return  next_month_return  \n",
       "0              NaN       NaN           0.832592  \n",
       "1        25.639307  0.832592          -0.143896  \n",
       "2        46.986397 -0.143896           0.569405  \n",
       "3        40.225224  0.569405           0.001204  \n",
       "4        63.129662  0.001204          -0.147837  \n",
       "...            ...       ...                ...  \n",
       "201361  187.640732  0.012866          -0.086767  \n",
       "201362  190.054947 -0.086767          -0.095437  \n",
       "201363  173.564438 -0.095437           0.125287  \n",
       "201364  157.000000  0.125287           0.072706  \n",
       "201365  176.669998  0.072706                NaN  \n",
       "\n",
       "[201366 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>1999-11-30</td>\n",
       "      <td>30.177038</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>1.181711</td>\n",
       "      <td>0.479782</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>-0.143896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>47.344421</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>-0.006968</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>-0.173071</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>-0.143896</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>74.302574</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>1.181116</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>74.391991</td>\n",
       "      <td>63.205650</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.113234</td>\n",
       "      <td>3.366080</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.147837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-28</td>\n",
       "      <td>63.394135</td>\n",
       "      <td>53.861515</td>\n",
       "      <td>-0.005711</td>\n",
       "      <td>0.075022</td>\n",
       "      <td>0.212424</td>\n",
       "      <td>-0.076128</td>\n",
       "      <td>63.205650</td>\n",
       "      <td>-0.147837</td>\n",
       "      <td>-0.169252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-05-31</td>\n",
       "      <td>52.664520</td>\n",
       "      <td>44.745338</td>\n",
       "      <td>-0.005072</td>\n",
       "      <td>0.085288</td>\n",
       "      <td>1.083793</td>\n",
       "      <td>-0.059472</td>\n",
       "      <td>53.861515</td>\n",
       "      <td>-0.169252</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.745185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>52.753933</td>\n",
       "      <td>44.821301</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.056377</td>\n",
       "      <td>0.381416</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>44.745338</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>-0.447458</td>\n",
       "      <td>-0.046079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>2000-07-31</td>\n",
       "      <td>29.148785</td>\n",
       "      <td>24.765671</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>0.072656</td>\n",
       "      <td>-2.054010</td>\n",
       "      <td>-0.362716</td>\n",
       "      <td>44.821301</td>\n",
       "      <td>-0.447458</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>-0.384325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>43.633762</td>\n",
       "      <td>37.072540</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.053768</td>\n",
       "      <td>2.345232</td>\n",
       "      <td>0.352655</td>\n",
       "      <td>24.765671</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>-0.197746</td>\n",
       "      <td>-0.412756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0      A  1999     11 1999-11-30  30.177038  25.639307          -0.004237   \n",
       "1      A  1999     12 1999-12-31  55.302216  46.986397           0.029614   \n",
       "2      A  2000      1 2000-01-31  47.344421  40.225224          -0.006968   \n",
       "3      A  2000      2 2000-02-29  74.302574  63.129662           0.024397   \n",
       "4      A  2000      3 2000-03-31  74.391991  63.205650           0.005110   \n",
       "5      A  2000      4 2000-04-28  63.394135  53.861515          -0.005711   \n",
       "6      A  2000      5 2000-05-31  52.664520  44.745338          -0.005072   \n",
       "7      A  2000      6 2000-06-30  52.753933  44.821301           0.001576   \n",
       "8      A  2000      7 2000-07-31  29.148785  24.765671          -0.026354   \n",
       "9      A  2000      8 2000-08-31  43.633762  37.072540           0.018962   \n",
       "\n",
       "   std_return_daily  skew_return_daily    Sharpe  prev_price    return  \\\n",
       "0          0.063538          -0.225378 -0.066687         NaN       NaN   \n",
       "1          0.061724           1.181711  0.479782   25.639307  0.832592   \n",
       "2          0.040263           0.382874 -0.173071   46.986397 -0.143896   \n",
       "3          0.059944           1.181116  0.407004   40.225224  0.569405   \n",
       "4          0.113234           3.366080  0.045123   63.129662  0.001204   \n",
       "5          0.075022           0.212424 -0.076128   63.205650 -0.147837   \n",
       "6          0.085288           1.083793 -0.059472   53.861515 -0.169252   \n",
       "7          0.056377           0.381416  0.027958   44.745338  0.001698   \n",
       "8          0.072656          -2.054010 -0.362716   44.821301 -0.447458   \n",
       "9          0.053768           2.345232  0.352655   24.765671  0.496933   \n",
       "\n",
       "   next_month_return  cum_ret6  \n",
       "0           0.832592       NaN  \n",
       "1          -0.143896       NaN  \n",
       "2           0.569405       NaN  \n",
       "3           0.001204       NaN  \n",
       "4          -0.147837       NaN  \n",
       "5          -0.169252       NaN  \n",
       "6           0.001698  0.745185  \n",
       "7          -0.447458 -0.046079  \n",
       "8           0.496933 -0.384325  \n",
       "9          -0.197746 -0.412756  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cum_ret6']= df.groupby('symbol')['return'].rolling(6).apply(lambda x: np.prod(1+x)-1).reset_index(drop=True) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>1999-11-30</td>\n",
       "      <td>30.177038</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>-0.225378</td>\n",
       "      <td>-0.066687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1999</td>\n",
       "      <td>12</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>1.181711</td>\n",
       "      <td>0.479782</td>\n",
       "      <td>25.639307</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>-0.143896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>47.344421</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>-0.006968</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.382874</td>\n",
       "      <td>-0.173071</td>\n",
       "      <td>46.986397</td>\n",
       "      <td>-0.143896</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>74.302574</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>1.181116</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>40.225224</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>74.391991</td>\n",
       "      <td>63.205650</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.113234</td>\n",
       "      <td>3.366080</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>63.129662</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.147837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201361</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>190.509995</td>\n",
       "      <td>190.054947</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>1.283727</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>187.640732</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>-0.086767</td>\n",
       "      <td>0.145743</td>\n",
       "      <td>0.227855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201362</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>173.979996</td>\n",
       "      <td>173.564438</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>-0.679612</td>\n",
       "      <td>-0.377698</td>\n",
       "      <td>190.054947</td>\n",
       "      <td>-0.086767</td>\n",
       "      <td>-0.095437</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>0.183626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201363</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>-0.004472</td>\n",
       "      <td>0.012649</td>\n",
       "      <td>-0.546997</td>\n",
       "      <td>-0.353544</td>\n",
       "      <td>173.564438</td>\n",
       "      <td>-0.095437</td>\n",
       "      <td>0.125287</td>\n",
       "      <td>-0.102731</td>\n",
       "      <td>0.050750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201364</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.931149</td>\n",
       "      <td>0.307381</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>0.125287</td>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.088783</td>\n",
       "      <td>0.156621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201365</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>189.514999</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.768087</td>\n",
       "      <td>176.669998</td>\n",
       "      <td>0.072706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105549</td>\n",
       "      <td>0.304973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201366 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol  year  month       Date       Close   adj_close  \\\n",
       "0           A  1999     11 1999-11-30   30.177038   25.639307   \n",
       "1           A  1999     12 1999-12-31   55.302216   46.986397   \n",
       "2           A  2000      1 2000-01-31   47.344421   40.225224   \n",
       "3           A  2000      2 2000-02-29   74.302574   63.129662   \n",
       "4           A  2000      3 2000-03-31   74.391991   63.205650   \n",
       "...       ...   ...    ...        ...         ...         ...   \n",
       "201361    ZTS  2023      8 2023-08-31  190.509995  190.054947   \n",
       "201362    ZTS  2023      9 2023-09-29  173.979996  173.564438   \n",
       "201363    ZTS  2023     10 2023-10-31  157.000000  157.000000   \n",
       "201364    ZTS  2023     11 2023-11-30  176.669998  176.669998   \n",
       "201365    ZTS  2023     12 2023-12-11  189.514999  189.514999   \n",
       "\n",
       "        avrg_return_daily  std_return_daily  skew_return_daily    Sharpe  \\\n",
       "0               -0.004237          0.063538          -0.225378 -0.066687   \n",
       "1                0.029614          0.061724           1.181711  0.479782   \n",
       "2               -0.006968          0.040263           0.382874 -0.173071   \n",
       "3                0.024397          0.059944           1.181116  0.407004   \n",
       "4                0.005110          0.113234           3.366080  0.045123   \n",
       "...                   ...               ...                ...       ...   \n",
       "201361           0.000684          0.016494           1.283727  0.041494   \n",
       "201362          -0.004461          0.011811          -0.679612 -0.377698   \n",
       "201363          -0.004472          0.012649          -0.546997 -0.353544   \n",
       "201364           0.005804          0.018882           0.931149  0.307381   \n",
       "201365           0.010151          0.013216          -0.984151  0.768087   \n",
       "\n",
       "        prev_price    return  next_month_return  cum_ret6  cum_ret12  \n",
       "0              NaN       NaN           0.832592       NaN        NaN  \n",
       "1        25.639307  0.832592          -0.143896       NaN        NaN  \n",
       "2        46.986397 -0.143896           0.569405       NaN        NaN  \n",
       "3        40.225224  0.569405           0.001204       NaN        NaN  \n",
       "4        63.129662  0.001204          -0.147837       NaN        NaN  \n",
       "...            ...       ...                ...       ...        ...  \n",
       "201361  187.640732  0.012866          -0.086767  0.145743   0.227855  \n",
       "201362  190.054947 -0.086767          -0.095437  0.049850   0.183626  \n",
       "201363  173.564438 -0.095437           0.125287 -0.102731   0.050750  \n",
       "201364  157.000000  0.125287           0.072706  0.088783   0.156621  \n",
       "201365  176.669998  0.072706                NaN  0.105549   0.304973  \n",
       "\n",
       "[201366 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cum_ret12']= df.groupby('symbol')['return'].rolling(12).apply(lambda x: np.prod(1+x)-1).reset_index(drop=True) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20.050072</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>22.503576</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>24.599428</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>25.937054</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.147352</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201349</th>\n",
       "      <td>156.529999</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.131837</td>\n",
       "      <td>-0.429848</td>\n",
       "      <td>-0.142536</td>\n",
       "      <td>-0.188785</td>\n",
       "      <td>-0.229898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201350</th>\n",
       "      <td>148.289993</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.549872</td>\n",
       "      <td>-0.143875</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>-0.210869</td>\n",
       "      <td>-0.231280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201351</th>\n",
       "      <td>150.779999</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>-0.199821</td>\n",
       "      <td>0.058510</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>-0.145965</td>\n",
       "      <td>-0.297473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201352</th>\n",
       "      <td>154.139999</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>-1.137458</td>\n",
       "      <td>0.046623</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.094653</td>\n",
       "      <td>-0.300707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201353</th>\n",
       "      <td>146.550003</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.433639</td>\n",
       "      <td>-0.147044</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>-0.144040</td>\n",
       "      <td>-0.395053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73646 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close  avrg_return_daily  std_return_daily  skew_return_daily  \\\n",
       "122      20.050072          -0.005306          0.014345          -1.057651   \n",
       "123      22.503576           0.006162          0.012060           0.795518   \n",
       "124      24.599428           0.003922          0.009486           0.943496   \n",
       "125      25.937054           0.002628          0.014793           0.484652   \n",
       "126      23.147352          -0.005176          0.032369           0.345697   \n",
       "...            ...                ...               ...                ...   \n",
       "201349  156.529999          -0.006552          0.015242           0.131837   \n",
       "201350  148.289993          -0.002436          0.016930           0.549872   \n",
       "201351  150.779999           0.001047          0.017897          -0.199821   \n",
       "201352  154.139999           0.001700          0.036468          -1.137458   \n",
       "201353  146.550003          -0.002287          0.015551           0.433639   \n",
       "\n",
       "          Sharpe    return  cum_ret6  cum_ret12  \n",
       "122    -0.369864 -0.097844  0.207149   0.550332  \n",
       "123     0.511000  0.122369  0.225078   1.268206  \n",
       "124     0.413428  0.093134  0.235717   1.237475  \n",
       "125     0.177654  0.054376  0.465642   0.985761  \n",
       "126    -0.159907 -0.107557  0.118949   0.775096  \n",
       "...          ...       ...       ...        ...  \n",
       "201349 -0.429848 -0.142536 -0.188785  -0.229898  \n",
       "201350 -0.143875 -0.052642 -0.210869  -0.231280  \n",
       "201351  0.058510  0.018952 -0.145965  -0.297473  \n",
       "201352  0.046623  0.022284 -0.094653  -0.300707  \n",
       "201353 -0.147044 -0.049241 -0.144040  -0.395053  \n",
       "\n",
       "[73646 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['Close','avrg_return_daily','std_return_daily','skew_return_daily','Sharpe','return','cum_ret6','cum_ret12']\n",
    "_df=(df[ (df['year']>=2010) & (df['year']<=2022)  ]).dropna()\n",
    "\n",
    "X=_df[features]\n",
    "\n",
    "y=(_df['next_month_return']).reset_index()\n",
    "y.drop(columns=['index'],inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8,test_size=0.25)\n",
    "_avrg=X_train.mean()\n",
    "_std=X_train.std()\n",
    "X_train=(X_train - _avrg)/ (_std)\n",
    "X_test=(X_test - _avrg)/ (_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter={'alpha':[a for a in range(100,10000,100)]}\n",
    "_model=Ridge()\n",
    "my_ridge=GridSearchCV(_model, param_grid=parameter, return_train_score=True, cv=5).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1800)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1800)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1800)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014495703852916209 0.019923008399222786\n"
     ]
    }
   ],
   "source": [
    "ridge_model=Ridge(alpha=1800,).fit(X_train,y_train)\n",
    "print(ridge_model.score(X_train,y_train),ridge_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006961683309181819\n",
      "0.007102504243078973\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,ridge_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,ridge_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'max_depth':[3,4,6],'min_samples_leaf':[6,20],'min_samples_split':[20,50],'max_leaf_nodes':[6,12]}\n",
    "_model=DecisionTreeRegressor()\n",
    "my_dfr=GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040396822231132834 0.022838735924750275\n"
     ]
    }
   ],
   "source": [
    "dfr_model=DecisionTreeRegressor(max_depth=6,min_samples_leaf=6,min_samples_split=20,max_leaf_nodes=20).fit(X_train,y_train)\n",
    "print(dfr_model.score(X_train,y_train),dfr_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006778715681128109\n",
      "0.007081374304003577\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,dfr_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,dfr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "parameter={'n_estimators':[50,60,100],'max_depth':[3,4,6],'min_samples_leaf':[6,20],'min_samples_split':[20,50],'max_leaf_nodes':[6,12]}\n",
    "_model=RandomForestRegressor()\n",
    "my_rfr=GridSearchCV(_model, param_grid=parameter, return_train_score=True, cv=5).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027233520978352077 0.024843975208350577\n"
     ]
    }
   ],
   "source": [
    "rfr_model=RandomForestRegressor(n_estimators=60,max_depth=3,min_samples_leaf=20,min_samples_split=20,max_leaf_nodes=6).fit(X_train,y_train)\n",
    "print(rfr_model.score(X_train,y_train),rfr_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0068717023225699425\n",
      "0.007066842567576525\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,rfr_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,rfr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'solver': ['lbfgs'],  # Wrap 'lbfgs' in a list\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 10), (10, 20)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_mlp\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "my_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05106111123417778 0.0473682732398939\n"
     ]
    }
   ],
   "source": [
    "mlp_model=MLPRegressor(solver='lbfgs',alpha=0,hidden_layer_sizes=(100),activation='relu',max_iter=1000).fit(X_train,y_train)\n",
    "print(mlp_model.score(X_train,y_train),mlp_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00670338226751739\n",
      "0.006903611593160817\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,mlp_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "14 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-2.68712470e-02 -4.54020960e-02             nan -1.64708374e+00\n",
      " -1.09641389e-02 -2.41943309e-02             nan -8.14967717e-01\n",
      " -6.66986440e-03 -1.89881317e-02             nan -7.20025082e+01\n",
      " -4.17657813e-02 -2.98198305e-02 -7.99185468e-03 -4.85093017e-01\n",
      " -2.49155808e-02 -1.03793839e-02             nan -7.53082824e-01\n",
      " -7.33787692e-03 -4.72109366e-03             nan -1.39128229e-01\n",
      " -3.83949670e-02 -1.89856668e-02             nan -1.60842849e-01\n",
      "  5.81012895e-03  1.69725809e-02 -4.62612078e-02 -6.95452454e-02\n",
      " -1.46091569e-03  4.50165901e-03 -6.87989850e-02 -2.69463660e-01\n",
      " -3.09099897e-02  1.38409118e-02 -1.91510288e-01 -5.24088248e-01\n",
      "  5.78347055e-03  1.83472336e-02 -3.68480419e-02 -3.08972926e-02\n",
      "  2.97972486e-03  1.78552749e-02  3.43325804e-03 -8.03938622e-02\n",
      " -4.17336088e-03 -1.77559988e-02             nan -3.16386480e-01\n",
      "  6.59876036e-03 -1.33468418e-02  1.58523698e-03 -1.12498437e-01\n",
      "  6.90170270e-03 -4.77452338e-03 -1.75544642e-03 -1.05547601e-01\n",
      " -1.29606276e-03 -6.26646247e-04  4.83689684e-03 -3.49657718e-01\n",
      "  1.43227660e-02  2.67807828e-03  1.37123352e-02 -2.76959431e-02\n",
      "  1.04993292e-02  8.63929513e-03  1.91741006e-02 -7.94930870e-02]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [-2.03818666e-02 -4.76691137e-02             nan -1.65339609e+00\n",
      " -6.21653398e-03 -2.16313728e-02             nan -8.30525361e-01\n",
      " -6.28602727e-03 -1.79116234e-02             nan -7.22508315e+01\n",
      " -4.20724368e-02 -3.34618478e-02 -6.94078679e-03 -4.80925026e-01\n",
      " -1.91988197e-02 -9.17702267e-03             nan -7.38077922e-01\n",
      " -9.85553645e-03 -5.68426734e-03             nan -1.42511225e-01\n",
      " -3.10459675e-02 -1.16348561e-02             nan -1.15734608e-01\n",
      "  5.61199753e-03  2.43876620e-02 -4.38061625e-02 -6.76520101e-02\n",
      " -1.81531412e-04  1.37206544e-02 -6.60421748e-02 -2.57320482e-01\n",
      " -2.84871636e-02  1.98291956e-02 -1.95313057e-01 -5.52080907e-01\n",
      "  6.62503269e-03  2.75677444e-02 -3.24413149e-02 -2.67193395e-02\n",
      "  2.44044227e-03  2.49107865e-02  3.03670535e-03 -7.89583044e-02\n",
      "  2.04996722e-02 -1.68819087e-02             nan -2.57394929e-01\n",
      "  1.39585084e-02 -1.33663230e-02  8.05759523e-03 -1.12541230e-01\n",
      "  1.56383441e-02 -5.31330546e-03  3.36318214e-03 -9.98834827e-02\n",
      "  1.80992460e-02  2.70604181e-03  2.34468845e-02 -2.65223732e-02\n",
      "  1.82218779e-02  2.44057058e-03  2.45256519e-02 -2.50825261e-02\n",
      "  1.29693974e-02  1.25950276e-02  2.65355746e-02 -8.10130006e-02]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 20), (10, 10)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000],\n",
    "    'learning_rate_init': [0.01, 0.1],  # Wrap values in a list\n",
    "    'batch_size': [20, 50]  # Wrap values in a list\n",
    "}\n",
    "_model=MLPRegressor()\n",
    "my_mlp1=GridSearchCV(_model,param_grid=parameters, return_train_score=True, cv=5).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mlp1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00830972656864748 0.009907563050878143\n"
     ]
    }
   ],
   "source": [
    "mlp1_model=MLPRegressor(solver='sgd',alpha=0,hidden_layer_sizes=(10,10),activation='relu',max_iter=1000,learning_rate_init=0.01,batch_size=200).fit(X_train,y_train)\n",
    "print(mlp1_model.score(X_train,y_train),mlp1_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007005381560908613\n",
      "0.007175085013459835\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,mlp1_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp1_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_X=X.copy()\n",
    "\n",
    "for j,col1 in enumerate(list(X.columns)):\n",
    "    for col2 in list(X.columns)[j+1:]:\n",
    "        New_X[col1+'*'+col2]=X[col1]*X[col2]\n",
    "\n",
    "for col in list(X.columns):\n",
    "    New_X[col+'^2']=X[col]*X[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(New_X,y,random_state=8,test_size=0.25)\n",
    "_avg=X_train.mean()\n",
    "_std=X_train.std()\n",
    "X_train = (X_train - _avg)/_std\n",
    "X_test = (X_test - _avg)/_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.02764471255537959\n",
      "Test R2 Score: 0.04124079333163466\n",
      "Train Mean Squared Error: 0.006868797631489589\n",
      "Test Mean Squared Error: 0.006948016729104993\n"
     ]
    }
   ],
   "source": [
    "parameter = {'alpha': [a for a in range(1000, 200000, 100)]}\n",
    "_model = Ridge()\n",
    "my_ridge = GridSearchCV(_model, param_grid=parameter, return_train_score=True, cv=5).fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best alpha value\n",
    "best_alpha = my_ridge.best_params_['alpha']\n",
    "\n",
    "# Create the Ridge model using the best alpha\n",
    "ridge_model = Ridge(alpha=best_alpha).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train R2 Score:\", ridge_model.score(X_train, y_train))\n",
    "print(\"Test R2 Score:\", ridge_model.score(X_test, y_test))\n",
    "\n",
    "print(\"Train Mean Squared Error:\", mean_squared_error(y_train, ridge_model.predict(X_train)))\n",
    "print(\"Test Mean Squared Error:\", mean_squared_error(y_test, ridge_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'max_depth':[3],'min_samples_leaf':[6],'min_samples_split':[20],'max_leaf_nodes':[6]}\n",
    "_model=DecisionTreeRegressor()\n",
    "my_dfr=GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024909655023910626 0.02854468400851129\n",
      "0.006888118302582471\n",
      "0.007040023960282612\n"
     ]
    }
   ],
   "source": [
    "dfr_model=DecisionTreeRegressor(max_depth=3,min_samples_leaf=6,min_samples_split=20,max_leaf_nodes=6).fit(X_train,y_train)\n",
    "print(dfr_model.score(X_train,y_train),dfr_model.score(X_test,y_test))\n",
    "\n",
    "print(mean_squared_error(y_train,dfr_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,dfr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter = {\n",
    "    'max_depth': [3, 4, 6],\n",
    "    'min_samples_leaf': [6, 20],\n",
    "    'min_samples_split': [20, 50],\n",
    "    'max_leaf_nodes': [6, 12]\n",
    "}\n",
    "\n",
    "_model = DecisionTreeRegressor()  # Use DecisionTreeRegressor instead of RandomForestRegressor\n",
    "my_tree = GridSearchCV(_model, param_grid=parameter, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04054794686066643 0.02815991088087577\n",
      "0.006777648124329886\n",
      "0.007042812366494649\n"
     ]
    }
   ],
   "source": [
    "rfr_model=RandomForestRegressor(n_estimators=5,max_depth=6,min_samples_leaf=6,min_samples_split=20,max_leaf_nodes=12).fit(X_train,y_train)\n",
    "print(rfr_model.score(X_train,y_train),rfr_model.score(X_test,y_test))\n",
    "\n",
    "print(mean_squared_error(y_train,rfr_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,rfr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = {\n",
    "    'solver': ['lbfgs'],  # Wrap the single value in a list\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 10), (10, 20)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021573693714643905 0.019220101625834762\n",
      "0.006911683807327194\n",
      "0.007107598126909796\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPRegressor(solver='lbfgs', alpha=0, hidden_layer_sizes=100, activation='logistic', max_iter=1000).fit(X_train, y_train)\n",
    "print(mlp_model.score(X_train,y_train),mlp_model.score(X_test,y_test))\n",
    "\n",
    "print(mean_squared_error(y_train,mlp_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:109: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:109: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:109: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "65 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan -3.79245848e+01             nan -6.70204212e+04\n",
      "             nan -8.51288845e-02             nan -2.43649523e+03\n",
      "             nan -5.51410198e-02             nan -3.71936137e+01\n",
      "             nan -4.62616457e+01             nan -5.70520338e+05\n",
      "             nan -2.82558931e-01             nan -1.05922952e+03\n",
      "             nan -1.32779539e-02             nan -2.98670554e+02\n",
      " -2.35003446e-02 -2.45795709e-02             nan -2.90033848e-01\n",
      "  3.39216566e-03 -2.53722118e-03  1.44623223e-02 -9.96188583e-02\n",
      "  4.91418628e-03  1.62544252e-02  1.65941163e-02 -5.14866210e-02\n",
      "  1.70807703e-02 -1.11878785e-02 -1.59896799e-01 -2.88509677e-01\n",
      "  7.17128570e-03  9.13131482e-03 -2.35467989e-02 -1.36359368e-02\n",
      "  7.51563965e-03  1.24703935e-02  1.71641232e-02 -7.79495660e-02\n",
      "             nan -5.49766545e-03             nan -4.94228921e+01\n",
      "  1.36830095e-02 -1.96276522e-02 -6.67314660e-03 -1.01078587e-01\n",
      "  1.30503028e-02 -3.19831705e-02 -8.74328759e-03 -8.22904017e-02\n",
      "  7.16498577e-03 -9.21735765e-03             nan -2.79276402e+01\n",
      "  3.28187514e-03 -6.79834754e-03  8.01232026e-03 -2.22036513e-02\n",
      "  4.77473937e-04 -1.06709544e-02 -2.85429457e-03 -4.10106216e-02]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [            nan -3.37442609e+01             nan -6.32381725e+04\n",
      "             nan -8.43939197e-02             nan -2.35336727e+03\n",
      "             nan -5.40952650e-02             nan -3.51372550e+01\n",
      "             nan -4.16786032e+01             nan -4.85727977e+05\n",
      "             nan -2.75331631e-01             nan -1.50401242e+03\n",
      "             nan -1.62908389e-02             nan -3.59435038e+02\n",
      " -4.92924523e-03 -1.44422875e-02             nan -3.92260073e-01\n",
      "  4.46422889e-03  1.21627101e-02  2.03979285e-02 -1.05593755e-01\n",
      "  5.35286271e-03  3.23983922e-02  2.26253137e-02 -5.62070133e-02\n",
      "  3.02733323e-02 -1.34330482e-03 -1.48886401e-01 -2.85487854e-01\n",
      "  8.28714841e-03  2.65485066e-02 -1.90185022e-02 -1.35730050e-02\n",
      "  9.43441452e-03  2.95009088e-02  1.94806273e-02 -8.11797553e-02\n",
      "             nan -2.81338619e-03             nan -7.94985645e-02\n",
      "  2.42703622e-02 -1.98167347e-02 -1.72654361e-03 -1.01334490e-01\n",
      "  1.74212987e-02 -2.70732565e-02 -5.67687819e-03 -8.16218503e-02\n",
      "  2.83082435e-02  9.30709525e-04             nan -3.03015485e+01\n",
      "  1.84850099e-02 -2.62703324e-03  1.73757773e-02 -2.28380444e-02\n",
      "  4.60534294e-03 -8.92855200e-03  1.47189909e-02 -4.38365886e-02]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 20), (10, 10)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000],\n",
    "    'learning_rate_init': [0.01, 0.1],\n",
    "    'batch_size': [20, 50]\n",
    "}\n",
    "_model=MLPRegressor()\n",
    "my_mlp1=GridSearchCV(_model,param_grid=parameters, return_train_score=True, cv=5).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.1, max_iter=1000,\n",
       "             solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.1, max_iter=1000,\n",
       "             solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.1, max_iter=1000,\n",
       "             solver='sgd')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1_model=MLPRegressor(solver='sgd',aplha=0,hidden_layer_sizes=(10,10),activation='logistic',max_iter=1000,learning_rate_init=0.1,batch_size=50).fit(X_train,y_train)\n",
    "print(mlp1.score(X_train,y_train),mlp1.score(X_test,y_test))\n",
    "print(mean_squared_error(y_train,mlp1_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp1_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, requests\n",
    "headers = {'User-Agent': \"ae161725@gmail.com\"}\n",
    "\n",
    "companyTickers = requests.get(\"https://www.sec.gov/files/company_tickers.json\" , headers=headers   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>cik_str10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>0000320193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>0000789019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1652044</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>0001652044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "      <td>0001018724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045810</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "      <td>0001045810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>19617</td>\n",
       "      <td>JPM-PM</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO</td>\n",
       "      <td>0000019617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>19617</td>\n",
       "      <td>AMJ</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO</td>\n",
       "      <td>0000019617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>1845123</td>\n",
       "      <td>IVCPU</td>\n",
       "      <td>Swiftmerge Acquisition Corp.</td>\n",
       "      <td>0001845123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10694</th>\n",
       "      <td>1845123</td>\n",
       "      <td>IVCPW</td>\n",
       "      <td>Swiftmerge Acquisition Corp.</td>\n",
       "      <td>0001845123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>1822993</td>\n",
       "      <td>JXN-PA</td>\n",
       "      <td>Jackson Financial Inc.</td>\n",
       "      <td>0001822993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cik_str  ticker                         title   cik_str10\n",
       "0       320193    AAPL                    Apple Inc.  0000320193\n",
       "1       789019    MSFT                MICROSOFT CORP  0000789019\n",
       "2      1652044   GOOGL                 Alphabet Inc.  0001652044\n",
       "3      1018724    AMZN                AMAZON COM INC  0001018724\n",
       "4      1045810    NVDA                   NVIDIA CORP  0001045810\n",
       "...        ...     ...                           ...         ...\n",
       "10691    19617  JPM-PM           JPMORGAN CHASE & CO  0000019617\n",
       "10692    19617     AMJ           JPMORGAN CHASE & CO  0000019617\n",
       "10693  1845123   IVCPU  Swiftmerge Acquisition Corp.  0001845123\n",
       "10694  1845123   IVCPW  Swiftmerge Acquisition Corp.  0001845123\n",
       "10695  1822993  JXN-PA        Jackson Financial Inc.  0001822993\n",
       "\n",
       "[10696 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyData = pd.DataFrame.from_dict(companyTickers.json(),  orient='index')\n",
    "companyData['cik_str10'] = companyData['cik_str'].astype(str).str.zfill(10)\n",
    "\n",
    "companyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols=_df['symbol'].to_list()\n",
    "len(set(symbols))\n",
    "symbols=set(symbols)\n",
    "symbols=list(symbols)\n",
    "symbols.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "all_asset_data = pd.DataFrame()\n",
    "\n",
    "for symb in symbols:\n",
    "    _cik = companyData[companyData['ticker'] == symb]['cik_str10']\n",
    "    \n",
    "    # Check if CIK is available\n",
    "    if not _cik.empty:\n",
    "        cik = _cik.iloc[0]\n",
    "        \n",
    "        # Fetch company facts\n",
    "        companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json', headers=headers)\n",
    "        \n",
    "        # Check if the request is successful and has the expected structure\n",
    "        if companyFacts.status_code == 200 and 'facts' in companyFacts.json().keys() and 'us-gaap' in companyFacts.json()['facts'].keys() and 'Assets' in companyFacts.json()['facts']['us-gaap'].keys():\n",
    "            \n",
    "            # Extract asset data and create DataFrame\n",
    "            asset_data = companyFacts.json()['facts']['us-gaap']['Assets']['units']['USD']\n",
    "            asset = pd.DataFrame.from_dict(asset_data)\n",
    "            asset['symbol'] = symb\n",
    "            \n",
    "            # Concatenate directly to the existing DataFrame\n",
    "            all_asset_data = pd.concat([all_asset_data, asset], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data processed successfully for symbol: {symb}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for symbol: {symb}\")\n",
    "    else:\n",
    "        print(f\"CIK not available for symbol: {symb}\")\n",
    "\n",
    "# Check if there is data\n",
    "if not all_asset_data.empty:\n",
    "    print(\"Data concatenated successfully.\")\n",
    "    # Further processing or analysis can be done with 'all_asset_data'\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: A\n",
      "Data processed successfully for symbol: AAL\n",
      "Data processed successfully for symbol: AAPL\n",
      "Data processed successfully for symbol: ABBV\n",
      "Data processed successfully for symbol: ABNB\n",
      "Data processed successfully for symbol: ABT\n",
      "Data processed successfully for symbol: ACGL\n",
      "Data processed successfully for symbol: ACN\n",
      "Data processed successfully for symbol: ADBE\n",
      "Data processed successfully for symbol: ADI\n",
      "Data processed successfully for symbol: ADM\n",
      "Data processed successfully for symbol: ADP\n",
      "Data processed successfully for symbol: ADSK\n",
      "Data processed successfully for symbol: AEE\n",
      "Data processed successfully for symbol: AEP\n",
      "Data processed successfully for symbol: AES\n",
      "Data processed successfully for symbol: AFL\n",
      "Data processed successfully for symbol: AIG\n",
      "Data processed successfully for symbol: AIZ\n",
      "Data processed successfully for symbol: AJG\n",
      "Data processed successfully for symbol: AKAM\n",
      "Data processed successfully for symbol: ALB\n",
      "Data processed successfully for symbol: ALGN\n",
      "Data processed successfully for symbol: ALK\n",
      "Data processed successfully for symbol: ALL\n",
      "Data processed successfully for symbol: ALLE\n",
      "Data processed successfully for symbol: AMAT\n",
      "Data processed successfully for symbol: AMCR\n",
      "Data processed successfully for symbol: AMD\n",
      "Data processed successfully for symbol: AME\n",
      "Data processed successfully for symbol: AMGN\n",
      "Data processed successfully for symbol: AMP\n",
      "Data processed successfully for symbol: AMT\n",
      "Data processed successfully for symbol: AMZN\n",
      "Data processed successfully for symbol: ANET\n",
      "Data processed successfully for symbol: ANSS\n",
      "Data processed successfully for symbol: AON\n",
      "Data processed successfully for symbol: AOS\n",
      "Data processed successfully for symbol: APA\n",
      "Data processed successfully for symbol: APD\n",
      "Data processed successfully for symbol: APH\n",
      "Data processed successfully for symbol: APTV\n",
      "Data processed successfully for symbol: ARE\n",
      "Data processed successfully for symbol: ATO\n",
      "Data processed successfully for symbol: AVB\n",
      "Data processed successfully for symbol: AVGO\n",
      "Data processed successfully for symbol: AVY\n",
      "Data processed successfully for symbol: AWK\n",
      "Data processed successfully for symbol: AXON\n",
      "Data processed successfully for symbol: AXP\n",
      "Data processed successfully for symbol: AZO\n",
      "Data processed successfully for symbol: BA\n",
      "Data processed successfully for symbol: BAC\n",
      "Data processed successfully for symbol: BALL\n",
      "Data processed successfully for symbol: BAX\n",
      "Data processed successfully for symbol: BBWI\n",
      "Data processed successfully for symbol: BBY\n",
      "Data processed successfully for symbol: BDX\n",
      "Data processed successfully for symbol: BEN\n",
      "Failed to fetch data for symbol: BG\n",
      "Data processed successfully for symbol: BIIB\n",
      "Data processed successfully for symbol: BIO\n",
      "Data processed successfully for symbol: BK\n",
      "Data processed successfully for symbol: BKNG\n",
      "Data processed successfully for symbol: BKR\n",
      "Data processed successfully for symbol: BLK\n",
      "Data processed successfully for symbol: BMY\n",
      "Data processed successfully for symbol: BR\n",
      "Data processed successfully for symbol: BRO\n",
      "Data processed successfully for symbol: BSX\n",
      "Data processed successfully for symbol: BWA\n",
      "Data processed successfully for symbol: BX\n",
      "Data processed successfully for symbol: BXP\n",
      "Data processed successfully for symbol: C\n",
      "Data processed successfully for symbol: CAG\n",
      "Data processed successfully for symbol: CAH\n",
      "Data processed successfully for symbol: CARR\n",
      "Data processed successfully for symbol: CAT\n",
      "Data processed successfully for symbol: CB\n",
      "Data processed successfully for symbol: CBOE\n",
      "Data processed successfully for symbol: CBRE\n",
      "Data processed successfully for symbol: CCI\n",
      "Data processed successfully for symbol: CCL\n",
      "Data processed successfully for symbol: CDAY\n",
      "Data processed successfully for symbol: CDNS\n",
      "Data processed successfully for symbol: CDW\n",
      "Data processed successfully for symbol: CE\n",
      "Data processed successfully for symbol: CF\n",
      "Data processed successfully for symbol: CFG\n",
      "Data processed successfully for symbol: CHD\n",
      "Data processed successfully for symbol: CHRW\n",
      "Data processed successfully for symbol: CHTR\n",
      "Data processed successfully for symbol: CI\n",
      "Data processed successfully for symbol: CINF\n",
      "Data processed successfully for symbol: CL\n",
      "Data processed successfully for symbol: CLX\n",
      "Data processed successfully for symbol: CMA\n",
      "Data processed successfully for symbol: CMCSA\n",
      "Data processed successfully for symbol: CME\n",
      "Data processed successfully for symbol: CMG\n",
      "Data processed successfully for symbol: CMI\n",
      "Data processed successfully for symbol: CMS\n",
      "Data processed successfully for symbol: CNC\n",
      "Data processed successfully for symbol: CNP\n",
      "Data processed successfully for symbol: COF\n",
      "Data processed successfully for symbol: COO\n",
      "Data processed successfully for symbol: COP\n",
      "Data processed successfully for symbol: COR\n",
      "Data processed successfully for symbol: COST\n",
      "Data processed successfully for symbol: CPB\n",
      "Data processed successfully for symbol: CPRT\n",
      "Data processed successfully for symbol: CPT\n",
      "Data processed successfully for symbol: CRL\n",
      "Data processed successfully for symbol: CRM\n",
      "Data processed successfully for symbol: CSCO\n",
      "Data processed successfully for symbol: CSGP\n",
      "Data processed successfully for symbol: CSX\n",
      "Data processed successfully for symbol: CTAS\n",
      "Data processed successfully for symbol: CTLT\n",
      "Data processed successfully for symbol: CTRA\n",
      "Data processed successfully for symbol: CTSH\n",
      "Data processed successfully for symbol: CTVA\n",
      "Data processed successfully for symbol: CVS\n",
      "Data processed successfully for symbol: CVX\n",
      "Data processed successfully for symbol: CZR\n",
      "Data processed successfully for symbol: D\n",
      "Data processed successfully for symbol: DAL\n",
      "Data processed successfully for symbol: DD\n",
      "Data processed successfully for symbol: DE\n",
      "Data processed successfully for symbol: DFS\n",
      "Data processed successfully for symbol: DG\n",
      "Data processed successfully for symbol: DGX\n",
      "Data processed successfully for symbol: DHI\n",
      "Data processed successfully for symbol: DHR\n",
      "Data processed successfully for symbol: DIS\n",
      "Data processed successfully for symbol: DLR\n",
      "Data processed successfully for symbol: DLTR\n",
      "Data processed successfully for symbol: DOV\n",
      "Data processed successfully for symbol: DOW\n",
      "Data processed successfully for symbol: DPZ\n",
      "Data processed successfully for symbol: DRI\n",
      "Data processed successfully for symbol: DTE\n",
      "Data processed successfully for symbol: DUK\n",
      "Data processed successfully for symbol: DVA\n",
      "Data processed successfully for symbol: DVN\n",
      "Data processed successfully for symbol: DXCM\n",
      "Data processed successfully for symbol: EA\n",
      "Data processed successfully for symbol: EBAY\n",
      "Data processed successfully for symbol: ECL\n",
      "Data processed successfully for symbol: ED\n",
      "Data processed successfully for symbol: EFX\n",
      "Data processed successfully for symbol: EG\n",
      "Data processed successfully for symbol: EIX\n",
      "Data processed successfully for symbol: EL\n",
      "Data processed successfully for symbol: ELV\n",
      "Data processed successfully for symbol: EMN\n",
      "Data processed successfully for symbol: EMR\n",
      "Data processed successfully for symbol: ENPH\n",
      "Data processed successfully for symbol: EOG\n",
      "Data processed successfully for symbol: EPAM\n",
      "Data processed successfully for symbol: EQIX\n",
      "Data processed successfully for symbol: EQR\n",
      "Data processed successfully for symbol: EQT\n",
      "Data processed successfully for symbol: ES\n",
      "Data processed successfully for symbol: ESS\n",
      "Data processed successfully for symbol: ETN\n",
      "Data processed successfully for symbol: ETR\n",
      "Data processed successfully for symbol: ETSY\n",
      "Data processed successfully for symbol: EVRG\n",
      "Data processed successfully for symbol: EW\n",
      "Data processed successfully for symbol: EXC\n",
      "Data processed successfully for symbol: EXPD\n",
      "Data processed successfully for symbol: EXPE\n",
      "Data processed successfully for symbol: EXR\n",
      "Data processed successfully for symbol: F\n",
      "Data processed successfully for symbol: FANG\n",
      "Data processed successfully for symbol: FAST\n",
      "Data processed successfully for symbol: FCX\n",
      "Data processed successfully for symbol: FDS\n",
      "Data processed successfully for symbol: FDX\n",
      "Data processed successfully for symbol: FE\n",
      "Data processed successfully for symbol: FFIV\n",
      "Data processed successfully for symbol: FI\n",
      "Data processed successfully for symbol: FICO\n",
      "Data processed successfully for symbol: FIS\n",
      "Data processed successfully for symbol: FITB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: FLT\n",
      "Data processed successfully for symbol: FMC\n",
      "Data processed successfully for symbol: FOX\n",
      "Data processed successfully for symbol: FOXA\n",
      "Data processed successfully for symbol: FRT\n",
      "Data processed successfully for symbol: FSLR\n",
      "Data processed successfully for symbol: FTNT\n",
      "Data processed successfully for symbol: FTV\n",
      "Data processed successfully for symbol: GD\n",
      "Data processed successfully for symbol: GE\n",
      "Data processed successfully for symbol: GEN\n",
      "Data processed successfully for symbol: GILD\n",
      "Data processed successfully for symbol: GIS\n",
      "Data processed successfully for symbol: GL\n",
      "Data processed successfully for symbol: GLW\n",
      "Data processed successfully for symbol: GM\n",
      "Data processed successfully for symbol: GNRC\n",
      "Data processed successfully for symbol: GOOG\n",
      "Data processed successfully for symbol: GOOGL\n",
      "Data processed successfully for symbol: GPC\n",
      "Data processed successfully for symbol: GPN\n",
      "Data processed successfully for symbol: GRMN\n",
      "Data processed successfully for symbol: GS\n",
      "Data processed successfully for symbol: GWW\n",
      "Data processed successfully for symbol: HAL\n",
      "Data processed successfully for symbol: HAS\n",
      "Data processed successfully for symbol: HBAN\n",
      "Data processed successfully for symbol: HCA\n",
      "Data processed successfully for symbol: HD\n",
      "Data processed successfully for symbol: HES\n",
      "Data processed successfully for symbol: HIG\n",
      "Data processed successfully for symbol: HII\n",
      "Data processed successfully for symbol: HLT\n",
      "Data processed successfully for symbol: HOLX\n",
      "Data processed successfully for symbol: HON\n",
      "Data processed successfully for symbol: HPE\n",
      "Data processed successfully for symbol: HPQ\n",
      "Data processed successfully for symbol: HRL\n",
      "Data processed successfully for symbol: HSIC\n",
      "Data processed successfully for symbol: HST\n",
      "Data processed successfully for symbol: HSY\n",
      "Data processed successfully for symbol: HUBB\n",
      "Data processed successfully for symbol: HUM\n",
      "Data processed successfully for symbol: HWM\n",
      "Data processed successfully for symbol: IBM\n",
      "Data processed successfully for symbol: ICE\n",
      "Data processed successfully for symbol: IDXX\n",
      "Data processed successfully for symbol: IEX\n",
      "Data processed successfully for symbol: IFF\n",
      "Data processed successfully for symbol: ILMN\n",
      "Data processed successfully for symbol: INCY\n",
      "Data processed successfully for symbol: INTC\n",
      "Data processed successfully for symbol: INTU\n",
      "Data processed successfully for symbol: INVH\n",
      "Data processed successfully for symbol: IP\n",
      "Data processed successfully for symbol: IPG\n",
      "Data processed successfully for symbol: IQV\n",
      "Data processed successfully for symbol: IR\n",
      "Data processed successfully for symbol: IRM\n",
      "Data processed successfully for symbol: ISRG\n",
      "Data processed successfully for symbol: IT\n",
      "Data processed successfully for symbol: ITW\n",
      "Data processed successfully for symbol: IVZ\n",
      "Data processed successfully for symbol: J\n",
      "Data processed successfully for symbol: JBHT\n",
      "Data processed successfully for symbol: JCI\n",
      "Data processed successfully for symbol: JKHY\n",
      "Data processed successfully for symbol: JNJ\n",
      "Data processed successfully for symbol: JNPR\n",
      "Data processed successfully for symbol: JPM\n",
      "Data processed successfully for symbol: K\n",
      "Data processed successfully for symbol: KDP\n",
      "Data processed successfully for symbol: KEY\n",
      "Data processed successfully for symbol: KEYS\n",
      "Data processed successfully for symbol: KHC\n",
      "Data processed successfully for symbol: KIM\n",
      "Data processed successfully for symbol: KLAC\n",
      "Data processed successfully for symbol: KMB\n",
      "Data processed successfully for symbol: KMI\n",
      "Data processed successfully for symbol: KMX\n",
      "Data processed successfully for symbol: KO\n",
      "Data processed successfully for symbol: KR\n",
      "Data processed successfully for symbol: L\n",
      "Data processed successfully for symbol: LDOS\n",
      "Data processed successfully for symbol: LEN\n",
      "Data processed successfully for symbol: LH\n",
      "Data processed successfully for symbol: LHX\n",
      "Data processed successfully for symbol: LIN\n",
      "Data processed successfully for symbol: LKQ\n",
      "Data processed successfully for symbol: LLY\n",
      "Data processed successfully for symbol: LMT\n",
      "Data processed successfully for symbol: LNT\n",
      "Data processed successfully for symbol: LOW\n",
      "Data processed successfully for symbol: LRCX\n",
      "Data processed successfully for symbol: LULU\n",
      "Data processed successfully for symbol: LUV\n",
      "Data processed successfully for symbol: LVS\n",
      "Data processed successfully for symbol: LW\n",
      "Data processed successfully for symbol: LYB\n",
      "Data processed successfully for symbol: LYV\n",
      "Data processed successfully for symbol: MA\n",
      "Data processed successfully for symbol: MAA\n",
      "Data processed successfully for symbol: MAR\n",
      "Data processed successfully for symbol: MAS\n",
      "Data processed successfully for symbol: MCD\n",
      "Data processed successfully for symbol: MCHP\n",
      "Data processed successfully for symbol: MCK\n",
      "Data processed successfully for symbol: MCO\n",
      "Data processed successfully for symbol: MDLZ\n",
      "Data processed successfully for symbol: MDT\n",
      "Data processed successfully for symbol: MET\n",
      "Data processed successfully for symbol: META\n",
      "Data processed successfully for symbol: MGM\n",
      "Data processed successfully for symbol: MHK\n",
      "Data processed successfully for symbol: MKC\n",
      "Data processed successfully for symbol: MKTX\n",
      "Data processed successfully for symbol: MLM\n",
      "Data processed successfully for symbol: MMC\n",
      "Data processed successfully for symbol: MMM\n",
      "Data processed successfully for symbol: MNST\n",
      "Data processed successfully for symbol: MO\n",
      "Data processed successfully for symbol: MOH\n",
      "Data processed successfully for symbol: MOS\n",
      "Data processed successfully for symbol: MPC\n",
      "Data processed successfully for symbol: MPWR\n",
      "Data processed successfully for symbol: MRK\n",
      "Data processed successfully for symbol: MRNA\n",
      "Data processed successfully for symbol: MRO\n",
      "Data processed successfully for symbol: MS\n",
      "Data processed successfully for symbol: MSCI\n",
      "Data processed successfully for symbol: MSFT\n",
      "Data processed successfully for symbol: MSI\n",
      "Data processed successfully for symbol: MTB\n",
      "Data processed successfully for symbol: MTCH\n",
      "Data processed successfully for symbol: MTD\n",
      "Data processed successfully for symbol: MU\n",
      "Data processed successfully for symbol: NCLH\n",
      "Data processed successfully for symbol: NDAQ\n",
      "Data processed successfully for symbol: NDSN\n",
      "Data processed successfully for symbol: NEE\n",
      "Data processed successfully for symbol: NEM\n",
      "Data processed successfully for symbol: NFLX\n",
      "Data processed successfully for symbol: NI\n",
      "Data processed successfully for symbol: NKE\n",
      "Data processed successfully for symbol: NOC\n",
      "Data processed successfully for symbol: NOW\n",
      "Data processed successfully for symbol: NRG\n",
      "Data processed successfully for symbol: NSC\n",
      "Data processed successfully for symbol: NTAP\n",
      "Data processed successfully for symbol: NTRS\n",
      "Data processed successfully for symbol: NUE\n",
      "Data processed successfully for symbol: NVDA\n",
      "Data processed successfully for symbol: NVR\n",
      "Data processed successfully for symbol: NWS\n",
      "Data processed successfully for symbol: NWSA\n",
      "Data processed successfully for symbol: NXPI\n",
      "Data processed successfully for symbol: O\n",
      "Data processed successfully for symbol: ODFL\n",
      "Data processed successfully for symbol: OKE\n",
      "Data processed successfully for symbol: OMC\n",
      "Data processed successfully for symbol: ON\n",
      "Data processed successfully for symbol: ORCL\n",
      "Data processed successfully for symbol: ORLY\n",
      "Data processed successfully for symbol: OTIS\n",
      "Data processed successfully for symbol: OXY\n",
      "Data processed successfully for symbol: PANW\n",
      "Data processed successfully for symbol: PARA\n",
      "Data processed successfully for symbol: PAYC\n",
      "Data processed successfully for symbol: PAYX\n",
      "Data processed successfully for symbol: PCAR\n",
      "Data processed successfully for symbol: PCG\n",
      "Data processed successfully for symbol: PEAK\n",
      "Data processed successfully for symbol: PEG\n",
      "Data processed successfully for symbol: PEP\n",
      "Data processed successfully for symbol: PFE\n",
      "Data processed successfully for symbol: PFG\n",
      "Data processed successfully for symbol: PG\n",
      "Data processed successfully for symbol: PGR\n",
      "Data processed successfully for symbol: PH\n",
      "Data processed successfully for symbol: PHM\n",
      "Data processed successfully for symbol: PKG\n",
      "Data processed successfully for symbol: PLD\n",
      "Data processed successfully for symbol: PM\n",
      "Data processed successfully for symbol: PNC\n",
      "Data processed successfully for symbol: PNR\n",
      "Data processed successfully for symbol: PNW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: PODD\n",
      "Data processed successfully for symbol: POOL\n",
      "Data processed successfully for symbol: PPG\n",
      "Data processed successfully for symbol: PPL\n",
      "Data processed successfully for symbol: PRU\n",
      "Data processed successfully for symbol: PSA\n",
      "Data processed successfully for symbol: PSX\n",
      "Data processed successfully for symbol: PTC\n",
      "Data processed successfully for symbol: PWR\n",
      "Data processed successfully for symbol: PXD\n",
      "Data processed successfully for symbol: PYPL\n",
      "Data processed successfully for symbol: QCOM\n",
      "Data processed successfully for symbol: QRVO\n",
      "Data processed successfully for symbol: RCL\n",
      "Data processed successfully for symbol: REG\n",
      "Data processed successfully for symbol: REGN\n",
      "Data processed successfully for symbol: RF\n",
      "Data processed successfully for symbol: RHI\n",
      "Data processed successfully for symbol: RJF\n",
      "Data processed successfully for symbol: RL\n",
      "Data processed successfully for symbol: RMD\n",
      "Data processed successfully for symbol: ROK\n",
      "Data processed successfully for symbol: ROL\n",
      "Data processed successfully for symbol: ROP\n",
      "Data processed successfully for symbol: ROST\n",
      "Data processed successfully for symbol: RSG\n",
      "Data processed successfully for symbol: RTX\n",
      "Data processed successfully for symbol: RVTY\n",
      "Data processed successfully for symbol: SBAC\n",
      "Data processed successfully for symbol: SBUX\n",
      "Data processed successfully for symbol: SCHW\n",
      "Data processed successfully for symbol: SEDG\n",
      "Data processed successfully for symbol: SEE\n",
      "Data processed successfully for symbol: SHW\n",
      "Data processed successfully for symbol: SJM\n",
      "Data processed successfully for symbol: SLB\n",
      "Data processed successfully for symbol: SNA\n",
      "Data processed successfully for symbol: SNPS\n",
      "Data processed successfully for symbol: SO\n",
      "Data processed successfully for symbol: SPG\n",
      "Data processed successfully for symbol: SPGI\n",
      "Data processed successfully for symbol: SRE\n",
      "Data processed successfully for symbol: STE\n",
      "Data processed successfully for symbol: STLD\n",
      "Data processed successfully for symbol: STT\n",
      "Data processed successfully for symbol: STX\n",
      "Data processed successfully for symbol: STZ\n",
      "Data processed successfully for symbol: SWK\n",
      "Data processed successfully for symbol: SWKS\n",
      "Data processed successfully for symbol: SYF\n",
      "Data processed successfully for symbol: SYK\n",
      "Data processed successfully for symbol: SYY\n",
      "Data processed successfully for symbol: T\n",
      "Data processed successfully for symbol: TAP\n",
      "Data processed successfully for symbol: TDG\n",
      "Data processed successfully for symbol: TDY\n",
      "Data processed successfully for symbol: TECH\n",
      "Data processed successfully for symbol: TEL\n",
      "Data processed successfully for symbol: TER\n",
      "Data processed successfully for symbol: TFC\n",
      "Data processed successfully for symbol: TFX\n",
      "Data processed successfully for symbol: TGT\n",
      "Data processed successfully for symbol: TJX\n",
      "Data processed successfully for symbol: TMO\n",
      "Data processed successfully for symbol: TMUS\n",
      "Data processed successfully for symbol: TPR\n",
      "Data processed successfully for symbol: TRGP\n",
      "Data processed successfully for symbol: TRMB\n",
      "Data processed successfully for symbol: TROW\n",
      "Data processed successfully for symbol: TRV\n",
      "Data processed successfully for symbol: TSCO\n",
      "Data processed successfully for symbol: TSLA\n",
      "Data processed successfully for symbol: TSN\n",
      "Data processed successfully for symbol: TT\n",
      "Data processed successfully for symbol: TTWO\n",
      "Data processed successfully for symbol: TXN\n",
      "Data processed successfully for symbol: TXT\n",
      "Data processed successfully for symbol: TYL\n",
      "Data processed successfully for symbol: UAL\n",
      "Data processed successfully for symbol: UDR\n",
      "Data processed successfully for symbol: UHS\n",
      "Data processed successfully for symbol: ULTA\n",
      "Data processed successfully for symbol: UNH\n",
      "Data processed successfully for symbol: UNP\n",
      "Data processed successfully for symbol: UPS\n",
      "Data processed successfully for symbol: URI\n",
      "Data processed successfully for symbol: USB\n",
      "Data processed successfully for symbol: V\n",
      "Data processed successfully for symbol: VFC\n",
      "Data processed successfully for symbol: VICI\n",
      "Data processed successfully for symbol: VLO\n",
      "Data processed successfully for symbol: VMC\n",
      "Data processed successfully for symbol: VRSK\n",
      "Data processed successfully for symbol: VRSN\n",
      "Data processed successfully for symbol: VRTX\n",
      "Data processed successfully for symbol: VTR\n",
      "Data processed successfully for symbol: VTRS\n",
      "Data processed successfully for symbol: VZ\n",
      "Data processed successfully for symbol: WAB\n",
      "Data processed successfully for symbol: WAT\n",
      "Data processed successfully for symbol: WBA\n",
      "Data processed successfully for symbol: WBD\n",
      "Data processed successfully for symbol: WDC\n",
      "Data processed successfully for symbol: WEC\n",
      "Data processed successfully for symbol: WELL\n",
      "Data processed successfully for symbol: WFC\n",
      "Data processed successfully for symbol: WHR\n",
      "Data processed successfully for symbol: WM\n",
      "Data processed successfully for symbol: WMB\n",
      "Data processed successfully for symbol: WMT\n",
      "Data processed successfully for symbol: WRB\n",
      "Data processed successfully for symbol: WRK\n",
      "Data processed successfully for symbol: WST\n",
      "Data processed successfully for symbol: WTW\n",
      "Data processed successfully for symbol: WY\n",
      "Data processed successfully for symbol: WYNN\n",
      "Data processed successfully for symbol: XEL\n",
      "Data processed successfully for symbol: XOM\n",
      "Data processed successfully for symbol: XRAY\n",
      "Data processed successfully for symbol: XYL\n",
      "Data processed successfully for symbol: YUM\n",
      "Data processed successfully for symbol: ZBH\n",
      "Data processed successfully for symbol: ZBRA\n",
      "Data processed successfully for symbol: ZION\n",
      "Data processed successfully for symbol: ZTS\n",
      "Data concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "    print(all_asset_data)\n",
    "    all_asset_data = all_asset_data[all_asset_data['form'].isin(['10-K', '10-Q'])]\n",
    "    all_asset_data['filed1'] = pd.to_datetime(all_asset_data['filed'])\n",
    "    all_asset_data['year'] = all_asset_data['filed1'].dt.year\n",
    "    all_asset_data['month'] = all_asset_data['filed1'].dt.month\n",
    "    all_asset_data['day'] = all_asset_data['filed1'].dt.day\n",
    "    \n",
    "    all_asset_data2 = all_asset_data.sort_values(by='filed1')\n",
    "    all_asset_data2 = all_asset_data2.groupby(['symbol','year', 'month']).first().reset_index()\n",
    "    \n",
    "    features = ['year', 'month', 'val', 'symbol']\n",
    "    all_asset_data3 = all_asset_data2[features].copy()\n",
    "    all_asset_data3.rename(columns={'val': 'asset'}, inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"Data processed successfully.\")\n",
    "    print(all_asset_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201349</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>156.529999</td>\n",
       "      <td>154.786163</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.131837</td>\n",
       "      <td>-0.429848</td>\n",
       "      <td>180.516296</td>\n",
       "      <td>-0.142536</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>-0.188785</td>\n",
       "      <td>-0.229898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201350</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>148.289993</td>\n",
       "      <td>146.637955</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.549872</td>\n",
       "      <td>-0.143875</td>\n",
       "      <td>154.786163</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>-0.210869</td>\n",
       "      <td>-0.231280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201351</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>150.779999</td>\n",
       "      <td>149.417023</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>-0.199821</td>\n",
       "      <td>0.058510</td>\n",
       "      <td>146.637955</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.145965</td>\n",
       "      <td>-0.297473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201352</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>154.139999</td>\n",
       "      <td>152.746674</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>-1.137458</td>\n",
       "      <td>0.046623</td>\n",
       "      <td>149.417023</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>-0.094653</td>\n",
       "      <td>-0.300707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201353</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>146.550003</td>\n",
       "      <td>145.225266</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.433639</td>\n",
       "      <td>-0.147044</td>\n",
       "      <td>152.746674</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>0.131893</td>\n",
       "      <td>-0.144040</td>\n",
       "      <td>-0.395053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73646 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol  year  month       Date       Close   adj_close  \\\n",
       "122         A  2010      1 2010-01-29   20.050072   18.079800   \n",
       "123         A  2010      2 2010-02-26   22.503576   20.292213   \n",
       "124         A  2010      3 2010-03-31   24.599428   22.182100   \n",
       "125         A  2010      4 2010-04-30   25.937054   23.388283   \n",
       "126         A  2010      5 2010-05-28   23.147352   20.872721   \n",
       "...       ...   ...    ...        ...         ...         ...   \n",
       "201349    ZTS  2022      8 2022-08-31  156.529999  154.786163   \n",
       "201350    ZTS  2022      9 2022-09-30  148.289993  146.637955   \n",
       "201351    ZTS  2022     10 2022-10-31  150.779999  149.417023   \n",
       "201352    ZTS  2022     11 2022-11-30  154.139999  152.746674   \n",
       "201353    ZTS  2022     12 2022-12-30  146.550003  145.225266   \n",
       "\n",
       "        avrg_return_daily  std_return_daily  skew_return_daily    Sharpe  \\\n",
       "122             -0.005306          0.014345          -1.057651 -0.369864   \n",
       "123              0.006162          0.012060           0.795518  0.511000   \n",
       "124              0.003922          0.009486           0.943496  0.413428   \n",
       "125              0.002628          0.014793           0.484652  0.177654   \n",
       "126             -0.005176          0.032369           0.345697 -0.159907   \n",
       "...                   ...               ...                ...       ...   \n",
       "201349          -0.006552          0.015242           0.131837 -0.429848   \n",
       "201350          -0.002436          0.016930           0.549872 -0.143875   \n",
       "201351           0.001047          0.017897          -0.199821  0.058510   \n",
       "201352           0.001700          0.036468          -1.137458  0.046623   \n",
       "201353          -0.002287          0.015551           0.433639 -0.147044   \n",
       "\n",
       "        prev_price    return  next_month_return  cum_ret6  cum_ret12  \n",
       "122      20.040653 -0.097844           0.122369  0.207149   0.550332  \n",
       "123      18.079800  0.122369           0.093134  0.225078   1.268206  \n",
       "124      20.292213  0.093134           0.054376  0.235717   1.237475  \n",
       "125      22.182100  0.054376          -0.107557  0.465642   0.985761  \n",
       "126      23.388283 -0.107557          -0.121446  0.118949   0.775096  \n",
       "...            ...       ...                ...       ...        ...  \n",
       "201349  180.516296 -0.142536          -0.052642 -0.188785  -0.229898  \n",
       "201350  154.786163 -0.052642           0.018952 -0.210869  -0.231280  \n",
       "201351  146.637955  0.018952           0.022284 -0.145965  -0.297473  \n",
       "201352  149.417023  0.022284          -0.049241 -0.094653  -0.300707  \n",
       "201353  152.746674 -0.049241           0.131893 -0.144040  -0.395053  \n",
       "\n",
       "[73646 rows x 15 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\369482554.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_asset_data4.sort_values(by=['symbol', 'year', 'month'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>20.336195</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>-0.678421</td>\n",
       "      <td>-0.237074</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>19.978540</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>-0.003568</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>19.291845</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>1.112051</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>-0.142721</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>23.869814</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.547784</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>-0.029660</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>24.892704</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.983643</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>9.100000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>25.050072</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>9.100000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>29.635193</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.632311</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.333440</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-1.215774</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>30.100143</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.026238</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>7.612000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>1.589836</td>\n",
       "      <td>0.115230</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>35.701000</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.339112</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>35.672390</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.424044</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>36.559372</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>8.649000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>30.157368</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.284088</td>\n",
       "      <td>-0.456845</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>8.649000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>26.373390</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.335696</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>8.649000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>22.353361</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.192555</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>-0.302144</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>26.516453</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.130691</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2011-11-30</td>\n",
       "      <td>26.824034</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.365538</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.070817</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>24.985695</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>-0.590230</td>\n",
       "      <td>-0.126739</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>-0.316572</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>30.379112</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.251102</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>31.201717</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>1.193771</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>9.696000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>31.838341</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.210213</td>\n",
       "      <td>0.068673</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>30.171675</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>-0.119917</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>-0.152973</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>29.084406</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>-0.079841</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>-0.182842</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>28.068670</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.052053</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.228468</td>\n",
       "      <td>9.413000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>9.413000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>26.580830</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-2.407801</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.143907</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>9.413000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>27.503576</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.084984</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.131602</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>25.743919</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.854400</td>\n",
       "      <td>-0.229559</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.142261</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>9.057000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>29.284693</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.109464</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.175410</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>29.670959</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-1.208602</td>\n",
       "      <td>-0.233845</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.121899</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>30.021460</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>-0.047061</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>29.642345</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>0.157554</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>32.510731</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.531282</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.193306</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>30.586552</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>-0.364063</td>\n",
       "      <td>-0.208150</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>31.995708</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.191883</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>33.361946</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>36.659515</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.956637</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.346833</td>\n",
       "      <td>1.027800e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>36.309013</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.171295</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>1.027800e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>38.319027</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>3.178360</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>1.027800e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>40.908440</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>1.008367</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>41.595135</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>-0.237913</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>37.470112</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>-2.053341</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.386610</td>\n",
       "      <td>1.053600e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0       A  2010      1 2010-01-29  20.050072  18.079800          -0.005306   \n",
       "1       A  2010      2 2010-02-26  22.503576  20.292213           0.006162   \n",
       "2       A  2010      3 2010-03-31  24.599428  22.182100           0.003922   \n",
       "3       A  2010      4 2010-04-30  25.937054  23.388283           0.002628   \n",
       "4       A  2010      5 2010-05-28  23.147352  20.872721          -0.005176   \n",
       "5       A  2010      6 2010-06-30  20.336195  18.337812          -0.005598   \n",
       "6       A  2010      7 2010-07-30  19.978540  18.015299          -0.000649   \n",
       "7       A  2010      8 2010-08-31  19.291845  17.396082          -0.001236   \n",
       "8       A  2010      9 2010-09-30  23.869814  21.524183           0.010359   \n",
       "9       A  2010     10 2010-10-29  24.892704  22.446566           0.002081   \n",
       "10      A  2010     11 2010-11-30  25.050072  22.588463           0.000434   \n",
       "11      A  2010     12 2010-12-31  29.635193  26.723019           0.007740   \n",
       "12      A  2011      1 2011-01-31  29.921316  26.981022           0.000613   \n",
       "13      A  2011      2 2011-02-28  30.100143  27.142279           0.000641   \n",
       "14      A  2011      3 2011-03-31  32.031475  28.883820           0.003029   \n",
       "15      A  2011      4 2011-04-29  35.701000  32.192753           0.005564   \n",
       "16      A  2011      5 2011-05-31  35.672390  32.166958           0.000087   \n",
       "17      A  2011      6 2011-06-30  36.559372  32.966778           0.001298   \n",
       "18      A  2011      7 2011-07-29  30.157368  27.193878          -0.009376   \n",
       "19      A  2011      8 2011-08-31  26.373390  23.781748          -0.004521   \n",
       "20      A  2011      9 2011-09-30  22.353361  20.156755          -0.007177   \n",
       "21      A  2011     10 2011-10-31  26.516453  23.910744           0.009367   \n",
       "22      A  2011     11 2011-11-30  26.824034  24.188101           0.001094   \n",
       "23      A  2011     12 2011-12-30  24.985695  22.530416          -0.003089   \n",
       "24      A  2012      1 2012-01-31  30.379112  27.393835           0.010027   \n",
       "25      A  2012      2 2012-02-29  31.201717  28.135605           0.001451   \n",
       "26      A  2012      3 2012-03-30  31.838341  28.774385           0.001156   \n",
       "27      A  2012      4 2012-04-30  30.171675  27.268116          -0.002481   \n",
       "28      A  2012      5 2012-05-31  29.084406  26.285479          -0.001500   \n",
       "29      A  2012      6 2012-06-29  28.068670  25.434919          -0.001276   \n",
       "30      A  2012      7 2012-07-31  27.389128  24.819136          -0.001000   \n",
       "31      A  2012      8 2012-08-31  26.580830  24.086683          -0.001078   \n",
       "32      A  2012      9 2012-09-28  27.503576  24.987616           0.002030   \n",
       "33      A  2012     10 2012-10-31  25.743919  23.388926          -0.003058   \n",
       "34      A  2012     11 2012-11-30  27.389128  24.883636           0.003127   \n",
       "35      A  2012     12 2012-12-31  29.284693  26.671030           0.003600   \n",
       "36      A  2013      1 2013-01-31  32.031475  29.172663           0.004341   \n",
       "37      A  2013      2 2013-02-28  29.670959  27.022825          -0.003888   \n",
       "38      A  2013      3 2013-03-28  30.021460  27.420221           0.000789   \n",
       "39      A  2013      4 2013-04-30  29.642345  27.073946          -0.000415   \n",
       "40      A  2013      5 2013-05-31  32.510731  29.693800           0.004295   \n",
       "41      A  2013      6 2013-06-28  30.586552  28.014383          -0.002819   \n",
       "42      A  2013      7 2013-07-31  31.995708  29.305031           0.002107   \n",
       "43      A  2013      8 2013-08-30  33.361946  30.556374           0.001957   \n",
       "44      A  2013      9 2013-09-30  36.659515  33.654156           0.004900   \n",
       "45      A  2013     10 2013-10-31  36.309013  33.332394          -0.000339   \n",
       "46      A  2013     11 2013-11-29  38.319027  35.177631           0.002915   \n",
       "47      A  2013     12 2013-12-31  40.908440  37.641235           0.003282   \n",
       "48      A  2014      1 2014-01-31  41.595135  38.273094           0.000897   \n",
       "49      A  2014      2 2014-02-28  40.722462  37.470112          -0.000823   \n",
       "\n",
       "    std_return_daily  skew_return_daily    Sharpe  prev_price    return  \\\n",
       "0           0.014345          -1.057651 -0.369864   20.040653 -0.097844   \n",
       "1           0.012060           0.795518  0.511000   18.079800  0.122369   \n",
       "2           0.009486           0.943496  0.413428   20.292213  0.093134   \n",
       "3           0.014793           0.484652  0.177654   22.182100  0.054376   \n",
       "4           0.032369           0.345697 -0.159907   23.388283 -0.107557   \n",
       "5           0.023612          -0.678421 -0.237074   20.872721 -0.121446   \n",
       "6           0.020241          -0.095339 -0.032066   18.337812 -0.017587   \n",
       "7           0.027381           1.112051 -0.045157   18.015299 -0.034372   \n",
       "8           0.018911           0.418899  0.547784   17.396082  0.237301   \n",
       "9           0.013007          -0.983643  0.160000   21.524183  0.042853   \n",
       "10          0.016767          -0.075015  0.025889   22.446566  0.006322   \n",
       "11          0.012241           0.452720  0.632311   22.588463  0.183038   \n",
       "12          0.016586          -1.215774  0.036945   26.723019  0.009655   \n",
       "13          0.026238          -0.276730  0.024438   26.981022  0.005977   \n",
       "14          0.026290           1.589836  0.115230   27.142279  0.064163   \n",
       "15          0.016409           0.475558  0.339112   28.883820  0.114560   \n",
       "16          0.016232           0.514109  0.005342   32.192753 -0.000801   \n",
       "17          0.019456          -0.178554  0.066708   32.166958  0.024865   \n",
       "18          0.020524          -0.284088 -0.456845   32.966778 -0.175113   \n",
       "19          0.051500          -0.335696 -0.087794   27.193878 -0.125474   \n",
       "20          0.037274           0.010767 -0.192555   23.781748 -0.152428   \n",
       "21          0.050285          -0.130691  0.186272   20.156755  0.186240   \n",
       "22          0.033704          -0.365538  0.032471   23.910744  0.011600   \n",
       "23          0.024370          -0.590230 -0.126739   24.188101 -0.068533   \n",
       "24          0.020942          -0.251102  0.478816   22.530416  0.215860   \n",
       "25          0.015591           1.193771  0.093057   27.393835  0.027078   \n",
       "26          0.016830           0.210213  0.068673   28.135605  0.022704   \n",
       "27          0.020689           0.042492 -0.119917   28.774385 -0.052348   \n",
       "28          0.018784           0.819410 -0.079841   27.268116 -0.036036   \n",
       "29          0.024521          -0.432317 -0.052053   26.285479 -0.032359   \n",
       "30          0.018667           0.009255 -0.053582   25.434919 -0.024210   \n",
       "31          0.021243          -2.407801 -0.050759   24.819136 -0.029512   \n",
       "32          0.014265           1.084984  0.142295   24.086683  0.037404   \n",
       "33          0.013322          -0.854400 -0.229559   24.987616 -0.063979   \n",
       "34          0.019133           0.457169  0.163445   23.388926  0.063907   \n",
       "35          0.016311           0.109464  0.220724   24.883636  0.071830   \n",
       "36          0.011486           0.460151  0.377920   26.671030  0.093796   \n",
       "37          0.016625          -1.208602 -0.233845   29.172663 -0.073694   \n",
       "38          0.011159          -0.319110  0.070744   27.022825  0.014706   \n",
       "39          0.018418          -0.323141 -0.022526   27.420221 -0.012628   \n",
       "40          0.013600           0.531282  0.315799   27.073946  0.096767   \n",
       "41          0.013544          -0.364063 -0.208150   29.693800 -0.056558   \n",
       "42          0.010980          -0.043075  0.191883   28.014383  0.046071   \n",
       "43          0.010727           0.960212  0.182432   29.305031  0.042701   \n",
       "44          0.011294           0.956637  0.433843   30.556374  0.101379   \n",
       "45          0.012836           0.171295 -0.026400   33.654156 -0.009561   \n",
       "46          0.021835           3.178360  0.133483   33.332394  0.055359   \n",
       "47          0.010612           1.008367  0.309251   35.177631  0.070033   \n",
       "48          0.014740          -0.237913  0.060830   37.641235  0.016786   \n",
       "49          0.024464          -2.053341 -0.033623   38.273094 -0.020980   \n",
       "\n",
       "    next_month_return  cum_ret6  cum_ret12         asset  \n",
       "0            0.122369  0.207149   0.550332           NaN  \n",
       "1            0.093134  0.225078   1.268206           NaN  \n",
       "2            0.054376  0.235717   1.237475  7.574000e+09  \n",
       "3           -0.107557  0.465642   0.985761  7.574000e+09  \n",
       "4           -0.121446  0.118949   0.775096  7.574000e+09  \n",
       "5           -0.017587 -0.084969   0.399803  7.612000e+09  \n",
       "6           -0.034372 -0.003568   0.202842  7.612000e+09  \n",
       "7            0.237301 -0.142721   0.050233  7.612000e+09  \n",
       "8            0.042853 -0.029660   0.199065  7.612000e+09  \n",
       "9            0.006322 -0.040264   0.406629  9.100000e+09  \n",
       "10           0.183038  0.082200   0.210927  9.100000e+09  \n",
       "11           0.009655  0.457263   0.333440  7.612000e+09  \n",
       "12           0.005977  0.497673   0.492330  7.612000e+09  \n",
       "13           0.064163  0.560252   0.337571  7.612000e+09  \n",
       "14           0.114560  0.341924   0.302123  9.696000e+09  \n",
       "15          -0.000801  0.434195   0.376448  9.696000e+09  \n",
       "16           0.024865  0.424044   0.541100  9.696000e+09  \n",
       "17          -0.175113  0.233647   0.797749  8.649000e+09  \n",
       "18          -0.125474  0.007889   0.509488  8.649000e+09  \n",
       "19          -0.152428 -0.123812   0.367075  8.649000e+09  \n",
       "20           0.186240 -0.302144  -0.063530  9.696000e+09  \n",
       "21           0.011600 -0.257263   0.065229  9.696000e+09  \n",
       "22          -0.068533 -0.248045   0.070817  9.696000e+09  \n",
       "23           0.215860 -0.316572  -0.156891  9.696000e+09  \n",
       "24           0.027078  0.007353   0.015300  9.696000e+09  \n",
       "25           0.022704  0.183076   0.036597  9.696000e+09  \n",
       "26          -0.052348  0.427531  -0.003789  9.057000e+09  \n",
       "27          -0.036036  0.140413  -0.152973  9.057000e+09  \n",
       "28          -0.032359  0.086711  -0.182842  9.057000e+09  \n",
       "29          -0.024210  0.128915  -0.228468  9.413000e+09  \n",
       "30          -0.029512 -0.093988  -0.087326  9.413000e+09  \n",
       "31           0.037404 -0.143907   0.012822  9.413000e+09  \n",
       "32          -0.063979 -0.131602   0.239665  9.057000e+09  \n",
       "33           0.063907 -0.142261  -0.021824  9.057000e+09  \n",
       "34           0.071830 -0.053331   0.028755  9.057000e+09  \n",
       "35           0.093796  0.048599   0.183779  1.053600e+10  \n",
       "36          -0.073694  0.175410   0.064935  1.053600e+10  \n",
       "37           0.014706  0.121899  -0.039551  1.053600e+10  \n",
       "38          -0.012628  0.097352  -0.047061  1.053600e+10  \n",
       "39           0.096767  0.157554  -0.007121  1.053600e+10  \n",
       "40          -0.056558  0.193306   0.129666  1.053600e+10  \n",
       "41           0.046071  0.050368   0.101414  1.053600e+10  \n",
       "42           0.042701  0.004537   0.180743  1.053600e+10  \n",
       "43           0.101379  0.130762   0.268600  1.053600e+10  \n",
       "44          -0.009561  0.227348   0.346833  1.027800e+10  \n",
       "45           0.055359  0.231161   0.425136  1.027800e+10  \n",
       "46           0.070033  0.184679   0.413685  1.027800e+10  \n",
       "47           0.016786  0.343640   0.411315  1.053600e+10  \n",
       "48          -0.020980  0.306025   0.311951  1.053600e+10  \n",
       "49          -0.017741  0.226262   0.386610  1.053600e+10  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_asset_data4 = all_asset_data3[(all_asset_data3['year'] >= 2010) & (all_asset_data3['year'] <= 2022)]\n",
    "all_asset_data4.sort_values(by=['symbol', 'year', 'month'], inplace=True)\n",
    "\n",
    "final_data = pd.merge(_df, all_asset_data4, how='left', on=['symbol', 'year', 'month'])\n",
    "\n",
    "final_data1 = final_data[(final_data['year'] >= 2010) & (final_data['year'] <= 2022)]\n",
    "\n",
    "# Group by 'symbol' and fill NaN values within each group using forward fill\n",
    "final_data1 = final_data1.fillna(method='ffill').reset_index()\n",
    "\n",
    "final_data1.drop(columns=['index'],inplace=True)\n",
    "final_data1.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: A\n",
      "Failed to fetch data for symbol: AAL\n",
      "Data processed successfully for symbol: AAPL\n",
      "Failed to fetch data for symbol: ABBV\n",
      "Data processed successfully for symbol: ABNB\n",
      "Failed to fetch data for symbol: ABT\n",
      "Data processed successfully for symbol: ACGL\n",
      "Failed to fetch data for symbol: ACN\n",
      "Data processed successfully for symbol: ADBE\n",
      "Failed to fetch data for symbol: ADI\n",
      "Failed to fetch data for symbol: ADM\n",
      "Data processed successfully for symbol: ADP\n",
      "Failed to fetch data for symbol: ADSK\n",
      "Failed to fetch data for symbol: AEE\n",
      "Data processed successfully for symbol: AEP\n",
      "Failed to fetch data for symbol: AES\n",
      "Data processed successfully for symbol: AFL\n",
      "Data processed successfully for symbol: AIG\n",
      "Data processed successfully for symbol: AIZ\n",
      "Data processed successfully for symbol: AJG\n",
      "Data processed successfully for symbol: AKAM\n",
      "Failed to fetch data for symbol: ALB\n",
      "Data processed successfully for symbol: ALGN\n",
      "Failed to fetch data for symbol: ALK\n",
      "Data processed successfully for symbol: ALL\n",
      "Data processed successfully for symbol: ALLE\n",
      "Data processed successfully for symbol: AMAT\n",
      "Data processed successfully for symbol: AMCR\n",
      "Failed to fetch data for symbol: AMD\n",
      "Data processed successfully for symbol: AME\n",
      "Failed to fetch data for symbol: AMGN\n",
      "Data processed successfully for symbol: AMP\n",
      "Data processed successfully for symbol: AMT\n",
      "Failed to fetch data for symbol: AMZN\n",
      "Data processed successfully for symbol: ANET\n",
      "Failed to fetch data for symbol: ANSS\n",
      "Data processed successfully for symbol: AON\n",
      "Data processed successfully for symbol: AOS\n",
      "Failed to fetch data for symbol: APA\n",
      "Data processed successfully for symbol: APD\n",
      "Data processed successfully for symbol: APH\n",
      "Data processed successfully for symbol: APTV\n",
      "Data processed successfully for symbol: ARE\n",
      "Failed to fetch data for symbol: ATO\n",
      "Data processed successfully for symbol: AVB\n",
      "Data processed successfully for symbol: AVGO\n",
      "Failed to fetch data for symbol: AVY\n",
      "Failed to fetch data for symbol: AWK\n",
      "Data processed successfully for symbol: AXON\n",
      "Data processed successfully for symbol: AXP\n",
      "Failed to fetch data for symbol: AZO\n",
      "Data processed successfully for symbol: BA\n",
      "Data processed successfully for symbol: BAC\n",
      "Data processed successfully for symbol: BALL\n",
      "Data processed successfully for symbol: BAX\n",
      "Failed to fetch data for symbol: BBWI\n",
      "Failed to fetch data for symbol: BBY\n",
      "Failed to fetch data for symbol: BDX\n",
      "Data processed successfully for symbol: BEN\n",
      "Failed to fetch data for symbol: BG\n",
      "Data processed successfully for symbol: BIIB\n",
      "Data processed successfully for symbol: BIO\n",
      "Data processed successfully for symbol: BK\n",
      "Data processed successfully for symbol: BKNG\n",
      "Data processed successfully for symbol: BKR\n",
      "Data processed successfully for symbol: BLK\n",
      "Data processed successfully for symbol: BMY\n",
      "Data processed successfully for symbol: BR\n",
      "Data processed successfully for symbol: BRO\n",
      "Failed to fetch data for symbol: BSX\n",
      "Data processed successfully for symbol: BWA\n",
      "Data processed successfully for symbol: BX\n",
      "Data processed successfully for symbol: BXP\n",
      "Data processed successfully for symbol: C\n",
      "Data processed successfully for symbol: CAG\n",
      "Failed to fetch data for symbol: CAH\n",
      "Data processed successfully for symbol: CARR\n",
      "Data processed successfully for symbol: CAT\n",
      "Data processed successfully for symbol: CB\n",
      "Data processed successfully for symbol: CBOE\n",
      "Data processed successfully for symbol: CBRE\n",
      "Data processed successfully for symbol: CCI\n",
      "Failed to fetch data for symbol: CCL\n",
      "Data processed successfully for symbol: CDAY\n",
      "Failed to fetch data for symbol: CDNS\n",
      "Data processed successfully for symbol: CDW\n",
      "Failed to fetch data for symbol: CE\n",
      "Failed to fetch data for symbol: CF\n",
      "Data processed successfully for symbol: CFG\n",
      "Data processed successfully for symbol: CHD\n",
      "Data processed successfully for symbol: CHRW\n",
      "Failed to fetch data for symbol: CHTR\n",
      "Data processed successfully for symbol: CI\n",
      "Data processed successfully for symbol: CINF\n",
      "Data processed successfully for symbol: CL\n",
      "Data processed successfully for symbol: CLX\n",
      "Data processed successfully for symbol: CMA\n",
      "Failed to fetch data for symbol: CMCSA\n",
      "Data processed successfully for symbol: CME\n",
      "Data processed successfully for symbol: CMG\n",
      "Data processed successfully for symbol: CMI\n",
      "Failed to fetch data for symbol: CMS\n",
      "Data processed successfully for symbol: CNC\n",
      "Failed to fetch data for symbol: CNP\n",
      "Data processed successfully for symbol: COF\n",
      "Data processed successfully for symbol: COO\n",
      "Data processed successfully for symbol: COP\n",
      "Failed to fetch data for symbol: COR\n",
      "Data processed successfully for symbol: COST\n",
      "Data processed successfully for symbol: CPB\n",
      "Data processed successfully for symbol: CPRT\n",
      "Data processed successfully for symbol: CPT\n",
      "Data processed successfully for symbol: CRL\n",
      "Data processed successfully for symbol: CRM\n",
      "Data processed successfully for symbol: CSCO\n",
      "Data processed successfully for symbol: CSGP\n",
      "Data processed successfully for symbol: CSX\n",
      "Failed to fetch data for symbol: CTAS\n",
      "Data processed successfully for symbol: CTLT\n",
      "Data processed successfully for symbol: CTRA\n",
      "Data processed successfully for symbol: CTSH\n",
      "Failed to fetch data for symbol: CTVA\n",
      "Data processed successfully for symbol: CVS\n",
      "Data processed successfully for symbol: CVX\n",
      "Data processed successfully for symbol: CZR\n",
      "Data processed successfully for symbol: D\n",
      "Failed to fetch data for symbol: DAL\n",
      "Data processed successfully for symbol: DD\n",
      "Data processed successfully for symbol: DE\n",
      "Data processed successfully for symbol: DFS\n",
      "Failed to fetch data for symbol: DG\n",
      "Failed to fetch data for symbol: DGX\n",
      "Data processed successfully for symbol: DHI\n",
      "Data processed successfully for symbol: DHR\n",
      "Failed to fetch data for symbol: DIS\n",
      "Data processed successfully for symbol: DLR\n",
      "Data processed successfully for symbol: DLTR\n",
      "Data processed successfully for symbol: DOV\n",
      "Failed to fetch data for symbol: DOW\n",
      "Data processed successfully for symbol: DPZ\n",
      "Data processed successfully for symbol: DRI\n",
      "Failed to fetch data for symbol: DTE\n",
      "Failed to fetch data for symbol: DUK\n",
      "Data processed successfully for symbol: DVA\n",
      "Failed to fetch data for symbol: DVN\n",
      "Data processed successfully for symbol: DXCM\n",
      "Data processed successfully for symbol: EA\n",
      "Data processed successfully for symbol: EBAY\n",
      "Data processed successfully for symbol: ECL\n",
      "Failed to fetch data for symbol: ED\n",
      "Data processed successfully for symbol: EFX\n",
      "Data processed successfully for symbol: EG\n",
      "Data processed successfully for symbol: EIX\n",
      "Data processed successfully for symbol: EL\n",
      "Data processed successfully for symbol: ELV\n",
      "Data processed successfully for symbol: EMN\n",
      "Failed to fetch data for symbol: EMR\n",
      "Data processed successfully for symbol: ENPH\n",
      "Failed to fetch data for symbol: EOG\n",
      "Data processed successfully for symbol: EPAM\n",
      "Data processed successfully for symbol: EQIX\n",
      "Data processed successfully for symbol: EQR\n",
      "Data processed successfully for symbol: EQT\n",
      "Failed to fetch data for symbol: ES\n",
      "Data processed successfully for symbol: ESS\n",
      "Failed to fetch data for symbol: ETN\n",
      "Failed to fetch data for symbol: ETR\n",
      "Data processed successfully for symbol: ETSY\n",
      "Failed to fetch data for symbol: EVRG\n",
      "Data processed successfully for symbol: EW\n",
      "Data processed successfully for symbol: EXC\n",
      "Failed to fetch data for symbol: EXPD\n",
      "Failed to fetch data for symbol: EXPE\n",
      "Data processed successfully for symbol: EXR\n",
      "Data processed successfully for symbol: F\n",
      "Data processed successfully for symbol: FANG\n",
      "Failed to fetch data for symbol: FAST\n",
      "Data processed successfully for symbol: FCX\n",
      "Data processed successfully for symbol: FDS\n",
      "Failed to fetch data for symbol: FDX\n",
      "Data processed successfully for symbol: FE\n",
      "Data processed successfully for symbol: FFIV\n",
      "Data processed successfully for symbol: FI\n",
      "Data processed successfully for symbol: FICO\n",
      "Data processed successfully for symbol: FIS\n",
      "Data processed successfully for symbol: FITB\n",
      "Failed to fetch data for symbol: FLT\n",
      "Failed to fetch data for symbol: FMC\n",
      "Failed to fetch data for symbol: FOX\n",
      "Failed to fetch data for symbol: FOXA\n",
      "Data processed successfully for symbol: FRT\n",
      "Data processed successfully for symbol: FSLR\n",
      "Data processed successfully for symbol: FTNT\n",
      "Failed to fetch data for symbol: FTV\n",
      "Failed to fetch data for symbol: GD\n",
      "Data processed successfully for symbol: GE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: GEN\n",
      "Failed to fetch data for symbol: GILD\n",
      "Data processed successfully for symbol: GIS\n",
      "Data processed successfully for symbol: GL\n",
      "Data processed successfully for symbol: GLW\n",
      "Data processed successfully for symbol: GM\n",
      "Data processed successfully for symbol: GNRC\n",
      "Data processed successfully for symbol: GOOG\n",
      "Data processed successfully for symbol: GOOGL\n",
      "Failed to fetch data for symbol: GPC\n",
      "Data processed successfully for symbol: GPN\n",
      "Failed to fetch data for symbol: GRMN\n",
      "Data processed successfully for symbol: GS\n",
      "Failed to fetch data for symbol: GWW\n",
      "Data processed successfully for symbol: HAL\n",
      "Data processed successfully for symbol: HAS\n",
      "Data processed successfully for symbol: HBAN\n",
      "Data processed successfully for symbol: HCA\n",
      "Data processed successfully for symbol: HD\n",
      "Data processed successfully for symbol: HES\n",
      "Data processed successfully for symbol: HIG\n",
      "Data processed successfully for symbol: HII\n",
      "Data processed successfully for symbol: HLT\n",
      "Data processed successfully for symbol: HOLX\n",
      "Failed to fetch data for symbol: HON\n",
      "Data processed successfully for symbol: HPE\n",
      "Failed to fetch data for symbol: HPQ\n",
      "Failed to fetch data for symbol: HRL\n",
      "Data processed successfully for symbol: HSIC\n",
      "Data processed successfully for symbol: HST\n",
      "Data processed successfully for symbol: HSY\n",
      "Data processed successfully for symbol: HUBB\n",
      "Data processed successfully for symbol: HUM\n",
      "Data processed successfully for symbol: HWM\n",
      "Data processed successfully for symbol: IBM\n",
      "Data processed successfully for symbol: ICE\n",
      "Data processed successfully for symbol: IDXX\n",
      "Data processed successfully for symbol: IEX\n",
      "Failed to fetch data for symbol: IFF\n",
      "Failed to fetch data for symbol: ILMN\n",
      "Data processed successfully for symbol: INCY\n",
      "Failed to fetch data for symbol: INTC\n",
      "Data processed successfully for symbol: INTU\n",
      "Data processed successfully for symbol: INVH\n",
      "Failed to fetch data for symbol: IP\n",
      "Data processed successfully for symbol: IPG\n",
      "Data processed successfully for symbol: IQV\n",
      "Data processed successfully for symbol: IR\n",
      "Failed to fetch data for symbol: IRM\n",
      "Data processed successfully for symbol: ISRG\n",
      "Data processed successfully for symbol: IT\n",
      "Failed to fetch data for symbol: ITW\n",
      "Data processed successfully for symbol: IVZ\n",
      "Failed to fetch data for symbol: J\n",
      "Data processed successfully for symbol: JBHT\n",
      "Data processed successfully for symbol: JCI\n",
      "Data processed successfully for symbol: JKHY\n",
      "Data processed successfully for symbol: JNJ\n",
      "Data processed successfully for symbol: JNPR\n",
      "Data processed successfully for symbol: JPM\n",
      "Failed to fetch data for symbol: K\n",
      "Data processed successfully for symbol: KDP\n",
      "Data processed successfully for symbol: KEY\n",
      "Data processed successfully for symbol: KEYS\n",
      "Data processed successfully for symbol: KHC\n",
      "Data processed successfully for symbol: KIM\n",
      "Data processed successfully for symbol: KLAC\n",
      "Failed to fetch data for symbol: KMB\n",
      "Data processed successfully for symbol: KMI\n",
      "Data processed successfully for symbol: KMX\n",
      "Failed to fetch data for symbol: KO\n",
      "Data processed successfully for symbol: KR\n",
      "Data processed successfully for symbol: L\n",
      "Data processed successfully for symbol: LDOS\n",
      "Data processed successfully for symbol: LEN\n",
      "Data processed successfully for symbol: LH\n",
      "Data processed successfully for symbol: LHX\n",
      "Data processed successfully for symbol: LIN\n",
      "Failed to fetch data for symbol: LKQ\n",
      "Failed to fetch data for symbol: LLY\n",
      "Data processed successfully for symbol: LMT\n",
      "Failed to fetch data for symbol: LNT\n",
      "Data processed successfully for symbol: LOW\n",
      "Data processed successfully for symbol: LRCX\n",
      "Data processed successfully for symbol: LULU\n",
      "Failed to fetch data for symbol: LUV\n",
      "Data processed successfully for symbol: LVS\n",
      "Data processed successfully for symbol: LW\n",
      "Failed to fetch data for symbol: LYB\n",
      "Failed to fetch data for symbol: LYV\n",
      "Data processed successfully for symbol: MA\n",
      "Data processed successfully for symbol: MAA\n",
      "Failed to fetch data for symbol: MAR\n",
      "Data processed successfully for symbol: MAS\n",
      "Failed to fetch data for symbol: MCD\n",
      "Failed to fetch data for symbol: MCHP\n",
      "Failed to fetch data for symbol: MCK\n",
      "Data processed successfully for symbol: MCO\n",
      "Data processed successfully for symbol: MDLZ\n",
      "Data processed successfully for symbol: MDT\n",
      "Data processed successfully for symbol: MET\n",
      "Data processed successfully for symbol: META\n",
      "Data processed successfully for symbol: MGM\n",
      "Data processed successfully for symbol: MHK\n",
      "Data processed successfully for symbol: MKC\n",
      "Data processed successfully for symbol: MKTX\n",
      "Data processed successfully for symbol: MLM\n",
      "Failed to fetch data for symbol: MMC\n",
      "Data processed successfully for symbol: MMM\n",
      "Failed to fetch data for symbol: MNST\n",
      "Data processed successfully for symbol: MO\n",
      "Data processed successfully for symbol: MOH\n",
      "Failed to fetch data for symbol: MOS\n",
      "Data processed successfully for symbol: MPC\n",
      "Data processed successfully for symbol: MPWR\n",
      "Failed to fetch data for symbol: MRK\n",
      "Data processed successfully for symbol: MRNA\n",
      "Data processed successfully for symbol: MRO\n",
      "Data processed successfully for symbol: MS\n",
      "Data processed successfully for symbol: MSCI\n",
      "Data processed successfully for symbol: MSFT\n",
      "Failed to fetch data for symbol: MSI\n",
      "Data processed successfully for symbol: MTB\n",
      "Failed to fetch data for symbol: MTCH\n",
      "Data processed successfully for symbol: MTD\n",
      "Data processed successfully for symbol: MU\n",
      "Data processed successfully for symbol: NCLH\n",
      "Data processed successfully for symbol: NDAQ\n",
      "Failed to fetch data for symbol: NDSN\n",
      "Data processed successfully for symbol: NEE\n",
      "Data processed successfully for symbol: NEM\n",
      "Data processed successfully for symbol: NFLX\n",
      "Failed to fetch data for symbol: NI\n",
      "Failed to fetch data for symbol: NKE\n",
      "Data processed successfully for symbol: NOC\n",
      "Data processed successfully for symbol: NOW\n",
      "Data processed successfully for symbol: NRG\n",
      "Data processed successfully for symbol: NSC\n",
      "Data processed successfully for symbol: NTAP\n",
      "Data processed successfully for symbol: NTRS\n",
      "Data processed successfully for symbol: NUE\n",
      "Data processed successfully for symbol: NVDA\n",
      "Data processed successfully for symbol: NVR\n",
      "Failed to fetch data for symbol: NWS\n",
      "Failed to fetch data for symbol: NWSA\n",
      "Data processed successfully for symbol: NXPI\n",
      "Data processed successfully for symbol: O\n",
      "Data processed successfully for symbol: ODFL\n",
      "Failed to fetch data for symbol: OKE\n",
      "Failed to fetch data for symbol: OMC\n",
      "Data processed successfully for symbol: ON\n",
      "Failed to fetch data for symbol: ORCL\n",
      "Failed to fetch data for symbol: ORLY\n",
      "Data processed successfully for symbol: OTIS\n",
      "Failed to fetch data for symbol: OXY\n",
      "Data processed successfully for symbol: PANW\n",
      "Failed to fetch data for symbol: PARA\n",
      "Data processed successfully for symbol: PAYC\n",
      "Data processed successfully for symbol: PAYX\n",
      "Failed to fetch data for symbol: PCAR\n",
      "Failed to fetch data for symbol: PCG\n",
      "Data processed successfully for symbol: PEAK\n",
      "Failed to fetch data for symbol: PEG\n",
      "Data processed successfully for symbol: PEP\n",
      "Data processed successfully for symbol: PFE\n",
      "Data processed successfully for symbol: PFG\n",
      "Data processed successfully for symbol: PG\n",
      "Data processed successfully for symbol: PGR\n",
      "Data processed successfully for symbol: PH\n",
      "Data processed successfully for symbol: PHM\n",
      "Failed to fetch data for symbol: PKG\n",
      "Data processed successfully for symbol: PLD\n",
      "Data processed successfully for symbol: PM\n",
      "Data processed successfully for symbol: PNC\n",
      "Data processed successfully for symbol: PNR\n",
      "Failed to fetch data for symbol: PNW\n",
      "Data processed successfully for symbol: PODD\n",
      "Data processed successfully for symbol: POOL\n",
      "Data processed successfully for symbol: PPG\n",
      "Failed to fetch data for symbol: PPL\n",
      "Data processed successfully for symbol: PRU\n",
      "Data processed successfully for symbol: PSA\n",
      "Data processed successfully for symbol: PSX\n",
      "Data processed successfully for symbol: PTC\n",
      "Data processed successfully for symbol: PWR\n",
      "Failed to fetch data for symbol: PXD\n",
      "Data processed successfully for symbol: PYPL\n",
      "Data processed successfully for symbol: QCOM\n",
      "Data processed successfully for symbol: QRVO\n",
      "Data processed successfully for symbol: RCL\n",
      "Data processed successfully for symbol: REG\n",
      "Data processed successfully for symbol: REGN\n",
      "Data processed successfully for symbol: RF\n",
      "Data processed successfully for symbol: RHI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: RJF\n",
      "Data processed successfully for symbol: RL\n",
      "Data processed successfully for symbol: RMD\n",
      "Failed to fetch data for symbol: ROK\n",
      "Data processed successfully for symbol: ROL\n",
      "Data processed successfully for symbol: ROP\n",
      "Failed to fetch data for symbol: ROST\n",
      "Failed to fetch data for symbol: RSG\n",
      "Data processed successfully for symbol: RTX\n",
      "Data processed successfully for symbol: RVTY\n",
      "Failed to fetch data for symbol: SBAC\n",
      "Data processed successfully for symbol: SBUX\n",
      "Data processed successfully for symbol: SCHW\n",
      "Failed to fetch data for symbol: SEDG\n",
      "Data processed successfully for symbol: SEE\n",
      "Failed to fetch data for symbol: SHW\n",
      "Data processed successfully for symbol: SJM\n",
      "Data processed successfully for symbol: SLB\n",
      "Data processed successfully for symbol: SNA\n",
      "Data processed successfully for symbol: SNPS\n",
      "Data processed successfully for symbol: SO\n",
      "Data processed successfully for symbol: SPG\n",
      "Data processed successfully for symbol: SPGI\n",
      "Failed to fetch data for symbol: SRE\n",
      "Data processed successfully for symbol: STE\n",
      "Data processed successfully for symbol: STLD\n",
      "Data processed successfully for symbol: STT\n",
      "Data processed successfully for symbol: STX\n",
      "Data processed successfully for symbol: STZ\n",
      "Failed to fetch data for symbol: SWK\n",
      "Data processed successfully for symbol: SWKS\n",
      "Data processed successfully for symbol: SYF\n",
      "Data processed successfully for symbol: SYK\n",
      "Failed to fetch data for symbol: SYY\n",
      "Data processed successfully for symbol: T\n",
      "Data processed successfully for symbol: TAP\n",
      "Data processed successfully for symbol: TDG\n",
      "Data processed successfully for symbol: TDY\n",
      "Failed to fetch data for symbol: TECH\n",
      "Data processed successfully for symbol: TEL\n",
      "Data processed successfully for symbol: TER\n",
      "Data processed successfully for symbol: TFC\n",
      "Data processed successfully for symbol: TFX\n",
      "Failed to fetch data for symbol: TGT\n",
      "Failed to fetch data for symbol: TJX\n",
      "Failed to fetch data for symbol: TMO\n",
      "Data processed successfully for symbol: TMUS\n",
      "Data processed successfully for symbol: TPR\n",
      "Failed to fetch data for symbol: TRGP\n",
      "Data processed successfully for symbol: TRMB\n",
      "Data processed successfully for symbol: TROW\n",
      "Data processed successfully for symbol: TRV\n",
      "Data processed successfully for symbol: TSCO\n",
      "Data processed successfully for symbol: TSLA\n",
      "Failed to fetch data for symbol: TSN\n",
      "Data processed successfully for symbol: TT\n",
      "Data processed successfully for symbol: TTWO\n",
      "Data processed successfully for symbol: TXN\n",
      "Data processed successfully for symbol: TXT\n",
      "Data processed successfully for symbol: TYL\n",
      "Failed to fetch data for symbol: UAL\n",
      "Data processed successfully for symbol: UDR\n",
      "Failed to fetch data for symbol: UHS\n",
      "Data processed successfully for symbol: ULTA\n",
      "Data processed successfully for symbol: UNH\n",
      "Data processed successfully for symbol: UNP\n",
      "Failed to fetch data for symbol: UPS\n",
      "Data processed successfully for symbol: URI\n",
      "Data processed successfully for symbol: USB\n",
      "Data processed successfully for symbol: V\n",
      "Data processed successfully for symbol: VFC\n",
      "Data processed successfully for symbol: VICI\n",
      "Failed to fetch data for symbol: VLO\n",
      "Data processed successfully for symbol: VMC\n",
      "Data processed successfully for symbol: VRSK\n",
      "Data processed successfully for symbol: VRSN\n",
      "Data processed successfully for symbol: VRTX\n",
      "Data processed successfully for symbol: VTR\n",
      "Data processed successfully for symbol: VTRS\n",
      "Failed to fetch data for symbol: VZ\n",
      "Data processed successfully for symbol: WAB\n",
      "Data processed successfully for symbol: WAT\n",
      "Data processed successfully for symbol: WBA\n",
      "Data processed successfully for symbol: WBD\n",
      "Data processed successfully for symbol: WDC\n",
      "Failed to fetch data for symbol: WEC\n",
      "Data processed successfully for symbol: WELL\n",
      "Data processed successfully for symbol: WFC\n",
      "Failed to fetch data for symbol: WHR\n",
      "Data processed successfully for symbol: WM\n",
      "Failed to fetch data for symbol: WMB\n",
      "Failed to fetch data for symbol: WMT\n",
      "Data processed successfully for symbol: WRB\n",
      "Failed to fetch data for symbol: WRK\n",
      "Data processed successfully for symbol: WST\n",
      "Data processed successfully for symbol: WTW\n",
      "Data processed successfully for symbol: WY\n",
      "Data processed successfully for symbol: WYNN\n",
      "Failed to fetch data for symbol: XEL\n",
      "Data processed successfully for symbol: XOM\n",
      "Data processed successfully for symbol: XRAY\n",
      "Data processed successfully for symbol: XYL\n",
      "Data processed successfully for symbol: YUM\n",
      "Data processed successfully for symbol: ZBH\n",
      "Data processed successfully for symbol: ZBRA\n",
      "Data processed successfully for symbol: ZION\n",
      "Data processed successfully for symbol: ZTS\n",
      "Data concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "all_liabilities_data = pd.DataFrame()\n",
    "\n",
    "for symb in symbols:\n",
    "    _cik = companyData[companyData['ticker'] == symb]['cik_str10']\n",
    "    \n",
    "    # Check if CIK is available\n",
    "    if not _cik.empty:\n",
    "        cik = _cik.iloc[0]\n",
    "        \n",
    "        # Fetch company facts\n",
    "        companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json', headers=headers)\n",
    "        \n",
    "        # Check if the request is successful and has the expected structure\n",
    "        if companyFacts.status_code == 200 and 'facts' in companyFacts.json().keys() and 'us-gaap' in companyFacts.json()['facts'].keys() and 'Liabilities' in companyFacts.json()['facts']['us-gaap'].keys():\n",
    "            \n",
    "            # Extract liabilities data and create DataFrame\n",
    "            liabilities_data = companyFacts.json()['facts']['us-gaap']['Liabilities']['units']['USD']\n",
    "            liabilities = pd.DataFrame.from_dict(liabilities_data)\n",
    "            liabilities['symbol'] = symb\n",
    "            \n",
    "            # Concatenate directly to the existing DataFrame\n",
    "            all_liabilities_data = pd.concat([all_liabilities_data, liabilities], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data processed successfully for symbol: {symb}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for symbol: {symb}\")\n",
    "    else:\n",
    "        print(f\"CIK not available for symbol: {symb}\")\n",
    "\n",
    "# Check if there is data\n",
    "if not all_liabilities_data.empty:\n",
    "    print(\"Data concatenated successfully.\")\n",
    "    # Further processing or analysis can be done with 'all_liabilities_data'\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              end          val                  accn      fy  fp    form  \\\n",
      "0      2008-10-31   4448000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "1      2008-10-31   4448000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "2      2008-10-31   4448000000  0001104659-10-047478  2009.0  FY     8-K   \n",
      "3      2009-07-31   4084000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "4      2009-10-31   5106000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "...           ...          ...                   ...     ...  ..     ...   \n",
      "35923  2022-12-31  10522000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "35924  2022-12-31  10522000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "35925  2023-03-31   9263000000  0001555280-23-000150  2023.0  Q1    10-Q   \n",
      "35926  2023-06-30   9128000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "35927  2023-09-30   9032000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "\n",
      "            filed      frame symbol  \n",
      "0      2009-10-05        NaN      A  \n",
      "1      2009-12-21        NaN      A  \n",
      "2      2010-09-07  CY2008Q3I      A  \n",
      "3      2009-10-05  CY2009Q2I      A  \n",
      "4      2009-12-21        NaN      A  \n",
      "...           ...        ...    ...  \n",
      "35923  2023-08-08        NaN    ZTS  \n",
      "35924  2023-11-02  CY2022Q4I    ZTS  \n",
      "35925  2023-05-04  CY2023Q1I    ZTS  \n",
      "35926  2023-08-08  CY2023Q2I    ZTS  \n",
      "35927  2023-11-02  CY2023Q3I    ZTS  \n",
      "\n",
      "[35928 rows x 9 columns]\n",
      "Data processed successfully.\n",
      "       year  month  liabilities symbol\n",
      "0      2009     12   4448000000      A\n",
      "1      2010      3   5098000000      A\n",
      "2      2010      6   5098000000      A\n",
      "3      2010     12   6460000000      A\n",
      "4      2011      3   4705000000      A\n",
      "...     ...    ...          ...    ...\n",
      "17190  2022     11   9012000000    ZTS\n",
      "17191  2023      2   9356000000    ZTS\n",
      "17192  2023      5  10522000000    ZTS\n",
      "17193  2023      8   9128000000    ZTS\n",
      "17194  2023     11  10522000000    ZTS\n",
      "\n",
      "[17195 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3621000704.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_liabilities_data['filed1'] = pd.to_datetime(all_liabilities_data['filed'])\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3621000704.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_liabilities_data['year'] = all_liabilities_data['filed1'].dt.year\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3621000704.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_liabilities_data['month'] = all_liabilities_data['filed1'].dt.month\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3621000704.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_liabilities_data['day'] = all_liabilities_data['filed1'].dt.day\n"
     ]
    }
   ],
   "source": [
    "    print(all_liabilities_data)\n",
    "    all_liabilities_data = all_liabilities_data[all_liabilities_data['form'].isin(['10-K', '10-Q'])]\n",
    "    all_liabilities_data['filed1'] = pd.to_datetime(all_liabilities_data['filed'])\n",
    "    all_liabilities_data['year'] = all_liabilities_data['filed1'].dt.year\n",
    "    all_liabilities_data['month'] = all_liabilities_data['filed1'].dt.month\n",
    "    all_liabilities_data['day'] = all_liabilities_data['filed1'].dt.day\n",
    "    \n",
    "    all_liabilities_data2 = all_liabilities_data.sort_values(by='filed1')\n",
    "    all_liabilities_data2 = all_liabilities_data2.groupby(['symbol','year', 'month']).first().reset_index()\n",
    "    \n",
    "    features = ['year', 'month', 'val', 'symbol']\n",
    "    all_liabilities_data3 = all_liabilities_data2[features].copy()\n",
    "    all_liabilities_data3.rename(columns={'val': 'liabilities'}, inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"Data processed successfully.\")\n",
    "    print(all_liabilities_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\271665417.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  all_liabilities_data4=all_liabilities_data3[(final_data['year'] >= 2010) & (final_data['year'] <= 2022)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "      <th>netIncome_x</th>\n",
       "      <th>netIncome_y</th>\n",
       "      <th>liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>20.336195</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>-0.678421</td>\n",
       "      <td>-0.237074</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>19.978540</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>-0.003568</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>19.291845</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>1.112051</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>-0.142721</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>23.869814</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.547784</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>-0.029660</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>24.892704</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.983643</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>25.050072</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>29.635193</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.632311</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.333440</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-1.215774</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>30.100143</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.026238</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>1.589836</td>\n",
       "      <td>0.115230</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>35.701000</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.339112</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>35.672390</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.424044</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>36.559372</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>30.157368</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.284088</td>\n",
       "      <td>-0.456845</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>26.373390</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.335696</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>22.353361</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.192555</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>-0.302144</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>26.516453</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.130691</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2011-11-30</td>\n",
       "      <td>26.824034</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.365538</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.070817</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>24.985695</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>-0.590230</td>\n",
       "      <td>-0.126739</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>-0.316572</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>30.379112</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.251102</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>31.201717</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>1.193771</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>31.838341</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.210213</td>\n",
       "      <td>0.068673</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>30.171675</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>-0.119917</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>-0.152973</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>29.084406</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>-0.079841</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>-0.182842</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>28.068670</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.052053</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.228468</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>26.580830</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-2.407801</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.143907</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>27.503576</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.084984</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.131602</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>25.743919</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.854400</td>\n",
       "      <td>-0.229559</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.142261</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>29.284693</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.109464</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.175410</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>29.670959</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-1.208602</td>\n",
       "      <td>-0.233845</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.121899</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>30.021460</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>-0.047061</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>29.642345</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>0.157554</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>32.510731</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.531282</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.193306</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>30.586552</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>-0.364063</td>\n",
       "      <td>-0.208150</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>31.995708</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.191883</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>33.361946</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>36.659515</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.956637</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.346833</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>36.309013</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.171295</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>38.319027</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>3.178360</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>40.908440</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>1.008367</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>41.595135</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>-0.237913</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>37.470112</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>-2.053341</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.386610</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0       A  2010      1 2010-01-29  20.050072  18.079800          -0.005306   \n",
       "1       A  2010      2 2010-02-26  22.503576  20.292213           0.006162   \n",
       "2       A  2010      3 2010-03-31  24.599428  22.182100           0.003922   \n",
       "3       A  2010      4 2010-04-30  25.937054  23.388283           0.002628   \n",
       "4       A  2010      5 2010-05-28  23.147352  20.872721          -0.005176   \n",
       "5       A  2010      6 2010-06-30  20.336195  18.337812          -0.005598   \n",
       "6       A  2010      7 2010-07-30  19.978540  18.015299          -0.000649   \n",
       "7       A  2010      8 2010-08-31  19.291845  17.396082          -0.001236   \n",
       "8       A  2010      9 2010-09-30  23.869814  21.524183           0.010359   \n",
       "9       A  2010     10 2010-10-29  24.892704  22.446566           0.002081   \n",
       "10      A  2010     11 2010-11-30  25.050072  22.588463           0.000434   \n",
       "11      A  2010     12 2010-12-31  29.635193  26.723019           0.007740   \n",
       "12      A  2011      1 2011-01-31  29.921316  26.981022           0.000613   \n",
       "13      A  2011      2 2011-02-28  30.100143  27.142279           0.000641   \n",
       "14      A  2011      3 2011-03-31  32.031475  28.883820           0.003029   \n",
       "15      A  2011      4 2011-04-29  35.701000  32.192753           0.005564   \n",
       "16      A  2011      5 2011-05-31  35.672390  32.166958           0.000087   \n",
       "17      A  2011      6 2011-06-30  36.559372  32.966778           0.001298   \n",
       "18      A  2011      7 2011-07-29  30.157368  27.193878          -0.009376   \n",
       "19      A  2011      8 2011-08-31  26.373390  23.781748          -0.004521   \n",
       "20      A  2011      9 2011-09-30  22.353361  20.156755          -0.007177   \n",
       "21      A  2011     10 2011-10-31  26.516453  23.910744           0.009367   \n",
       "22      A  2011     11 2011-11-30  26.824034  24.188101           0.001094   \n",
       "23      A  2011     12 2011-12-30  24.985695  22.530416          -0.003089   \n",
       "24      A  2012      1 2012-01-31  30.379112  27.393835           0.010027   \n",
       "25      A  2012      2 2012-02-29  31.201717  28.135605           0.001451   \n",
       "26      A  2012      3 2012-03-30  31.838341  28.774385           0.001156   \n",
       "27      A  2012      4 2012-04-30  30.171675  27.268116          -0.002481   \n",
       "28      A  2012      5 2012-05-31  29.084406  26.285479          -0.001500   \n",
       "29      A  2012      6 2012-06-29  28.068670  25.434919          -0.001276   \n",
       "30      A  2012      7 2012-07-31  27.389128  24.819136          -0.001000   \n",
       "31      A  2012      8 2012-08-31  26.580830  24.086683          -0.001078   \n",
       "32      A  2012      9 2012-09-28  27.503576  24.987616           0.002030   \n",
       "33      A  2012     10 2012-10-31  25.743919  23.388926          -0.003058   \n",
       "34      A  2012     11 2012-11-30  27.389128  24.883636           0.003127   \n",
       "35      A  2012     12 2012-12-31  29.284693  26.671030           0.003600   \n",
       "36      A  2013      1 2013-01-31  32.031475  29.172663           0.004341   \n",
       "37      A  2013      2 2013-02-28  29.670959  27.022825          -0.003888   \n",
       "38      A  2013      3 2013-03-28  30.021460  27.420221           0.000789   \n",
       "39      A  2013      4 2013-04-30  29.642345  27.073946          -0.000415   \n",
       "40      A  2013      5 2013-05-31  32.510731  29.693800           0.004295   \n",
       "41      A  2013      6 2013-06-28  30.586552  28.014383          -0.002819   \n",
       "42      A  2013      7 2013-07-31  31.995708  29.305031           0.002107   \n",
       "43      A  2013      8 2013-08-30  33.361946  30.556374           0.001957   \n",
       "44      A  2013      9 2013-09-30  36.659515  33.654156           0.004900   \n",
       "45      A  2013     10 2013-10-31  36.309013  33.332394          -0.000339   \n",
       "46      A  2013     11 2013-11-29  38.319027  35.177631           0.002915   \n",
       "47      A  2013     12 2013-12-31  40.908440  37.641235           0.003282   \n",
       "48      A  2014      1 2014-01-31  41.595135  38.273094           0.000897   \n",
       "49      A  2014      2 2014-02-28  40.722462  37.470112          -0.000823   \n",
       "\n",
       "    std_return_daily  skew_return_daily    Sharpe  prev_price    return  \\\n",
       "0           0.014345          -1.057651 -0.369864   20.040653 -0.097844   \n",
       "1           0.012060           0.795518  0.511000   18.079800  0.122369   \n",
       "2           0.009486           0.943496  0.413428   20.292213  0.093134   \n",
       "3           0.014793           0.484652  0.177654   22.182100  0.054376   \n",
       "4           0.032369           0.345697 -0.159907   23.388283 -0.107557   \n",
       "5           0.023612          -0.678421 -0.237074   20.872721 -0.121446   \n",
       "6           0.020241          -0.095339 -0.032066   18.337812 -0.017587   \n",
       "7           0.027381           1.112051 -0.045157   18.015299 -0.034372   \n",
       "8           0.018911           0.418899  0.547784   17.396082  0.237301   \n",
       "9           0.013007          -0.983643  0.160000   21.524183  0.042853   \n",
       "10          0.016767          -0.075015  0.025889   22.446566  0.006322   \n",
       "11          0.012241           0.452720  0.632311   22.588463  0.183038   \n",
       "12          0.016586          -1.215774  0.036945   26.723019  0.009655   \n",
       "13          0.026238          -0.276730  0.024438   26.981022  0.005977   \n",
       "14          0.026290           1.589836  0.115230   27.142279  0.064163   \n",
       "15          0.016409           0.475558  0.339112   28.883820  0.114560   \n",
       "16          0.016232           0.514109  0.005342   32.192753 -0.000801   \n",
       "17          0.019456          -0.178554  0.066708   32.166958  0.024865   \n",
       "18          0.020524          -0.284088 -0.456845   32.966778 -0.175113   \n",
       "19          0.051500          -0.335696 -0.087794   27.193878 -0.125474   \n",
       "20          0.037274           0.010767 -0.192555   23.781748 -0.152428   \n",
       "21          0.050285          -0.130691  0.186272   20.156755  0.186240   \n",
       "22          0.033704          -0.365538  0.032471   23.910744  0.011600   \n",
       "23          0.024370          -0.590230 -0.126739   24.188101 -0.068533   \n",
       "24          0.020942          -0.251102  0.478816   22.530416  0.215860   \n",
       "25          0.015591           1.193771  0.093057   27.393835  0.027078   \n",
       "26          0.016830           0.210213  0.068673   28.135605  0.022704   \n",
       "27          0.020689           0.042492 -0.119917   28.774385 -0.052348   \n",
       "28          0.018784           0.819410 -0.079841   27.268116 -0.036036   \n",
       "29          0.024521          -0.432317 -0.052053   26.285479 -0.032359   \n",
       "30          0.018667           0.009255 -0.053582   25.434919 -0.024210   \n",
       "31          0.021243          -2.407801 -0.050759   24.819136 -0.029512   \n",
       "32          0.014265           1.084984  0.142295   24.086683  0.037404   \n",
       "33          0.013322          -0.854400 -0.229559   24.987616 -0.063979   \n",
       "34          0.019133           0.457169  0.163445   23.388926  0.063907   \n",
       "35          0.016311           0.109464  0.220724   24.883636  0.071830   \n",
       "36          0.011486           0.460151  0.377920   26.671030  0.093796   \n",
       "37          0.016625          -1.208602 -0.233845   29.172663 -0.073694   \n",
       "38          0.011159          -0.319110  0.070744   27.022825  0.014706   \n",
       "39          0.018418          -0.323141 -0.022526   27.420221 -0.012628   \n",
       "40          0.013600           0.531282  0.315799   27.073946  0.096767   \n",
       "41          0.013544          -0.364063 -0.208150   29.693800 -0.056558   \n",
       "42          0.010980          -0.043075  0.191883   28.014383  0.046071   \n",
       "43          0.010727           0.960212  0.182432   29.305031  0.042701   \n",
       "44          0.011294           0.956637  0.433843   30.556374  0.101379   \n",
       "45          0.012836           0.171295 -0.026400   33.654156 -0.009561   \n",
       "46          0.021835           3.178360  0.133483   33.332394  0.055359   \n",
       "47          0.010612           1.008367  0.309251   35.177631  0.070033   \n",
       "48          0.014740          -0.237913  0.060830   37.641235  0.016786   \n",
       "49          0.024464          -2.053341 -0.033623   38.273094 -0.020980   \n",
       "\n",
       "    next_month_return  cum_ret6  cum_ret12         asset  netIncome_x  \\\n",
       "0            0.122369  0.207149   0.550332           NaN          NaN   \n",
       "1            0.093134  0.225078   1.268206           NaN          NaN   \n",
       "2            0.054376  0.235717   1.237475  7.574000e+09          NaN   \n",
       "3           -0.107557  0.465642   0.985761  7.574000e+09          NaN   \n",
       "4           -0.121446  0.118949   0.775096  7.574000e+09          NaN   \n",
       "5           -0.017587 -0.084969   0.399803  7.612000e+09          NaN   \n",
       "6           -0.034372 -0.003568   0.202842  7.612000e+09          NaN   \n",
       "7            0.237301 -0.142721   0.050233  7.612000e+09          NaN   \n",
       "8            0.042853 -0.029660   0.199065  7.612000e+09          NaN   \n",
       "9            0.006322 -0.040264   0.406629  9.100000e+09          NaN   \n",
       "10           0.183038  0.082200   0.210927  9.100000e+09          NaN   \n",
       "11           0.009655  0.457263   0.333440  7.612000e+09          NaN   \n",
       "12           0.005977  0.497673   0.492330  7.612000e+09          NaN   \n",
       "13           0.064163  0.560252   0.337571  7.612000e+09          NaN   \n",
       "14           0.114560  0.341924   0.302123  9.696000e+09          NaN   \n",
       "15          -0.000801  0.434195   0.376448  9.696000e+09          NaN   \n",
       "16           0.024865  0.424044   0.541100  9.696000e+09          NaN   \n",
       "17          -0.175113  0.233647   0.797749  8.649000e+09          NaN   \n",
       "18          -0.125474  0.007889   0.509488  8.649000e+09          NaN   \n",
       "19          -0.152428 -0.123812   0.367075  8.649000e+09          NaN   \n",
       "20           0.186240 -0.302144  -0.063530  9.696000e+09          NaN   \n",
       "21           0.011600 -0.257263   0.065229  9.696000e+09          NaN   \n",
       "22          -0.068533 -0.248045   0.070817  9.696000e+09          NaN   \n",
       "23           0.215860 -0.316572  -0.156891  9.696000e+09          NaN   \n",
       "24           0.027078  0.007353   0.015300  9.696000e+09          NaN   \n",
       "25           0.022704  0.183076   0.036597  9.696000e+09          NaN   \n",
       "26          -0.052348  0.427531  -0.003789  9.057000e+09          NaN   \n",
       "27          -0.036036  0.140413  -0.152973  9.057000e+09          NaN   \n",
       "28          -0.032359  0.086711  -0.182842  9.057000e+09          NaN   \n",
       "29          -0.024210  0.128915  -0.228468  9.413000e+09          NaN   \n",
       "30          -0.029512 -0.093988  -0.087326  9.413000e+09          NaN   \n",
       "31           0.037404 -0.143907   0.012822  9.413000e+09          NaN   \n",
       "32          -0.063979 -0.131602   0.239665  9.057000e+09          NaN   \n",
       "33           0.063907 -0.142261  -0.021824  9.057000e+09          NaN   \n",
       "34           0.071830 -0.053331   0.028755  9.057000e+09          NaN   \n",
       "35           0.093796  0.048599   0.183779  1.053600e+10          NaN   \n",
       "36          -0.073694  0.175410   0.064935  1.053600e+10          NaN   \n",
       "37           0.014706  0.121899  -0.039551  1.053600e+10          NaN   \n",
       "38          -0.012628  0.097352  -0.047061  1.053600e+10          NaN   \n",
       "39           0.096767  0.157554  -0.007121  1.053600e+10          NaN   \n",
       "40          -0.056558  0.193306   0.129666  1.053600e+10          NaN   \n",
       "41           0.046071  0.050368   0.101414  1.053600e+10          NaN   \n",
       "42           0.042701  0.004537   0.180743  1.053600e+10          NaN   \n",
       "43           0.101379  0.130762   0.268600  1.053600e+10          NaN   \n",
       "44          -0.009561  0.227348   0.346833  1.027800e+10          NaN   \n",
       "45           0.055359  0.231161   0.425136  1.027800e+10          NaN   \n",
       "46           0.070033  0.184679   0.413685  1.027800e+10          NaN   \n",
       "47           0.016786  0.343640   0.411315  1.053600e+10          NaN   \n",
       "48          -0.020980  0.306025   0.311951  1.053600e+10          NaN   \n",
       "49          -0.017741  0.226262   0.386610  1.053600e+10          NaN   \n",
       "\n",
       "    netIncome_y   liabilities  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN  5.098000e+09  \n",
       "3           NaN  5.098000e+09  \n",
       "4           NaN  5.098000e+09  \n",
       "5           NaN  5.098000e+09  \n",
       "6           NaN  5.098000e+09  \n",
       "7           NaN  5.098000e+09  \n",
       "8           NaN  5.098000e+09  \n",
       "9           NaN  5.098000e+09  \n",
       "10          NaN  5.098000e+09  \n",
       "11          NaN  6.460000e+09  \n",
       "12          NaN  6.460000e+09  \n",
       "13          NaN  6.460000e+09  \n",
       "14          NaN  4.705000e+09  \n",
       "15          NaN  4.705000e+09  \n",
       "16          NaN  4.705000e+09  \n",
       "17          NaN  4.688000e+09  \n",
       "18          NaN  4.688000e+09  \n",
       "19          NaN  4.688000e+09  \n",
       "20          NaN  4.553000e+09  \n",
       "21          NaN  4.553000e+09  \n",
       "22          NaN  4.553000e+09  \n",
       "23          NaN  4.741000e+09  \n",
       "24          NaN  4.741000e+09  \n",
       "25          NaN  4.741000e+09  \n",
       "26          NaN  4.600000e+09  \n",
       "27          NaN  4.600000e+09  \n",
       "28          NaN  4.600000e+09  \n",
       "29          NaN  4.741000e+09  \n",
       "30          NaN  4.741000e+09  \n",
       "31          NaN  4.741000e+09  \n",
       "32          NaN  4.741000e+09  \n",
       "33          NaN  4.741000e+09  \n",
       "34          NaN  4.741000e+09  \n",
       "35          NaN  4.741000e+09  \n",
       "36          NaN  4.741000e+09  \n",
       "37          NaN  4.741000e+09  \n",
       "38          NaN  5.302000e+09  \n",
       "39          NaN  5.302000e+09  \n",
       "40          NaN  5.302000e+09  \n",
       "41          NaN  5.351000e+09  \n",
       "42          NaN  5.351000e+09  \n",
       "43          NaN  5.351000e+09  \n",
       "44          NaN  5.488000e+09  \n",
       "45          NaN  5.488000e+09  \n",
       "46          NaN  5.488000e+09  \n",
       "47          NaN  5.397000e+09  \n",
       "48          NaN  5.397000e+09  \n",
       "49          NaN  5.397000e+09  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_liabilities_data4=all_liabilities_data3[(all_liabilities_data3['year'] >= 2010) & (all_liabilities_data3['year'] <= 2022)]\n",
    "all_liabilities_data4.sort_values(by=['symbol','year','month'])\n",
    "final_data1 = pd.merge(final_data1, all_liabilities_data4, how='left', on=['symbol', 'year', 'month'])\n",
    "final_data2 = final_data1[(final_data1['year'] >= 2010) & (final_data1['year'] <= 2022)]\n",
    "final_data2 = final_data2.fillna(method='ffill').reset_index()\n",
    "\n",
    "final_data2.drop(columns=['index'],inplace=True)\n",
    "final_data2.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: A\n",
      "Data processed successfully for symbol: AAL\n",
      "Data processed successfully for symbol: AAPL\n",
      "Data processed successfully for symbol: ABBV\n",
      "Data processed successfully for symbol: ABNB\n",
      "Data processed successfully for symbol: ABT\n",
      "Failed to fetch data for symbol: ACGL\n",
      "Data processed successfully for symbol: ACN\n",
      "Data processed successfully for symbol: ADBE\n",
      "Data processed successfully for symbol: ADI\n",
      "Data processed successfully for symbol: ADM\n",
      "Data processed successfully for symbol: ADP\n",
      "Data processed successfully for symbol: ADSK\n",
      "Data processed successfully for symbol: AEE\n",
      "Data processed successfully for symbol: AEP\n",
      "Data processed successfully for symbol: AES\n",
      "Failed to fetch data for symbol: AFL\n",
      "Failed to fetch data for symbol: AIG\n",
      "Failed to fetch data for symbol: AIZ\n",
      "Data processed successfully for symbol: AJG\n",
      "Data processed successfully for symbol: AKAM\n",
      "Data processed successfully for symbol: ALB\n",
      "Data processed successfully for symbol: ALGN\n",
      "Data processed successfully for symbol: ALK\n",
      "Failed to fetch data for symbol: ALL\n",
      "Data processed successfully for symbol: ALLE\n",
      "Data processed successfully for symbol: AMAT\n",
      "Data processed successfully for symbol: AMCR\n",
      "Data processed successfully for symbol: AMD\n",
      "Data processed successfully for symbol: AME\n",
      "Data processed successfully for symbol: AMGN\n",
      "Failed to fetch data for symbol: AMP\n",
      "Data processed successfully for symbol: AMT\n",
      "Data processed successfully for symbol: AMZN\n",
      "Data processed successfully for symbol: ANET\n",
      "Data processed successfully for symbol: ANSS\n",
      "Data processed successfully for symbol: AON\n",
      "Data processed successfully for symbol: AOS\n",
      "Data processed successfully for symbol: APA\n",
      "Data processed successfully for symbol: APD\n",
      "Data processed successfully for symbol: APH\n",
      "Data processed successfully for symbol: APTV\n",
      "Failed to fetch data for symbol: ARE\n",
      "Data processed successfully for symbol: ATO\n",
      "Failed to fetch data for symbol: AVB\n",
      "Data processed successfully for symbol: AVGO\n",
      "Data processed successfully for symbol: AVY\n",
      "Data processed successfully for symbol: AWK\n",
      "Data processed successfully for symbol: AXON\n",
      "Failed to fetch data for symbol: AXP\n",
      "Data processed successfully for symbol: AZO\n",
      "Data processed successfully for symbol: BA\n",
      "Failed to fetch data for symbol: BAC\n",
      "Data processed successfully for symbol: BALL\n",
      "Data processed successfully for symbol: BAX\n",
      "Data processed successfully for symbol: BBWI\n",
      "Data processed successfully for symbol: BBY\n",
      "Data processed successfully for symbol: BDX\n",
      "Data processed successfully for symbol: BEN\n",
      "Failed to fetch data for symbol: BG\n",
      "Data processed successfully for symbol: BIIB\n",
      "Data processed successfully for symbol: BIO\n",
      "Failed to fetch data for symbol: BK\n",
      "Data processed successfully for symbol: BKNG\n",
      "Data processed successfully for symbol: BKR\n",
      "Failed to fetch data for symbol: BLK\n",
      "Data processed successfully for symbol: BMY\n",
      "Data processed successfully for symbol: BR\n",
      "Data processed successfully for symbol: BRO\n",
      "Data processed successfully for symbol: BSX\n",
      "Data processed successfully for symbol: BWA\n",
      "Failed to fetch data for symbol: BX\n",
      "Failed to fetch data for symbol: BXP\n",
      "Failed to fetch data for symbol: C\n",
      "Data processed successfully for symbol: CAG\n",
      "Data processed successfully for symbol: CAH\n",
      "Data processed successfully for symbol: CARR\n",
      "Data processed successfully for symbol: CAT\n",
      "Failed to fetch data for symbol: CB\n",
      "Data processed successfully for symbol: CBOE\n",
      "Data processed successfully for symbol: CBRE\n",
      "Data processed successfully for symbol: CCI\n",
      "Data processed successfully for symbol: CCL\n",
      "Data processed successfully for symbol: CDAY\n",
      "Data processed successfully for symbol: CDNS\n",
      "Data processed successfully for symbol: CDW\n",
      "Data processed successfully for symbol: CE\n",
      "Data processed successfully for symbol: CF\n",
      "Failed to fetch data for symbol: CFG\n",
      "Data processed successfully for symbol: CHD\n",
      "Data processed successfully for symbol: CHRW\n",
      "Data processed successfully for symbol: CHTR\n",
      "Data processed successfully for symbol: CI\n",
      "Failed to fetch data for symbol: CINF\n",
      "Data processed successfully for symbol: CL\n",
      "Data processed successfully for symbol: CLX\n",
      "Failed to fetch data for symbol: CMA\n",
      "Data processed successfully for symbol: CMCSA\n",
      "Data processed successfully for symbol: CME\n",
      "Data processed successfully for symbol: CMG\n",
      "Data processed successfully for symbol: CMI\n",
      "Data processed successfully for symbol: CMS\n",
      "Data processed successfully for symbol: CNC\n",
      "Data processed successfully for symbol: CNP\n",
      "Failed to fetch data for symbol: COF\n",
      "Data processed successfully for symbol: COO\n",
      "Data processed successfully for symbol: COP\n",
      "Data processed successfully for symbol: COR\n",
      "Data processed successfully for symbol: COST\n",
      "Data processed successfully for symbol: CPB\n",
      "Data processed successfully for symbol: CPRT\n",
      "Failed to fetch data for symbol: CPT\n",
      "Data processed successfully for symbol: CRL\n",
      "Data processed successfully for symbol: CRM\n",
      "Data processed successfully for symbol: CSCO\n",
      "Data processed successfully for symbol: CSGP\n",
      "Data processed successfully for symbol: CSX\n",
      "Data processed successfully for symbol: CTAS\n",
      "Data processed successfully for symbol: CTLT\n",
      "Data processed successfully for symbol: CTRA\n",
      "Data processed successfully for symbol: CTSH\n",
      "Data processed successfully for symbol: CTVA\n",
      "Data processed successfully for symbol: CVS\n",
      "Data processed successfully for symbol: CVX\n",
      "Data processed successfully for symbol: CZR\n",
      "Data processed successfully for symbol: D\n",
      "Data processed successfully for symbol: DAL\n",
      "Data processed successfully for symbol: DD\n",
      "Failed to fetch data for symbol: DE\n",
      "Failed to fetch data for symbol: DFS\n",
      "Data processed successfully for symbol: DG\n",
      "Data processed successfully for symbol: DGX\n",
      "Failed to fetch data for symbol: DHI\n",
      "Data processed successfully for symbol: DHR\n",
      "Data processed successfully for symbol: DIS\n",
      "Failed to fetch data for symbol: DLR\n",
      "Data processed successfully for symbol: DLTR\n",
      "Data processed successfully for symbol: DOV\n",
      "Data processed successfully for symbol: DOW\n",
      "Data processed successfully for symbol: DPZ\n",
      "Data processed successfully for symbol: DRI\n",
      "Data processed successfully for symbol: DTE\n",
      "Data processed successfully for symbol: DUK\n",
      "Data processed successfully for symbol: DVA\n",
      "Data processed successfully for symbol: DVN\n",
      "Data processed successfully for symbol: DXCM\n",
      "Data processed successfully for symbol: EA\n",
      "Data processed successfully for symbol: EBAY\n",
      "Data processed successfully for symbol: ECL\n",
      "Data processed successfully for symbol: ED\n",
      "Data processed successfully for symbol: EFX\n",
      "Failed to fetch data for symbol: EG\n",
      "Data processed successfully for symbol: EIX\n",
      "Data processed successfully for symbol: EL\n",
      "Data processed successfully for symbol: ELV\n",
      "Data processed successfully for symbol: EMN\n",
      "Data processed successfully for symbol: EMR\n",
      "Data processed successfully for symbol: ENPH\n",
      "Data processed successfully for symbol: EOG\n",
      "Data processed successfully for symbol: EPAM\n",
      "Data processed successfully for symbol: EQIX\n",
      "Failed to fetch data for symbol: EQR\n",
      "Data processed successfully for symbol: EQT\n",
      "Data processed successfully for symbol: ES\n",
      "Failed to fetch data for symbol: ESS\n",
      "Data processed successfully for symbol: ETN\n",
      "Data processed successfully for symbol: ETR\n",
      "Data processed successfully for symbol: ETSY\n",
      "Data processed successfully for symbol: EVRG\n",
      "Data processed successfully for symbol: EW\n",
      "Data processed successfully for symbol: EXC\n",
      "Data processed successfully for symbol: EXPD\n",
      "Data processed successfully for symbol: EXPE\n",
      "Failed to fetch data for symbol: EXR\n",
      "Data processed successfully for symbol: F\n",
      "Data processed successfully for symbol: FANG\n",
      "Data processed successfully for symbol: FAST\n",
      "Data processed successfully for symbol: FCX\n",
      "Data processed successfully for symbol: FDS\n",
      "Data processed successfully for symbol: FDX\n",
      "Data processed successfully for symbol: FE\n",
      "Data processed successfully for symbol: FFIV\n",
      "Data processed successfully for symbol: FI\n",
      "Data processed successfully for symbol: FICO\n",
      "Data processed successfully for symbol: FIS\n",
      "Failed to fetch data for symbol: FITB\n",
      "Data processed successfully for symbol: FLT\n",
      "Data processed successfully for symbol: FMC\n",
      "Data processed successfully for symbol: FOX\n",
      "Data processed successfully for symbol: FOXA\n",
      "Failed to fetch data for symbol: FRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: FSLR\n",
      "Data processed successfully for symbol: FTNT\n",
      "Data processed successfully for symbol: FTV\n",
      "Data processed successfully for symbol: GD\n",
      "Data processed successfully for symbol: GE\n",
      "Data processed successfully for symbol: GEN\n",
      "Data processed successfully for symbol: GILD\n",
      "Data processed successfully for symbol: GIS\n",
      "Failed to fetch data for symbol: GL\n",
      "Data processed successfully for symbol: GLW\n",
      "Data processed successfully for symbol: GM\n",
      "Data processed successfully for symbol: GNRC\n",
      "Data processed successfully for symbol: GOOG\n",
      "Data processed successfully for symbol: GOOGL\n",
      "Data processed successfully for symbol: GPC\n",
      "Data processed successfully for symbol: GPN\n",
      "Data processed successfully for symbol: GRMN\n",
      "Failed to fetch data for symbol: GS\n",
      "Data processed successfully for symbol: GWW\n",
      "Data processed successfully for symbol: HAL\n",
      "Data processed successfully for symbol: HAS\n",
      "Failed to fetch data for symbol: HBAN\n",
      "Data processed successfully for symbol: HCA\n",
      "Data processed successfully for symbol: HD\n",
      "Data processed successfully for symbol: HES\n",
      "Failed to fetch data for symbol: HIG\n",
      "Data processed successfully for symbol: HII\n",
      "Data processed successfully for symbol: HLT\n",
      "Data processed successfully for symbol: HOLX\n",
      "Data processed successfully for symbol: HON\n",
      "Data processed successfully for symbol: HPE\n",
      "Data processed successfully for symbol: HPQ\n",
      "Data processed successfully for symbol: HRL\n",
      "Data processed successfully for symbol: HSIC\n",
      "Failed to fetch data for symbol: HST\n",
      "Data processed successfully for symbol: HSY\n",
      "Data processed successfully for symbol: HUBB\n",
      "Data processed successfully for symbol: HUM\n",
      "Data processed successfully for symbol: HWM\n",
      "Data processed successfully for symbol: IBM\n",
      "Data processed successfully for symbol: ICE\n",
      "Data processed successfully for symbol: IDXX\n",
      "Data processed successfully for symbol: IEX\n",
      "Data processed successfully for symbol: IFF\n",
      "Data processed successfully for symbol: ILMN\n",
      "Data processed successfully for symbol: INCY\n",
      "Data processed successfully for symbol: INTC\n",
      "Data processed successfully for symbol: INTU\n",
      "Failed to fetch data for symbol: INVH\n",
      "Data processed successfully for symbol: IP\n",
      "Data processed successfully for symbol: IPG\n",
      "Data processed successfully for symbol: IQV\n",
      "Data processed successfully for symbol: IR\n",
      "Data processed successfully for symbol: IRM\n",
      "Data processed successfully for symbol: ISRG\n",
      "Data processed successfully for symbol: IT\n",
      "Data processed successfully for symbol: ITW\n",
      "Data processed successfully for symbol: IVZ\n",
      "Data processed successfully for symbol: J\n",
      "Data processed successfully for symbol: JBHT\n",
      "Data processed successfully for symbol: JCI\n",
      "Data processed successfully for symbol: JKHY\n",
      "Data processed successfully for symbol: JNJ\n",
      "Data processed successfully for symbol: JNPR\n",
      "Failed to fetch data for symbol: JPM\n",
      "Data processed successfully for symbol: K\n",
      "Data processed successfully for symbol: KDP\n",
      "Failed to fetch data for symbol: KEY\n",
      "Data processed successfully for symbol: KEYS\n",
      "Data processed successfully for symbol: KHC\n",
      "Failed to fetch data for symbol: KIM\n",
      "Data processed successfully for symbol: KLAC\n",
      "Data processed successfully for symbol: KMB\n",
      "Data processed successfully for symbol: KMI\n",
      "Data processed successfully for symbol: KMX\n",
      "Data processed successfully for symbol: KO\n",
      "Data processed successfully for symbol: KR\n",
      "Failed to fetch data for symbol: L\n",
      "Data processed successfully for symbol: LDOS\n",
      "Failed to fetch data for symbol: LEN\n",
      "Data processed successfully for symbol: LH\n",
      "Data processed successfully for symbol: LHX\n",
      "Data processed successfully for symbol: LIN\n",
      "Data processed successfully for symbol: LKQ\n",
      "Data processed successfully for symbol: LLY\n",
      "Data processed successfully for symbol: LMT\n",
      "Data processed successfully for symbol: LNT\n",
      "Data processed successfully for symbol: LOW\n",
      "Data processed successfully for symbol: LRCX\n",
      "Data processed successfully for symbol: LULU\n",
      "Data processed successfully for symbol: LUV\n",
      "Data processed successfully for symbol: LVS\n",
      "Data processed successfully for symbol: LW\n",
      "Data processed successfully for symbol: LYB\n",
      "Data processed successfully for symbol: LYV\n",
      "Data processed successfully for symbol: MA\n",
      "Failed to fetch data for symbol: MAA\n",
      "Data processed successfully for symbol: MAR\n",
      "Data processed successfully for symbol: MAS\n",
      "Data processed successfully for symbol: MCD\n",
      "Data processed successfully for symbol: MCHP\n",
      "Data processed successfully for symbol: MCK\n",
      "Data processed successfully for symbol: MCO\n",
      "Data processed successfully for symbol: MDLZ\n",
      "Data processed successfully for symbol: MDT\n",
      "Failed to fetch data for symbol: MET\n",
      "Data processed successfully for symbol: META\n",
      "Data processed successfully for symbol: MGM\n",
      "Data processed successfully for symbol: MHK\n",
      "Data processed successfully for symbol: MKC\n",
      "Failed to fetch data for symbol: MKTX\n",
      "Data processed successfully for symbol: MLM\n",
      "Data processed successfully for symbol: MMC\n",
      "Data processed successfully for symbol: MMM\n",
      "Data processed successfully for symbol: MNST\n",
      "Data processed successfully for symbol: MO\n",
      "Data processed successfully for symbol: MOH\n",
      "Data processed successfully for symbol: MOS\n",
      "Data processed successfully for symbol: MPC\n",
      "Data processed successfully for symbol: MPWR\n",
      "Data processed successfully for symbol: MRK\n",
      "Data processed successfully for symbol: MRNA\n",
      "Data processed successfully for symbol: MRO\n",
      "Failed to fetch data for symbol: MS\n",
      "Data processed successfully for symbol: MSCI\n",
      "Data processed successfully for symbol: MSFT\n",
      "Data processed successfully for symbol: MSI\n",
      "Failed to fetch data for symbol: MTB\n",
      "Data processed successfully for symbol: MTCH\n",
      "Data processed successfully for symbol: MTD\n",
      "Data processed successfully for symbol: MU\n",
      "Data processed successfully for symbol: NCLH\n",
      "Data processed successfully for symbol: NDAQ\n",
      "Data processed successfully for symbol: NDSN\n",
      "Data processed successfully for symbol: NEE\n",
      "Data processed successfully for symbol: NEM\n",
      "Data processed successfully for symbol: NFLX\n",
      "Data processed successfully for symbol: NI\n",
      "Data processed successfully for symbol: NKE\n",
      "Data processed successfully for symbol: NOC\n",
      "Data processed successfully for symbol: NOW\n",
      "Data processed successfully for symbol: NRG\n",
      "Data processed successfully for symbol: NSC\n",
      "Data processed successfully for symbol: NTAP\n",
      "Failed to fetch data for symbol: NTRS\n",
      "Data processed successfully for symbol: NUE\n",
      "Data processed successfully for symbol: NVDA\n",
      "Failed to fetch data for symbol: NVR\n",
      "Data processed successfully for symbol: NWS\n",
      "Data processed successfully for symbol: NWSA\n",
      "Data processed successfully for symbol: NXPI\n",
      "Failed to fetch data for symbol: O\n",
      "Data processed successfully for symbol: ODFL\n",
      "Data processed successfully for symbol: OKE\n",
      "Data processed successfully for symbol: OMC\n",
      "Data processed successfully for symbol: ON\n",
      "Data processed successfully for symbol: ORCL\n",
      "Data processed successfully for symbol: ORLY\n",
      "Data processed successfully for symbol: OTIS\n",
      "Data processed successfully for symbol: OXY\n",
      "Data processed successfully for symbol: PANW\n",
      "Data processed successfully for symbol: PARA\n",
      "Data processed successfully for symbol: PAYC\n",
      "Data processed successfully for symbol: PAYX\n",
      "Failed to fetch data for symbol: PCAR\n",
      "Data processed successfully for symbol: PCG\n",
      "Failed to fetch data for symbol: PEAK\n",
      "Data processed successfully for symbol: PEG\n",
      "Data processed successfully for symbol: PEP\n",
      "Data processed successfully for symbol: PFE\n",
      "Failed to fetch data for symbol: PFG\n",
      "Data processed successfully for symbol: PG\n",
      "Failed to fetch data for symbol: PGR\n",
      "Data processed successfully for symbol: PH\n",
      "Failed to fetch data for symbol: PHM\n",
      "Data processed successfully for symbol: PKG\n",
      "Failed to fetch data for symbol: PLD\n",
      "Data processed successfully for symbol: PM\n",
      "Failed to fetch data for symbol: PNC\n",
      "Data processed successfully for symbol: PNR\n",
      "Data processed successfully for symbol: PNW\n",
      "Data processed successfully for symbol: PODD\n",
      "Data processed successfully for symbol: POOL\n",
      "Data processed successfully for symbol: PPG\n",
      "Data processed successfully for symbol: PPL\n",
      "Failed to fetch data for symbol: PRU\n",
      "Failed to fetch data for symbol: PSA\n",
      "Data processed successfully for symbol: PSX\n",
      "Data processed successfully for symbol: PTC\n",
      "Data processed successfully for symbol: PWR\n",
      "Data processed successfully for symbol: PXD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: PYPL\n",
      "Data processed successfully for symbol: QCOM\n",
      "Data processed successfully for symbol: QRVO\n",
      "Data processed successfully for symbol: RCL\n",
      "Failed to fetch data for symbol: REG\n",
      "Data processed successfully for symbol: REGN\n",
      "Failed to fetch data for symbol: RF\n",
      "Data processed successfully for symbol: RHI\n",
      "Failed to fetch data for symbol: RJF\n",
      "Data processed successfully for symbol: RL\n",
      "Data processed successfully for symbol: RMD\n",
      "Data processed successfully for symbol: ROK\n",
      "Data processed successfully for symbol: ROL\n",
      "Data processed successfully for symbol: ROP\n",
      "Data processed successfully for symbol: ROST\n",
      "Data processed successfully for symbol: RSG\n",
      "Data processed successfully for symbol: RTX\n",
      "Data processed successfully for symbol: RVTY\n",
      "Data processed successfully for symbol: SBAC\n",
      "Data processed successfully for symbol: SBUX\n",
      "Failed to fetch data for symbol: SCHW\n",
      "Data processed successfully for symbol: SEDG\n",
      "Data processed successfully for symbol: SEE\n",
      "Data processed successfully for symbol: SHW\n",
      "Data processed successfully for symbol: SJM\n",
      "Data processed successfully for symbol: SLB\n",
      "Data processed successfully for symbol: SNA\n",
      "Data processed successfully for symbol: SNPS\n",
      "Data processed successfully for symbol: SO\n",
      "Failed to fetch data for symbol: SPG\n",
      "Data processed successfully for symbol: SPGI\n",
      "Data processed successfully for symbol: SRE\n",
      "Data processed successfully for symbol: STE\n",
      "Data processed successfully for symbol: STLD\n",
      "Failed to fetch data for symbol: STT\n",
      "Data processed successfully for symbol: STX\n",
      "Data processed successfully for symbol: STZ\n",
      "Data processed successfully for symbol: SWK\n",
      "Data processed successfully for symbol: SWKS\n",
      "Failed to fetch data for symbol: SYF\n",
      "Data processed successfully for symbol: SYK\n",
      "Data processed successfully for symbol: SYY\n",
      "Data processed successfully for symbol: T\n",
      "Data processed successfully for symbol: TAP\n",
      "Data processed successfully for symbol: TDG\n",
      "Data processed successfully for symbol: TDY\n",
      "Data processed successfully for symbol: TECH\n",
      "Data processed successfully for symbol: TEL\n",
      "Data processed successfully for symbol: TER\n",
      "Failed to fetch data for symbol: TFC\n",
      "Data processed successfully for symbol: TFX\n",
      "Data processed successfully for symbol: TGT\n",
      "Data processed successfully for symbol: TJX\n",
      "Data processed successfully for symbol: TMO\n",
      "Data processed successfully for symbol: TMUS\n",
      "Data processed successfully for symbol: TPR\n",
      "Data processed successfully for symbol: TRGP\n",
      "Data processed successfully for symbol: TRMB\n",
      "Failed to fetch data for symbol: TROW\n",
      "Failed to fetch data for symbol: TRV\n",
      "Data processed successfully for symbol: TSCO\n",
      "Data processed successfully for symbol: TSLA\n",
      "Data processed successfully for symbol: TSN\n",
      "Data processed successfully for symbol: TT\n",
      "Data processed successfully for symbol: TTWO\n",
      "Data processed successfully for symbol: TXN\n",
      "Failed to fetch data for symbol: TXT\n",
      "Data processed successfully for symbol: TYL\n",
      "Data processed successfully for symbol: UAL\n",
      "Failed to fetch data for symbol: UDR\n",
      "Data processed successfully for symbol: UHS\n",
      "Data processed successfully for symbol: ULTA\n",
      "Data processed successfully for symbol: UNH\n",
      "Data processed successfully for symbol: UNP\n",
      "Data processed successfully for symbol: UPS\n",
      "Data processed successfully for symbol: URI\n",
      "Failed to fetch data for symbol: USB\n",
      "Data processed successfully for symbol: V\n",
      "Data processed successfully for symbol: VFC\n",
      "Failed to fetch data for symbol: VICI\n",
      "Data processed successfully for symbol: VLO\n",
      "Data processed successfully for symbol: VMC\n",
      "Data processed successfully for symbol: VRSK\n",
      "Data processed successfully for symbol: VRSN\n",
      "Data processed successfully for symbol: VRTX\n",
      "Failed to fetch data for symbol: VTR\n",
      "Data processed successfully for symbol: VTRS\n",
      "Data processed successfully for symbol: VZ\n",
      "Data processed successfully for symbol: WAB\n",
      "Data processed successfully for symbol: WAT\n",
      "Data processed successfully for symbol: WBA\n",
      "Data processed successfully for symbol: WBD\n",
      "Data processed successfully for symbol: WDC\n",
      "Data processed successfully for symbol: WEC\n",
      "Failed to fetch data for symbol: WELL\n",
      "Failed to fetch data for symbol: WFC\n",
      "Data processed successfully for symbol: WHR\n",
      "Data processed successfully for symbol: WM\n",
      "Data processed successfully for symbol: WMB\n",
      "Data processed successfully for symbol: WMT\n",
      "Failed to fetch data for symbol: WRB\n",
      "Data processed successfully for symbol: WRK\n",
      "Data processed successfully for symbol: WST\n",
      "Data processed successfully for symbol: WTW\n",
      "Data processed successfully for symbol: WY\n",
      "Data processed successfully for symbol: WYNN\n",
      "Data processed successfully for symbol: XEL\n",
      "Data processed successfully for symbol: XOM\n",
      "Data processed successfully for symbol: XRAY\n",
      "Data processed successfully for symbol: XYL\n",
      "Data processed successfully for symbol: YUM\n",
      "Data processed successfully for symbol: ZBH\n",
      "Data processed successfully for symbol: ZBRA\n",
      "Failed to fetch data for symbol: ZION\n",
      "Data processed successfully for symbol: ZTS\n",
      "Data concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "all_ac_data = pd.DataFrame()\n",
    "\n",
    "for symb in symbols:\n",
    "    _cik = companyData[companyData['ticker'] == symb]['cik_str10']\n",
    "    \n",
    "    # Check if CIK is available\n",
    "    if not _cik.empty:\n",
    "        cik = _cik.iloc[0]\n",
    "        \n",
    "        # Fetch company facts\n",
    "        companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json', headers=headers)\n",
    "        \n",
    "        # Check if the request is successful and has the expected structure\n",
    "        if companyFacts.status_code == 200 and 'facts' in companyFacts.json().keys() and 'us-gaap' in companyFacts.json()['facts'].keys() and 'AssetsCurrent' in companyFacts.json()['facts']['us-gaap'].keys():\n",
    "            \n",
    "            # Extract ac data and create DataFrame\n",
    "            ac_data = companyFacts.json()['facts']['us-gaap']['AssetsCurrent']['units']['USD']\n",
    "            ac = pd.DataFrame.from_dict(ac_data)\n",
    "            ac['symbol'] = symb\n",
    "            \n",
    "            # Concatenate directly to the existing DataFrame\n",
    "            all_ac_data = pd.concat([all_ac_data, ac], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data processed successfully for symbol: {symb}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for symbol: {symb}\")\n",
    "    else:\n",
    "        print(f\"CIK not available for symbol: {symb}\")\n",
    "\n",
    "# Check if there is data\n",
    "if not all_ac_data.empty:\n",
    "    print(\"Data concatenated successfully.\")\n",
    "    # Further processing or analysis can be done with 'all_ac_data'\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              end         val                  accn      fy  fp    form  \\\n",
      "0      2008-10-31  3182000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "1      2008-10-31  3182000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "2      2008-10-31  3182000000  0001104659-10-047478  2009.0  FY     8-K   \n",
      "3      2009-07-31  2897000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "4      2009-10-31  3961000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "...           ...         ...                   ...     ...  ..     ...   \n",
      "45200  2022-12-31  7506000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "45201  2022-12-31  7506000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "45202  2023-03-31  6269000000  0001555280-23-000150  2023.0  Q1    10-Q   \n",
      "45203  2023-06-30  6183000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "45204  2023-09-30  6222000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "\n",
      "            filed      frame symbol  \n",
      "0      2009-10-05        NaN      A  \n",
      "1      2009-12-21        NaN      A  \n",
      "2      2010-09-07  CY2008Q3I      A  \n",
      "3      2009-10-05  CY2009Q2I      A  \n",
      "4      2009-12-21        NaN      A  \n",
      "...           ...        ...    ...  \n",
      "45200  2023-08-08        NaN    ZTS  \n",
      "45201  2023-11-02  CY2022Q4I    ZTS  \n",
      "45202  2023-05-04  CY2023Q1I    ZTS  \n",
      "45203  2023-08-08  CY2023Q2I    ZTS  \n",
      "45204  2023-11-02  CY2023Q3I    ZTS  \n",
      "\n",
      "[45205 rows x 9 columns]\n",
      "Data processed successfully.\n",
      "       year  month  currentAsset symbol\n",
      "0      2009     12    3182000000      A\n",
      "1      2010      3    3961000000      A\n",
      "2      2010      6    3961000000      A\n",
      "3      2010     12    6169000000      A\n",
      "4      2011      3    6169000000      A\n",
      "...     ...    ...           ...    ...\n",
      "21622  2022     11    6551000000    ZTS\n",
      "21623  2023      2    7506000000    ZTS\n",
      "21624  2023      5    7506000000    ZTS\n",
      "21625  2023      8    6183000000    ZTS\n",
      "21626  2023     11    7506000000    ZTS\n",
      "\n",
      "[21627 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "    print(all_ac_data)\n",
    "    all_ac_data = all_ac_data[all_ac_data['form'].isin(['10-K', '10-Q'])]\n",
    "    all_ac_data['filed1'] = pd.to_datetime(all_ac_data['filed'])\n",
    "    all_ac_data['year'] = all_ac_data['filed1'].dt.year\n",
    "    all_ac_data['month'] = all_ac_data['filed1'].dt.month\n",
    "    all_ac_data['day'] = all_ac_data['filed1'].dt.day\n",
    "    \n",
    "    all_ac_data2 = all_ac_data.sort_values(by='filed1')\n",
    "    all_ac_data2 = all_ac_data2.groupby(['symbol','year', 'month']).first().reset_index()\n",
    "    \n",
    "    features = ['year', 'month', 'val', 'symbol']\n",
    "    all_ac_data3 = all_ac_data2[features].copy()\n",
    "    all_ac_data3.rename(columns={'val': 'currentAsset'}, inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"Data processed successfully.\")\n",
    "    print(all_ac_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "      <th>netIncome_x</th>\n",
       "      <th>netIncome_y</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>currentAsset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>20.336195</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>-0.678421</td>\n",
       "      <td>-0.237074</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>19.978540</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>-0.003568</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>19.291845</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>1.112051</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>-0.142721</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>23.869814</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.547784</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>-0.029660</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>24.892704</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.983643</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>25.050072</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>29.635193</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.632311</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.333440</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-1.215774</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>30.100143</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.026238</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>1.589836</td>\n",
       "      <td>0.115230</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>35.701000</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.339112</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>35.672390</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.424044</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>36.559372</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>30.157368</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.284088</td>\n",
       "      <td>-0.456845</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>26.373390</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.335696</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>22.353361</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.192555</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>-0.302144</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>26.516453</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.130691</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2011-11-30</td>\n",
       "      <td>26.824034</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.365538</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.070817</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>24.985695</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>-0.590230</td>\n",
       "      <td>-0.126739</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>-0.316572</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>30.379112</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.251102</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>31.201717</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>1.193771</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>31.838341</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.210213</td>\n",
       "      <td>0.068673</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>30.171675</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>-0.119917</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>-0.152973</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>29.084406</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>-0.079841</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>-0.182842</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>28.068670</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.052053</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.228468</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>26.580830</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-2.407801</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.143907</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>27.503576</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.084984</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.131602</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>25.743919</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.854400</td>\n",
       "      <td>-0.229559</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.142261</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>29.284693</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.109464</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.175410</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>29.670959</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-1.208602</td>\n",
       "      <td>-0.233845</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.121899</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>30.021460</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>-0.047061</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>29.642345</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>0.157554</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>32.510731</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.531282</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.193306</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>30.586552</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>-0.364063</td>\n",
       "      <td>-0.208150</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>31.995708</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.191883</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>33.361946</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>36.659515</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.956637</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.346833</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>36.309013</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.171295</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>38.319027</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>3.178360</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>40.908440</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>1.008367</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>41.595135</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>-0.237913</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>37.470112</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>-2.053341</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.386610</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0       A  2010      1 2010-01-29  20.050072  18.079800          -0.005306   \n",
       "1       A  2010      2 2010-02-26  22.503576  20.292213           0.006162   \n",
       "2       A  2010      3 2010-03-31  24.599428  22.182100           0.003922   \n",
       "3       A  2010      4 2010-04-30  25.937054  23.388283           0.002628   \n",
       "4       A  2010      5 2010-05-28  23.147352  20.872721          -0.005176   \n",
       "5       A  2010      6 2010-06-30  20.336195  18.337812          -0.005598   \n",
       "6       A  2010      7 2010-07-30  19.978540  18.015299          -0.000649   \n",
       "7       A  2010      8 2010-08-31  19.291845  17.396082          -0.001236   \n",
       "8       A  2010      9 2010-09-30  23.869814  21.524183           0.010359   \n",
       "9       A  2010     10 2010-10-29  24.892704  22.446566           0.002081   \n",
       "10      A  2010     11 2010-11-30  25.050072  22.588463           0.000434   \n",
       "11      A  2010     12 2010-12-31  29.635193  26.723019           0.007740   \n",
       "12      A  2011      1 2011-01-31  29.921316  26.981022           0.000613   \n",
       "13      A  2011      2 2011-02-28  30.100143  27.142279           0.000641   \n",
       "14      A  2011      3 2011-03-31  32.031475  28.883820           0.003029   \n",
       "15      A  2011      4 2011-04-29  35.701000  32.192753           0.005564   \n",
       "16      A  2011      5 2011-05-31  35.672390  32.166958           0.000087   \n",
       "17      A  2011      6 2011-06-30  36.559372  32.966778           0.001298   \n",
       "18      A  2011      7 2011-07-29  30.157368  27.193878          -0.009376   \n",
       "19      A  2011      8 2011-08-31  26.373390  23.781748          -0.004521   \n",
       "20      A  2011      9 2011-09-30  22.353361  20.156755          -0.007177   \n",
       "21      A  2011     10 2011-10-31  26.516453  23.910744           0.009367   \n",
       "22      A  2011     11 2011-11-30  26.824034  24.188101           0.001094   \n",
       "23      A  2011     12 2011-12-30  24.985695  22.530416          -0.003089   \n",
       "24      A  2012      1 2012-01-31  30.379112  27.393835           0.010027   \n",
       "25      A  2012      2 2012-02-29  31.201717  28.135605           0.001451   \n",
       "26      A  2012      3 2012-03-30  31.838341  28.774385           0.001156   \n",
       "27      A  2012      4 2012-04-30  30.171675  27.268116          -0.002481   \n",
       "28      A  2012      5 2012-05-31  29.084406  26.285479          -0.001500   \n",
       "29      A  2012      6 2012-06-29  28.068670  25.434919          -0.001276   \n",
       "30      A  2012      7 2012-07-31  27.389128  24.819136          -0.001000   \n",
       "31      A  2012      8 2012-08-31  26.580830  24.086683          -0.001078   \n",
       "32      A  2012      9 2012-09-28  27.503576  24.987616           0.002030   \n",
       "33      A  2012     10 2012-10-31  25.743919  23.388926          -0.003058   \n",
       "34      A  2012     11 2012-11-30  27.389128  24.883636           0.003127   \n",
       "35      A  2012     12 2012-12-31  29.284693  26.671030           0.003600   \n",
       "36      A  2013      1 2013-01-31  32.031475  29.172663           0.004341   \n",
       "37      A  2013      2 2013-02-28  29.670959  27.022825          -0.003888   \n",
       "38      A  2013      3 2013-03-28  30.021460  27.420221           0.000789   \n",
       "39      A  2013      4 2013-04-30  29.642345  27.073946          -0.000415   \n",
       "40      A  2013      5 2013-05-31  32.510731  29.693800           0.004295   \n",
       "41      A  2013      6 2013-06-28  30.586552  28.014383          -0.002819   \n",
       "42      A  2013      7 2013-07-31  31.995708  29.305031           0.002107   \n",
       "43      A  2013      8 2013-08-30  33.361946  30.556374           0.001957   \n",
       "44      A  2013      9 2013-09-30  36.659515  33.654156           0.004900   \n",
       "45      A  2013     10 2013-10-31  36.309013  33.332394          -0.000339   \n",
       "46      A  2013     11 2013-11-29  38.319027  35.177631           0.002915   \n",
       "47      A  2013     12 2013-12-31  40.908440  37.641235           0.003282   \n",
       "48      A  2014      1 2014-01-31  41.595135  38.273094           0.000897   \n",
       "49      A  2014      2 2014-02-28  40.722462  37.470112          -0.000823   \n",
       "\n",
       "    std_return_daily  skew_return_daily    Sharpe  prev_price    return  \\\n",
       "0           0.014345          -1.057651 -0.369864   20.040653 -0.097844   \n",
       "1           0.012060           0.795518  0.511000   18.079800  0.122369   \n",
       "2           0.009486           0.943496  0.413428   20.292213  0.093134   \n",
       "3           0.014793           0.484652  0.177654   22.182100  0.054376   \n",
       "4           0.032369           0.345697 -0.159907   23.388283 -0.107557   \n",
       "5           0.023612          -0.678421 -0.237074   20.872721 -0.121446   \n",
       "6           0.020241          -0.095339 -0.032066   18.337812 -0.017587   \n",
       "7           0.027381           1.112051 -0.045157   18.015299 -0.034372   \n",
       "8           0.018911           0.418899  0.547784   17.396082  0.237301   \n",
       "9           0.013007          -0.983643  0.160000   21.524183  0.042853   \n",
       "10          0.016767          -0.075015  0.025889   22.446566  0.006322   \n",
       "11          0.012241           0.452720  0.632311   22.588463  0.183038   \n",
       "12          0.016586          -1.215774  0.036945   26.723019  0.009655   \n",
       "13          0.026238          -0.276730  0.024438   26.981022  0.005977   \n",
       "14          0.026290           1.589836  0.115230   27.142279  0.064163   \n",
       "15          0.016409           0.475558  0.339112   28.883820  0.114560   \n",
       "16          0.016232           0.514109  0.005342   32.192753 -0.000801   \n",
       "17          0.019456          -0.178554  0.066708   32.166958  0.024865   \n",
       "18          0.020524          -0.284088 -0.456845   32.966778 -0.175113   \n",
       "19          0.051500          -0.335696 -0.087794   27.193878 -0.125474   \n",
       "20          0.037274           0.010767 -0.192555   23.781748 -0.152428   \n",
       "21          0.050285          -0.130691  0.186272   20.156755  0.186240   \n",
       "22          0.033704          -0.365538  0.032471   23.910744  0.011600   \n",
       "23          0.024370          -0.590230 -0.126739   24.188101 -0.068533   \n",
       "24          0.020942          -0.251102  0.478816   22.530416  0.215860   \n",
       "25          0.015591           1.193771  0.093057   27.393835  0.027078   \n",
       "26          0.016830           0.210213  0.068673   28.135605  0.022704   \n",
       "27          0.020689           0.042492 -0.119917   28.774385 -0.052348   \n",
       "28          0.018784           0.819410 -0.079841   27.268116 -0.036036   \n",
       "29          0.024521          -0.432317 -0.052053   26.285479 -0.032359   \n",
       "30          0.018667           0.009255 -0.053582   25.434919 -0.024210   \n",
       "31          0.021243          -2.407801 -0.050759   24.819136 -0.029512   \n",
       "32          0.014265           1.084984  0.142295   24.086683  0.037404   \n",
       "33          0.013322          -0.854400 -0.229559   24.987616 -0.063979   \n",
       "34          0.019133           0.457169  0.163445   23.388926  0.063907   \n",
       "35          0.016311           0.109464  0.220724   24.883636  0.071830   \n",
       "36          0.011486           0.460151  0.377920   26.671030  0.093796   \n",
       "37          0.016625          -1.208602 -0.233845   29.172663 -0.073694   \n",
       "38          0.011159          -0.319110  0.070744   27.022825  0.014706   \n",
       "39          0.018418          -0.323141 -0.022526   27.420221 -0.012628   \n",
       "40          0.013600           0.531282  0.315799   27.073946  0.096767   \n",
       "41          0.013544          -0.364063 -0.208150   29.693800 -0.056558   \n",
       "42          0.010980          -0.043075  0.191883   28.014383  0.046071   \n",
       "43          0.010727           0.960212  0.182432   29.305031  0.042701   \n",
       "44          0.011294           0.956637  0.433843   30.556374  0.101379   \n",
       "45          0.012836           0.171295 -0.026400   33.654156 -0.009561   \n",
       "46          0.021835           3.178360  0.133483   33.332394  0.055359   \n",
       "47          0.010612           1.008367  0.309251   35.177631  0.070033   \n",
       "48          0.014740          -0.237913  0.060830   37.641235  0.016786   \n",
       "49          0.024464          -2.053341 -0.033623   38.273094 -0.020980   \n",
       "\n",
       "    next_month_return  cum_ret6  cum_ret12         asset  netIncome_x  \\\n",
       "0            0.122369  0.207149   0.550332           NaN          NaN   \n",
       "1            0.093134  0.225078   1.268206           NaN          NaN   \n",
       "2            0.054376  0.235717   1.237475  7.574000e+09          NaN   \n",
       "3           -0.107557  0.465642   0.985761  7.574000e+09          NaN   \n",
       "4           -0.121446  0.118949   0.775096  7.574000e+09          NaN   \n",
       "5           -0.017587 -0.084969   0.399803  7.612000e+09          NaN   \n",
       "6           -0.034372 -0.003568   0.202842  7.612000e+09          NaN   \n",
       "7            0.237301 -0.142721   0.050233  7.612000e+09          NaN   \n",
       "8            0.042853 -0.029660   0.199065  7.612000e+09          NaN   \n",
       "9            0.006322 -0.040264   0.406629  9.100000e+09          NaN   \n",
       "10           0.183038  0.082200   0.210927  9.100000e+09          NaN   \n",
       "11           0.009655  0.457263   0.333440  7.612000e+09          NaN   \n",
       "12           0.005977  0.497673   0.492330  7.612000e+09          NaN   \n",
       "13           0.064163  0.560252   0.337571  7.612000e+09          NaN   \n",
       "14           0.114560  0.341924   0.302123  9.696000e+09          NaN   \n",
       "15          -0.000801  0.434195   0.376448  9.696000e+09          NaN   \n",
       "16           0.024865  0.424044   0.541100  9.696000e+09          NaN   \n",
       "17          -0.175113  0.233647   0.797749  8.649000e+09          NaN   \n",
       "18          -0.125474  0.007889   0.509488  8.649000e+09          NaN   \n",
       "19          -0.152428 -0.123812   0.367075  8.649000e+09          NaN   \n",
       "20           0.186240 -0.302144  -0.063530  9.696000e+09          NaN   \n",
       "21           0.011600 -0.257263   0.065229  9.696000e+09          NaN   \n",
       "22          -0.068533 -0.248045   0.070817  9.696000e+09          NaN   \n",
       "23           0.215860 -0.316572  -0.156891  9.696000e+09          NaN   \n",
       "24           0.027078  0.007353   0.015300  9.696000e+09          NaN   \n",
       "25           0.022704  0.183076   0.036597  9.696000e+09          NaN   \n",
       "26          -0.052348  0.427531  -0.003789  9.057000e+09          NaN   \n",
       "27          -0.036036  0.140413  -0.152973  9.057000e+09          NaN   \n",
       "28          -0.032359  0.086711  -0.182842  9.057000e+09          NaN   \n",
       "29          -0.024210  0.128915  -0.228468  9.413000e+09          NaN   \n",
       "30          -0.029512 -0.093988  -0.087326  9.413000e+09          NaN   \n",
       "31           0.037404 -0.143907   0.012822  9.413000e+09          NaN   \n",
       "32          -0.063979 -0.131602   0.239665  9.057000e+09          NaN   \n",
       "33           0.063907 -0.142261  -0.021824  9.057000e+09          NaN   \n",
       "34           0.071830 -0.053331   0.028755  9.057000e+09          NaN   \n",
       "35           0.093796  0.048599   0.183779  1.053600e+10          NaN   \n",
       "36          -0.073694  0.175410   0.064935  1.053600e+10          NaN   \n",
       "37           0.014706  0.121899  -0.039551  1.053600e+10          NaN   \n",
       "38          -0.012628  0.097352  -0.047061  1.053600e+10          NaN   \n",
       "39           0.096767  0.157554  -0.007121  1.053600e+10          NaN   \n",
       "40          -0.056558  0.193306   0.129666  1.053600e+10          NaN   \n",
       "41           0.046071  0.050368   0.101414  1.053600e+10          NaN   \n",
       "42           0.042701  0.004537   0.180743  1.053600e+10          NaN   \n",
       "43           0.101379  0.130762   0.268600  1.053600e+10          NaN   \n",
       "44          -0.009561  0.227348   0.346833  1.027800e+10          NaN   \n",
       "45           0.055359  0.231161   0.425136  1.027800e+10          NaN   \n",
       "46           0.070033  0.184679   0.413685  1.027800e+10          NaN   \n",
       "47           0.016786  0.343640   0.411315  1.053600e+10          NaN   \n",
       "48          -0.020980  0.306025   0.311951  1.053600e+10          NaN   \n",
       "49          -0.017741  0.226262   0.386610  1.053600e+10          NaN   \n",
       "\n",
       "    netIncome_y   liabilities  currentAsset  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN  5.098000e+09  3.961000e+09  \n",
       "3           NaN  5.098000e+09  3.961000e+09  \n",
       "4           NaN  5.098000e+09  3.961000e+09  \n",
       "5           NaN  5.098000e+09  3.961000e+09  \n",
       "6           NaN  5.098000e+09  3.961000e+09  \n",
       "7           NaN  5.098000e+09  3.961000e+09  \n",
       "8           NaN  5.098000e+09  3.961000e+09  \n",
       "9           NaN  5.098000e+09  3.961000e+09  \n",
       "10          NaN  5.098000e+09  3.961000e+09  \n",
       "11          NaN  6.460000e+09  6.169000e+09  \n",
       "12          NaN  6.460000e+09  6.169000e+09  \n",
       "13          NaN  6.460000e+09  6.169000e+09  \n",
       "14          NaN  4.705000e+09  6.169000e+09  \n",
       "15          NaN  4.705000e+09  6.169000e+09  \n",
       "16          NaN  4.705000e+09  6.169000e+09  \n",
       "17          NaN  4.688000e+09  5.096000e+09  \n",
       "18          NaN  4.688000e+09  5.096000e+09  \n",
       "19          NaN  4.688000e+09  5.096000e+09  \n",
       "20          NaN  4.553000e+09  5.223000e+09  \n",
       "21          NaN  4.553000e+09  5.223000e+09  \n",
       "22          NaN  4.553000e+09  5.223000e+09  \n",
       "23          NaN  4.741000e+09  6.169000e+09  \n",
       "24          NaN  4.741000e+09  6.169000e+09  \n",
       "25          NaN  4.741000e+09  6.169000e+09  \n",
       "26          NaN  4.600000e+09  5.569000e+09  \n",
       "27          NaN  4.600000e+09  5.569000e+09  \n",
       "28          NaN  4.600000e+09  5.569000e+09  \n",
       "29          NaN  4.741000e+09  6.010000e+09  \n",
       "30          NaN  4.741000e+09  6.010000e+09  \n",
       "31          NaN  4.741000e+09  6.010000e+09  \n",
       "32          NaN  4.741000e+09  4.211000e+09  \n",
       "33          NaN  4.741000e+09  4.211000e+09  \n",
       "34          NaN  4.741000e+09  4.211000e+09  \n",
       "35          NaN  4.741000e+09  4.629000e+09  \n",
       "36          NaN  4.741000e+09  4.629000e+09  \n",
       "37          NaN  4.741000e+09  4.629000e+09  \n",
       "38          NaN  5.302000e+09  4.712000e+09  \n",
       "39          NaN  5.302000e+09  4.712000e+09  \n",
       "40          NaN  5.302000e+09  4.712000e+09  \n",
       "41          NaN  5.351000e+09  4.818000e+09  \n",
       "42          NaN  5.351000e+09  4.818000e+09  \n",
       "43          NaN  5.351000e+09  4.818000e+09  \n",
       "44          NaN  5.488000e+09  4.629000e+09  \n",
       "45          NaN  5.488000e+09  4.629000e+09  \n",
       "46          NaN  5.488000e+09  4.629000e+09  \n",
       "47          NaN  5.397000e+09  4.629000e+09  \n",
       "48          NaN  5.397000e+09  4.629000e+09  \n",
       "49          NaN  5.397000e+09  4.629000e+09  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ac_data4=all_ac_data3[(all_ac_data3['year'] >= 2010) & (all_ac_data3['year'] <= 2022)]\n",
    "all_ac_data4.sort_values(by=['symbol','year','month'])\n",
    "final_data2 = pd.merge(final_data2, all_ac_data4, how='left', on=['symbol', 'year', 'month'])\n",
    "final_data3 = final_data2[(final_data2['year'] >= 2010) & (final_data2['year'] <= 2022)]\n",
    "final_data3 = final_data3.fillna(method='ffill').reset_index()\n",
    "\n",
    "final_data3.drop(columns=['index'],inplace=True)\n",
    "final_data3.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: A\n",
      "Data processed successfully for symbol: AAL\n",
      "Data processed successfully for symbol: AAPL\n",
      "Data processed successfully for symbol: ABBV\n",
      "Data processed successfully for symbol: ABNB\n",
      "Data processed successfully for symbol: ABT\n",
      "Failed to fetch data for symbol: ACGL\n",
      "Data processed successfully for symbol: ACN\n",
      "Data processed successfully for symbol: ADBE\n",
      "Data processed successfully for symbol: ADI\n",
      "Data processed successfully for symbol: ADM\n",
      "Data processed successfully for symbol: ADP\n",
      "Data processed successfully for symbol: ADSK\n",
      "Data processed successfully for symbol: AEE\n",
      "Data processed successfully for symbol: AEP\n",
      "Data processed successfully for symbol: AES\n",
      "Failed to fetch data for symbol: AFL\n",
      "Failed to fetch data for symbol: AIG\n",
      "Failed to fetch data for symbol: AIZ\n",
      "Data processed successfully for symbol: AJG\n",
      "Data processed successfully for symbol: AKAM\n",
      "Data processed successfully for symbol: ALB\n",
      "Data processed successfully for symbol: ALGN\n",
      "Data processed successfully for symbol: ALK\n",
      "Failed to fetch data for symbol: ALL\n",
      "Data processed successfully for symbol: ALLE\n",
      "Data processed successfully for symbol: AMAT\n",
      "Data processed successfully for symbol: AMCR\n",
      "Data processed successfully for symbol: AMD\n",
      "Data processed successfully for symbol: AME\n",
      "Data processed successfully for symbol: AMGN\n",
      "Failed to fetch data for symbol: AMP\n",
      "Data processed successfully for symbol: AMT\n",
      "Data processed successfully for symbol: AMZN\n",
      "Data processed successfully for symbol: ANET\n",
      "Data processed successfully for symbol: ANSS\n",
      "Data processed successfully for symbol: AON\n",
      "Data processed successfully for symbol: AOS\n",
      "Data processed successfully for symbol: APA\n",
      "Data processed successfully for symbol: APD\n",
      "Data processed successfully for symbol: APH\n",
      "Data processed successfully for symbol: APTV\n",
      "Failed to fetch data for symbol: ARE\n",
      "Data processed successfully for symbol: ATO\n",
      "Failed to fetch data for symbol: AVB\n",
      "Data processed successfully for symbol: AVGO\n",
      "Data processed successfully for symbol: AVY\n",
      "Data processed successfully for symbol: AWK\n",
      "Data processed successfully for symbol: AXON\n",
      "Failed to fetch data for symbol: AXP\n",
      "Data processed successfully for symbol: AZO\n",
      "Data processed successfully for symbol: BA\n",
      "Failed to fetch data for symbol: BAC\n",
      "Data processed successfully for symbol: BALL\n",
      "Data processed successfully for symbol: BAX\n",
      "Data processed successfully for symbol: BBWI\n",
      "Data processed successfully for symbol: BBY\n",
      "Data processed successfully for symbol: BDX\n",
      "Data processed successfully for symbol: BEN\n",
      "Failed to fetch data for symbol: BG\n",
      "Data processed successfully for symbol: BIIB\n",
      "Data processed successfully for symbol: BIO\n",
      "Failed to fetch data for symbol: BK\n",
      "Data processed successfully for symbol: BKNG\n",
      "Data processed successfully for symbol: BKR\n",
      "Failed to fetch data for symbol: BLK\n",
      "Data processed successfully for symbol: BMY\n",
      "Data processed successfully for symbol: BR\n",
      "Data processed successfully for symbol: BRO\n",
      "Data processed successfully for symbol: BSX\n",
      "Data processed successfully for symbol: BWA\n",
      "Failed to fetch data for symbol: BX\n",
      "Failed to fetch data for symbol: BXP\n",
      "Failed to fetch data for symbol: C\n",
      "Data processed successfully for symbol: CAG\n",
      "Data processed successfully for symbol: CAH\n",
      "Data processed successfully for symbol: CARR\n",
      "Data processed successfully for symbol: CAT\n",
      "Failed to fetch data for symbol: CB\n",
      "Data processed successfully for symbol: CBOE\n",
      "Data processed successfully for symbol: CBRE\n",
      "Data processed successfully for symbol: CCI\n",
      "Data processed successfully for symbol: CCL\n",
      "Data processed successfully for symbol: CDAY\n",
      "Data processed successfully for symbol: CDNS\n",
      "Data processed successfully for symbol: CDW\n",
      "Data processed successfully for symbol: CE\n",
      "Data processed successfully for symbol: CF\n",
      "Failed to fetch data for symbol: CFG\n",
      "Data processed successfully for symbol: CHD\n",
      "Data processed successfully for symbol: CHRW\n",
      "Data processed successfully for symbol: CHTR\n",
      "Data processed successfully for symbol: CI\n",
      "Failed to fetch data for symbol: CINF\n",
      "Data processed successfully for symbol: CL\n",
      "Data processed successfully for symbol: CLX\n",
      "Failed to fetch data for symbol: CMA\n",
      "Data processed successfully for symbol: CMCSA\n",
      "Data processed successfully for symbol: CME\n",
      "Data processed successfully for symbol: CMG\n",
      "Data processed successfully for symbol: CMI\n",
      "Data processed successfully for symbol: CMS\n",
      "Data processed successfully for symbol: CNC\n",
      "Data processed successfully for symbol: CNP\n",
      "Failed to fetch data for symbol: COF\n",
      "Data processed successfully for symbol: COO\n",
      "Data processed successfully for symbol: COP\n",
      "Data processed successfully for symbol: COR\n",
      "Data processed successfully for symbol: COST\n",
      "Data processed successfully for symbol: CPB\n",
      "Data processed successfully for symbol: CPRT\n",
      "Failed to fetch data for symbol: CPT\n",
      "Data processed successfully for symbol: CRL\n",
      "Data processed successfully for symbol: CRM\n",
      "Data processed successfully for symbol: CSCO\n",
      "Data processed successfully for symbol: CSGP\n",
      "Data processed successfully for symbol: CSX\n",
      "Data processed successfully for symbol: CTAS\n",
      "Data processed successfully for symbol: CTLT\n",
      "Data processed successfully for symbol: CTRA\n",
      "Data processed successfully for symbol: CTSH\n",
      "Data processed successfully for symbol: CTVA\n",
      "Data processed successfully for symbol: CVS\n",
      "Data processed successfully for symbol: CVX\n",
      "Data processed successfully for symbol: CZR\n",
      "Data processed successfully for symbol: D\n",
      "Data processed successfully for symbol: DAL\n",
      "Data processed successfully for symbol: DD\n",
      "Failed to fetch data for symbol: DE\n",
      "Failed to fetch data for symbol: DFS\n",
      "Data processed successfully for symbol: DG\n",
      "Data processed successfully for symbol: DGX\n",
      "Failed to fetch data for symbol: DHI\n",
      "Data processed successfully for symbol: DHR\n",
      "Data processed successfully for symbol: DIS\n",
      "Failed to fetch data for symbol: DLR\n",
      "Data processed successfully for symbol: DLTR\n",
      "Data processed successfully for symbol: DOV\n",
      "Data processed successfully for symbol: DOW\n",
      "Data processed successfully for symbol: DPZ\n",
      "Data processed successfully for symbol: DRI\n",
      "Data processed successfully for symbol: DTE\n",
      "Data processed successfully for symbol: DUK\n",
      "Data processed successfully for symbol: DVA\n",
      "Data processed successfully for symbol: DVN\n",
      "Data processed successfully for symbol: DXCM\n",
      "Data processed successfully for symbol: EA\n",
      "Data processed successfully for symbol: EBAY\n",
      "Data processed successfully for symbol: ECL\n",
      "Data processed successfully for symbol: ED\n",
      "Data processed successfully for symbol: EFX\n",
      "Failed to fetch data for symbol: EG\n",
      "Data processed successfully for symbol: EIX\n",
      "Data processed successfully for symbol: EL\n",
      "Data processed successfully for symbol: ELV\n",
      "Data processed successfully for symbol: EMN\n",
      "Data processed successfully for symbol: EMR\n",
      "Data processed successfully for symbol: ENPH\n",
      "Data processed successfully for symbol: EOG\n",
      "Data processed successfully for symbol: EPAM\n",
      "Data processed successfully for symbol: EQIX\n",
      "Failed to fetch data for symbol: EQR\n",
      "Data processed successfully for symbol: EQT\n",
      "Data processed successfully for symbol: ES\n",
      "Failed to fetch data for symbol: ESS\n",
      "Data processed successfully for symbol: ETN\n",
      "Data processed successfully for symbol: ETR\n",
      "Data processed successfully for symbol: ETSY\n",
      "Data processed successfully for symbol: EVRG\n",
      "Data processed successfully for symbol: EW\n",
      "Data processed successfully for symbol: EXC\n",
      "Data processed successfully for symbol: EXPD\n",
      "Data processed successfully for symbol: EXPE\n",
      "Failed to fetch data for symbol: EXR\n",
      "Data processed successfully for symbol: F\n",
      "Data processed successfully for symbol: FANG\n",
      "Data processed successfully for symbol: FAST\n",
      "Data processed successfully for symbol: FCX\n",
      "Data processed successfully for symbol: FDS\n",
      "Data processed successfully for symbol: FDX\n",
      "Data processed successfully for symbol: FE\n",
      "Data processed successfully for symbol: FFIV\n",
      "Data processed successfully for symbol: FI\n",
      "Data processed successfully for symbol: FICO\n",
      "Data processed successfully for symbol: FIS\n",
      "Failed to fetch data for symbol: FITB\n",
      "Data processed successfully for symbol: FLT\n",
      "Data processed successfully for symbol: FMC\n",
      "Data processed successfully for symbol: FOX\n",
      "Data processed successfully for symbol: FOXA\n",
      "Failed to fetch data for symbol: FRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: FSLR\n",
      "Data processed successfully for symbol: FTNT\n",
      "Data processed successfully for symbol: FTV\n",
      "Data processed successfully for symbol: GD\n",
      "Data processed successfully for symbol: GE\n",
      "Data processed successfully for symbol: GEN\n",
      "Data processed successfully for symbol: GILD\n",
      "Data processed successfully for symbol: GIS\n",
      "Failed to fetch data for symbol: GL\n",
      "Data processed successfully for symbol: GLW\n",
      "Data processed successfully for symbol: GM\n",
      "Data processed successfully for symbol: GNRC\n",
      "Data processed successfully for symbol: GOOG\n",
      "Data processed successfully for symbol: GOOGL\n",
      "Data processed successfully for symbol: GPC\n",
      "Data processed successfully for symbol: GPN\n",
      "Data processed successfully for symbol: GRMN\n",
      "Failed to fetch data for symbol: GS\n",
      "Data processed successfully for symbol: GWW\n",
      "Data processed successfully for symbol: HAL\n",
      "Data processed successfully for symbol: HAS\n",
      "Failed to fetch data for symbol: HBAN\n",
      "Data processed successfully for symbol: HCA\n",
      "Data processed successfully for symbol: HD\n",
      "Data processed successfully for symbol: HES\n",
      "Failed to fetch data for symbol: HIG\n",
      "Data processed successfully for symbol: HII\n",
      "Data processed successfully for symbol: HLT\n",
      "Data processed successfully for symbol: HOLX\n",
      "Data processed successfully for symbol: HON\n",
      "Data processed successfully for symbol: HPE\n",
      "Data processed successfully for symbol: HPQ\n",
      "Data processed successfully for symbol: HRL\n",
      "Data processed successfully for symbol: HSIC\n",
      "Failed to fetch data for symbol: HST\n",
      "Data processed successfully for symbol: HSY\n",
      "Data processed successfully for symbol: HUBB\n",
      "Data processed successfully for symbol: HUM\n",
      "Data processed successfully for symbol: HWM\n",
      "Data processed successfully for symbol: IBM\n",
      "Data processed successfully for symbol: ICE\n",
      "Data processed successfully for symbol: IDXX\n",
      "Data processed successfully for symbol: IEX\n",
      "Data processed successfully for symbol: IFF\n",
      "Data processed successfully for symbol: ILMN\n",
      "Data processed successfully for symbol: INCY\n",
      "Data processed successfully for symbol: INTC\n",
      "Data processed successfully for symbol: INTU\n",
      "Failed to fetch data for symbol: INVH\n",
      "Data processed successfully for symbol: IP\n",
      "Data processed successfully for symbol: IPG\n",
      "Data processed successfully for symbol: IQV\n",
      "Data processed successfully for symbol: IR\n",
      "Data processed successfully for symbol: IRM\n",
      "Data processed successfully for symbol: ISRG\n",
      "Data processed successfully for symbol: IT\n",
      "Data processed successfully for symbol: ITW\n",
      "Data processed successfully for symbol: IVZ\n",
      "Data processed successfully for symbol: J\n",
      "Data processed successfully for symbol: JBHT\n",
      "Data processed successfully for symbol: JCI\n",
      "Data processed successfully for symbol: JKHY\n",
      "Data processed successfully for symbol: JNJ\n",
      "Data processed successfully for symbol: JNPR\n",
      "Failed to fetch data for symbol: JPM\n",
      "Data processed successfully for symbol: K\n",
      "Data processed successfully for symbol: KDP\n",
      "Failed to fetch data for symbol: KEY\n",
      "Data processed successfully for symbol: KEYS\n",
      "Data processed successfully for symbol: KHC\n",
      "Failed to fetch data for symbol: KIM\n",
      "Data processed successfully for symbol: KLAC\n",
      "Data processed successfully for symbol: KMB\n",
      "Data processed successfully for symbol: KMI\n",
      "Data processed successfully for symbol: KMX\n",
      "Data processed successfully for symbol: KO\n",
      "Data processed successfully for symbol: KR\n",
      "Failed to fetch data for symbol: L\n",
      "Data processed successfully for symbol: LDOS\n",
      "Failed to fetch data for symbol: LEN\n",
      "Data processed successfully for symbol: LH\n",
      "Data processed successfully for symbol: LHX\n",
      "Data processed successfully for symbol: LIN\n",
      "Data processed successfully for symbol: LKQ\n",
      "Data processed successfully for symbol: LLY\n",
      "Data processed successfully for symbol: LMT\n",
      "Data processed successfully for symbol: LNT\n",
      "Data processed successfully for symbol: LOW\n",
      "Data processed successfully for symbol: LRCX\n",
      "Data processed successfully for symbol: LULU\n",
      "Data processed successfully for symbol: LUV\n",
      "Data processed successfully for symbol: LVS\n",
      "Data processed successfully for symbol: LW\n",
      "Data processed successfully for symbol: LYB\n",
      "Data processed successfully for symbol: LYV\n",
      "Data processed successfully for symbol: MA\n",
      "Failed to fetch data for symbol: MAA\n",
      "Data processed successfully for symbol: MAR\n",
      "Data processed successfully for symbol: MAS\n",
      "Data processed successfully for symbol: MCD\n",
      "Data processed successfully for symbol: MCHP\n",
      "Data processed successfully for symbol: MCK\n",
      "Data processed successfully for symbol: MCO\n",
      "Data processed successfully for symbol: MDLZ\n",
      "Data processed successfully for symbol: MDT\n",
      "Failed to fetch data for symbol: MET\n",
      "Data processed successfully for symbol: META\n",
      "Data processed successfully for symbol: MGM\n",
      "Data processed successfully for symbol: MHK\n",
      "Data processed successfully for symbol: MKC\n",
      "Failed to fetch data for symbol: MKTX\n",
      "Data processed successfully for symbol: MLM\n",
      "Data processed successfully for symbol: MMC\n",
      "Data processed successfully for symbol: MMM\n",
      "Data processed successfully for symbol: MNST\n",
      "Data processed successfully for symbol: MO\n",
      "Data processed successfully for symbol: MOH\n",
      "Data processed successfully for symbol: MOS\n",
      "Data processed successfully for symbol: MPC\n",
      "Data processed successfully for symbol: MPWR\n",
      "Data processed successfully for symbol: MRK\n",
      "Data processed successfully for symbol: MRNA\n",
      "Data processed successfully for symbol: MRO\n",
      "Failed to fetch data for symbol: MS\n",
      "Data processed successfully for symbol: MSCI\n",
      "Data processed successfully for symbol: MSFT\n",
      "Data processed successfully for symbol: MSI\n",
      "Failed to fetch data for symbol: MTB\n",
      "Data processed successfully for symbol: MTCH\n",
      "Data processed successfully for symbol: MTD\n",
      "Data processed successfully for symbol: MU\n",
      "Data processed successfully for symbol: NCLH\n",
      "Data processed successfully for symbol: NDAQ\n",
      "Data processed successfully for symbol: NDSN\n",
      "Data processed successfully for symbol: NEE\n",
      "Data processed successfully for symbol: NEM\n",
      "Data processed successfully for symbol: NFLX\n",
      "Data processed successfully for symbol: NI\n",
      "Data processed successfully for symbol: NKE\n",
      "Data processed successfully for symbol: NOC\n",
      "Data processed successfully for symbol: NOW\n",
      "Data processed successfully for symbol: NRG\n",
      "Data processed successfully for symbol: NSC\n",
      "Data processed successfully for symbol: NTAP\n",
      "Failed to fetch data for symbol: NTRS\n",
      "Data processed successfully for symbol: NUE\n",
      "Data processed successfully for symbol: NVDA\n",
      "Failed to fetch data for symbol: NVR\n",
      "Data processed successfully for symbol: NWS\n",
      "Data processed successfully for symbol: NWSA\n",
      "Data processed successfully for symbol: NXPI\n",
      "Failed to fetch data for symbol: O\n",
      "Data processed successfully for symbol: ODFL\n",
      "Data processed successfully for symbol: OKE\n",
      "Data processed successfully for symbol: OMC\n",
      "Data processed successfully for symbol: ON\n",
      "Data processed successfully for symbol: ORCL\n",
      "Data processed successfully for symbol: ORLY\n",
      "Data processed successfully for symbol: OTIS\n",
      "Data processed successfully for symbol: OXY\n",
      "Data processed successfully for symbol: PANW\n",
      "Data processed successfully for symbol: PARA\n",
      "Data processed successfully for symbol: PAYC\n",
      "Data processed successfully for symbol: PAYX\n",
      "Failed to fetch data for symbol: PCAR\n",
      "Data processed successfully for symbol: PCG\n",
      "Failed to fetch data for symbol: PEAK\n",
      "Data processed successfully for symbol: PEG\n",
      "Data processed successfully for symbol: PEP\n",
      "Data processed successfully for symbol: PFE\n",
      "Failed to fetch data for symbol: PFG\n",
      "Data processed successfully for symbol: PG\n",
      "Failed to fetch data for symbol: PGR\n",
      "Data processed successfully for symbol: PH\n",
      "Failed to fetch data for symbol: PHM\n",
      "Data processed successfully for symbol: PKG\n",
      "Failed to fetch data for symbol: PLD\n",
      "Data processed successfully for symbol: PM\n",
      "Failed to fetch data for symbol: PNC\n",
      "Data processed successfully for symbol: PNR\n",
      "Data processed successfully for symbol: PNW\n",
      "Data processed successfully for symbol: PODD\n",
      "Data processed successfully for symbol: POOL\n",
      "Data processed successfully for symbol: PPG\n",
      "Data processed successfully for symbol: PPL\n",
      "Failed to fetch data for symbol: PRU\n",
      "Failed to fetch data for symbol: PSA\n",
      "Data processed successfully for symbol: PSX\n",
      "Data processed successfully for symbol: PTC\n",
      "Data processed successfully for symbol: PWR\n",
      "Data processed successfully for symbol: PXD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: PYPL\n",
      "Data processed successfully for symbol: QCOM\n",
      "Data processed successfully for symbol: QRVO\n",
      "Data processed successfully for symbol: RCL\n",
      "Failed to fetch data for symbol: REG\n",
      "Data processed successfully for symbol: REGN\n",
      "Failed to fetch data for symbol: RF\n",
      "Data processed successfully for symbol: RHI\n",
      "Failed to fetch data for symbol: RJF\n",
      "Data processed successfully for symbol: RL\n",
      "Data processed successfully for symbol: RMD\n",
      "Data processed successfully for symbol: ROK\n",
      "Data processed successfully for symbol: ROL\n",
      "Data processed successfully for symbol: ROP\n",
      "Data processed successfully for symbol: ROST\n",
      "Data processed successfully for symbol: RSG\n",
      "Data processed successfully for symbol: RTX\n",
      "Data processed successfully for symbol: RVTY\n",
      "Data processed successfully for symbol: SBAC\n",
      "Data processed successfully for symbol: SBUX\n",
      "Failed to fetch data for symbol: SCHW\n",
      "Data processed successfully for symbol: SEDG\n",
      "Data processed successfully for symbol: SEE\n",
      "Data processed successfully for symbol: SHW\n",
      "Data processed successfully for symbol: SJM\n",
      "Data processed successfully for symbol: SLB\n",
      "Data processed successfully for symbol: SNA\n",
      "Data processed successfully for symbol: SNPS\n",
      "Data processed successfully for symbol: SO\n",
      "Failed to fetch data for symbol: SPG\n",
      "Data processed successfully for symbol: SPGI\n",
      "Data processed successfully for symbol: SRE\n",
      "Data processed successfully for symbol: STE\n",
      "Data processed successfully for symbol: STLD\n",
      "Failed to fetch data for symbol: STT\n",
      "Data processed successfully for symbol: STX\n",
      "Data processed successfully for symbol: STZ\n",
      "Data processed successfully for symbol: SWK\n",
      "Data processed successfully for symbol: SWKS\n",
      "Failed to fetch data for symbol: SYF\n",
      "Data processed successfully for symbol: SYK\n",
      "Data processed successfully for symbol: SYY\n",
      "Data processed successfully for symbol: T\n",
      "Data processed successfully for symbol: TAP\n",
      "Data processed successfully for symbol: TDG\n",
      "Data processed successfully for symbol: TDY\n",
      "Data processed successfully for symbol: TECH\n",
      "Data processed successfully for symbol: TEL\n",
      "Data processed successfully for symbol: TER\n",
      "Failed to fetch data for symbol: TFC\n",
      "Data processed successfully for symbol: TFX\n",
      "Data processed successfully for symbol: TGT\n",
      "Data processed successfully for symbol: TJX\n",
      "Data processed successfully for symbol: TMO\n",
      "Data processed successfully for symbol: TMUS\n",
      "Data processed successfully for symbol: TPR\n",
      "Data processed successfully for symbol: TRGP\n",
      "Data processed successfully for symbol: TRMB\n",
      "Failed to fetch data for symbol: TROW\n",
      "Failed to fetch data for symbol: TRV\n",
      "Data processed successfully for symbol: TSCO\n",
      "Data processed successfully for symbol: TSLA\n",
      "Data processed successfully for symbol: TSN\n",
      "Data processed successfully for symbol: TT\n",
      "Data processed successfully for symbol: TTWO\n",
      "Data processed successfully for symbol: TXN\n",
      "Failed to fetch data for symbol: TXT\n",
      "Data processed successfully for symbol: TYL\n",
      "Data processed successfully for symbol: UAL\n",
      "Failed to fetch data for symbol: UDR\n",
      "Data processed successfully for symbol: UHS\n",
      "Data processed successfully for symbol: ULTA\n",
      "Data processed successfully for symbol: UNH\n",
      "Data processed successfully for symbol: UNP\n",
      "Data processed successfully for symbol: UPS\n",
      "Data processed successfully for symbol: URI\n",
      "Failed to fetch data for symbol: USB\n",
      "Data processed successfully for symbol: V\n",
      "Data processed successfully for symbol: VFC\n",
      "Failed to fetch data for symbol: VICI\n",
      "Data processed successfully for symbol: VLO\n",
      "Data processed successfully for symbol: VMC\n",
      "Data processed successfully for symbol: VRSK\n",
      "Data processed successfully for symbol: VRSN\n",
      "Data processed successfully for symbol: VRTX\n",
      "Failed to fetch data for symbol: VTR\n",
      "Data processed successfully for symbol: VTRS\n",
      "Data processed successfully for symbol: VZ\n",
      "Data processed successfully for symbol: WAB\n",
      "Data processed successfully for symbol: WAT\n",
      "Data processed successfully for symbol: WBA\n",
      "Data processed successfully for symbol: WBD\n",
      "Data processed successfully for symbol: WDC\n",
      "Data processed successfully for symbol: WEC\n",
      "Failed to fetch data for symbol: WELL\n",
      "Failed to fetch data for symbol: WFC\n",
      "Data processed successfully for symbol: WHR\n",
      "Data processed successfully for symbol: WM\n",
      "Data processed successfully for symbol: WMB\n",
      "Data processed successfully for symbol: WMT\n",
      "Failed to fetch data for symbol: WRB\n",
      "Data processed successfully for symbol: WRK\n",
      "Data processed successfully for symbol: WST\n",
      "Data processed successfully for symbol: WTW\n",
      "Data processed successfully for symbol: WY\n",
      "Data processed successfully for symbol: WYNN\n",
      "Data processed successfully for symbol: XEL\n",
      "Data processed successfully for symbol: XOM\n",
      "Data processed successfully for symbol: XRAY\n",
      "Data processed successfully for symbol: XYL\n",
      "Data processed successfully for symbol: YUM\n",
      "Data processed successfully for symbol: ZBH\n",
      "Data processed successfully for symbol: ZBRA\n",
      "Failed to fetch data for symbol: ZION\n",
      "Data processed successfully for symbol: ZTS\n",
      "Data concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "all_lc_data = pd.DataFrame()\n",
    "\n",
    "for symb in symbols:\n",
    "    _cik = companyData[companyData['ticker'] == symb]['cik_str10']\n",
    "    \n",
    "    # Check if CIK is available\n",
    "    if not _cik.empty:\n",
    "        cik = _cik.iloc[0]\n",
    "        \n",
    "        # Fetch company facts\n",
    "        companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json', headers=headers)\n",
    "        \n",
    "        # Check if the request is successful and has the expected structure\n",
    "        if companyFacts.status_code == 200 and 'facts' in companyFacts.json().keys() and 'us-gaap' in companyFacts.json()['facts'].keys() and 'LiabilitiesCurrent' in companyFacts.json()['facts']['us-gaap'].keys():\n",
    "            \n",
    "            # Extract lc data and create DataFrame\n",
    "            lc_data = companyFacts.json()['facts']['us-gaap']['LiabilitiesCurrent']['units']['USD']\n",
    "            lc = pd.DataFrame.from_dict(lc_data)\n",
    "            lc['symbol'] = symb\n",
    "            \n",
    "            # Concatenate directly to the existing DataFrame\n",
    "            all_lc_data = pd.concat([all_lc_data, lc], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data processed successfully for symbol: {symb}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for symbol: {symb}\")\n",
    "    else:\n",
    "        print(f\"CIK not available for symbol: {symb}\")\n",
    "\n",
    "# Check if there is data\n",
    "if not all_lc_data.empty:\n",
    "    print(\"Data concatenated successfully.\")\n",
    "    # Further processing or analysis can be done with 'all_lc_data'\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              end         val                  accn      fy  fp    form  \\\n",
      "0      2008-10-31  1330000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "1      2008-10-31  1330000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "2      2008-10-31  1330000000  0001104659-10-047478  2009.0  FY     8-K   \n",
      "3      2009-07-31   991000000  0001140361-09-022500  2009.0  Q3  10-Q/A   \n",
      "4      2009-10-31  1123000000  0001047469-09-010861  2009.0  FY    10-K   \n",
      "...           ...         ...                   ...     ...  ..     ...   \n",
      "45143  2022-12-31  3167000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "45144  2022-12-31  3167000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "45145  2023-03-31  1915000000  0001555280-23-000150  2023.0  Q1    10-Q   \n",
      "45146  2023-06-30  1769000000  0001555280-23-000205  2023.0  Q2    10-Q   \n",
      "45147  2023-09-30  1608000000  0001555280-23-000247  2023.0  Q3    10-Q   \n",
      "\n",
      "            filed      frame symbol  \n",
      "0      2009-10-05        NaN      A  \n",
      "1      2009-12-21        NaN      A  \n",
      "2      2010-09-07  CY2008Q3I      A  \n",
      "3      2009-10-05  CY2009Q2I      A  \n",
      "4      2009-12-21        NaN      A  \n",
      "...           ...        ...    ...  \n",
      "45143  2023-08-08        NaN    ZTS  \n",
      "45144  2023-11-02  CY2022Q4I    ZTS  \n",
      "45145  2023-05-04  CY2023Q1I    ZTS  \n",
      "45146  2023-08-08  CY2023Q2I    ZTS  \n",
      "45147  2023-11-02  CY2023Q3I    ZTS  \n",
      "\n",
      "[45148 rows x 9 columns]\n",
      "Data processed successfully.\n",
      "       year  month  currentLiablities symbol\n",
      "0      2009     12         1330000000      A\n",
      "1      2010      3         2549000000      A\n",
      "2      2010      6         1123000000      A\n",
      "3      2010     12         3083000000      A\n",
      "4      2011      3         1406000000      A\n",
      "...     ...    ...                ...    ...\n",
      "21602  2022     11         2880000000    ZTS\n",
      "21603  2023      2         1797000000    ZTS\n",
      "21604  2023      5         1915000000    ZTS\n",
      "21605  2023      8         3167000000    ZTS\n",
      "21606  2023     11         3167000000    ZTS\n",
      "\n",
      "[21607 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "    print(all_lc_data)\n",
    "    all_lc_data = all_lc_data[all_lc_data['form'].isin(['10-K', '10-Q'])]\n",
    "    all_lc_data['filed1'] = pd.to_datetime(all_lc_data['filed'])\n",
    "    all_lc_data['year'] = all_lc_data['filed1'].dt.year\n",
    "    all_lc_data['month'] = all_lc_data['filed1'].dt.month\n",
    "    all_lc_data['day'] = all_lc_data['filed1'].dt.day\n",
    "    \n",
    "    all_lc_data2 = all_lc_data.sort_values(by='filed1')\n",
    "    all_lc_data2 = all_lc_data2.groupby(['symbol','year', 'month']).first().reset_index()\n",
    "    \n",
    "    features = ['year', 'month', 'val', 'symbol']\n",
    "    all_lc_data3 = all_lc_data2[features].copy()\n",
    "    all_lc_data3.rename(columns={'val': 'currentLiablities'}, inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"Data processed successfully.\")\n",
    "    print(all_lc_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>...</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "      <th>netIncome_x</th>\n",
       "      <th>netIncome_y</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>currentAsset</th>\n",
       "      <th>currentLiablities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>20.336195</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>-0.678421</td>\n",
       "      <td>-0.237074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>19.978540</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>-0.003568</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>19.291845</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>1.112051</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>-0.142721</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>23.869814</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.547784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>-0.029660</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>24.892704</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.983643</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>25.050072</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>1.123000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>29.635193</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.632311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.333440</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-1.215774</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>30.100143</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.026238</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>1.589836</td>\n",
       "      <td>0.115230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.406000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>35.701000</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.339112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.406000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>35.672390</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.424044</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.406000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>36.559372</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>30.157368</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.284088</td>\n",
       "      <td>-0.456845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>26.373390</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.335696</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>5.096000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>22.353361</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.192555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>-0.302144</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "      <td>1.505000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>26.516453</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.130691</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "      <td>1.505000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2011-11-30</td>\n",
       "      <td>26.824034</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.365538</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.070817</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>5.223000e+09</td>\n",
       "      <td>1.505000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>24.985695</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>-0.590230</td>\n",
       "      <td>-0.126739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>-0.316572</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>30.379112</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.251102</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>31.201717</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>1.193771</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.169000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>31.838341</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.210213</td>\n",
       "      <td>0.068673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>30.171675</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>-0.119917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>-0.152973</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>29.084406</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>-0.079841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>-0.182842</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>5.569000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>28.068670</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.052053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.228468</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>26.580830</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-2.407801</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.143907</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>6.010000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>27.503576</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.084984</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.131602</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>25.743919</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.854400</td>\n",
       "      <td>-0.229559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.142261</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.211000e+09</td>\n",
       "      <td>1.837000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>29.284693</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.109464</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.175410</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>29.670959</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-1.208602</td>\n",
       "      <td>-0.233845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.121899</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>30.021460</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>-0.047061</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "      <td>1.846000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>29.642345</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>0.157554</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "      <td>1.846000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>32.510731</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.531282</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.193306</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>4.712000e+09</td>\n",
       "      <td>1.846000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>30.586552</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>-0.364063</td>\n",
       "      <td>-0.208150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>31.995708</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.191883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>33.361946</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>4.818000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>36.659515</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.956637</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.346833</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.550000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>36.309013</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.171295</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.550000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>38.319027</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>3.178360</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.550000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>40.908440</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>1.008367</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>41.595135</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>-0.237913</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>37.470112</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>-2.053341</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.386610</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>4.629000e+09</td>\n",
       "      <td>1.893000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0       A  2010      1 2010-01-29  20.050072  18.079800          -0.005306   \n",
       "1       A  2010      2 2010-02-26  22.503576  20.292213           0.006162   \n",
       "2       A  2010      3 2010-03-31  24.599428  22.182100           0.003922   \n",
       "3       A  2010      4 2010-04-30  25.937054  23.388283           0.002628   \n",
       "4       A  2010      5 2010-05-28  23.147352  20.872721          -0.005176   \n",
       "5       A  2010      6 2010-06-30  20.336195  18.337812          -0.005598   \n",
       "6       A  2010      7 2010-07-30  19.978540  18.015299          -0.000649   \n",
       "7       A  2010      8 2010-08-31  19.291845  17.396082          -0.001236   \n",
       "8       A  2010      9 2010-09-30  23.869814  21.524183           0.010359   \n",
       "9       A  2010     10 2010-10-29  24.892704  22.446566           0.002081   \n",
       "10      A  2010     11 2010-11-30  25.050072  22.588463           0.000434   \n",
       "11      A  2010     12 2010-12-31  29.635193  26.723019           0.007740   \n",
       "12      A  2011      1 2011-01-31  29.921316  26.981022           0.000613   \n",
       "13      A  2011      2 2011-02-28  30.100143  27.142279           0.000641   \n",
       "14      A  2011      3 2011-03-31  32.031475  28.883820           0.003029   \n",
       "15      A  2011      4 2011-04-29  35.701000  32.192753           0.005564   \n",
       "16      A  2011      5 2011-05-31  35.672390  32.166958           0.000087   \n",
       "17      A  2011      6 2011-06-30  36.559372  32.966778           0.001298   \n",
       "18      A  2011      7 2011-07-29  30.157368  27.193878          -0.009376   \n",
       "19      A  2011      8 2011-08-31  26.373390  23.781748          -0.004521   \n",
       "20      A  2011      9 2011-09-30  22.353361  20.156755          -0.007177   \n",
       "21      A  2011     10 2011-10-31  26.516453  23.910744           0.009367   \n",
       "22      A  2011     11 2011-11-30  26.824034  24.188101           0.001094   \n",
       "23      A  2011     12 2011-12-30  24.985695  22.530416          -0.003089   \n",
       "24      A  2012      1 2012-01-31  30.379112  27.393835           0.010027   \n",
       "25      A  2012      2 2012-02-29  31.201717  28.135605           0.001451   \n",
       "26      A  2012      3 2012-03-30  31.838341  28.774385           0.001156   \n",
       "27      A  2012      4 2012-04-30  30.171675  27.268116          -0.002481   \n",
       "28      A  2012      5 2012-05-31  29.084406  26.285479          -0.001500   \n",
       "29      A  2012      6 2012-06-29  28.068670  25.434919          -0.001276   \n",
       "30      A  2012      7 2012-07-31  27.389128  24.819136          -0.001000   \n",
       "31      A  2012      8 2012-08-31  26.580830  24.086683          -0.001078   \n",
       "32      A  2012      9 2012-09-28  27.503576  24.987616           0.002030   \n",
       "33      A  2012     10 2012-10-31  25.743919  23.388926          -0.003058   \n",
       "34      A  2012     11 2012-11-30  27.389128  24.883636           0.003127   \n",
       "35      A  2012     12 2012-12-31  29.284693  26.671030           0.003600   \n",
       "36      A  2013      1 2013-01-31  32.031475  29.172663           0.004341   \n",
       "37      A  2013      2 2013-02-28  29.670959  27.022825          -0.003888   \n",
       "38      A  2013      3 2013-03-28  30.021460  27.420221           0.000789   \n",
       "39      A  2013      4 2013-04-30  29.642345  27.073946          -0.000415   \n",
       "40      A  2013      5 2013-05-31  32.510731  29.693800           0.004295   \n",
       "41      A  2013      6 2013-06-28  30.586552  28.014383          -0.002819   \n",
       "42      A  2013      7 2013-07-31  31.995708  29.305031           0.002107   \n",
       "43      A  2013      8 2013-08-30  33.361946  30.556374           0.001957   \n",
       "44      A  2013      9 2013-09-30  36.659515  33.654156           0.004900   \n",
       "45      A  2013     10 2013-10-31  36.309013  33.332394          -0.000339   \n",
       "46      A  2013     11 2013-11-29  38.319027  35.177631           0.002915   \n",
       "47      A  2013     12 2013-12-31  40.908440  37.641235           0.003282   \n",
       "48      A  2014      1 2014-01-31  41.595135  38.273094           0.000897   \n",
       "49      A  2014      2 2014-02-28  40.722462  37.470112          -0.000823   \n",
       "\n",
       "    std_return_daily  skew_return_daily    Sharpe  ...    return  \\\n",
       "0           0.014345          -1.057651 -0.369864  ... -0.097844   \n",
       "1           0.012060           0.795518  0.511000  ...  0.122369   \n",
       "2           0.009486           0.943496  0.413428  ...  0.093134   \n",
       "3           0.014793           0.484652  0.177654  ...  0.054376   \n",
       "4           0.032369           0.345697 -0.159907  ... -0.107557   \n",
       "5           0.023612          -0.678421 -0.237074  ... -0.121446   \n",
       "6           0.020241          -0.095339 -0.032066  ... -0.017587   \n",
       "7           0.027381           1.112051 -0.045157  ... -0.034372   \n",
       "8           0.018911           0.418899  0.547784  ...  0.237301   \n",
       "9           0.013007          -0.983643  0.160000  ...  0.042853   \n",
       "10          0.016767          -0.075015  0.025889  ...  0.006322   \n",
       "11          0.012241           0.452720  0.632311  ...  0.183038   \n",
       "12          0.016586          -1.215774  0.036945  ...  0.009655   \n",
       "13          0.026238          -0.276730  0.024438  ...  0.005977   \n",
       "14          0.026290           1.589836  0.115230  ...  0.064163   \n",
       "15          0.016409           0.475558  0.339112  ...  0.114560   \n",
       "16          0.016232           0.514109  0.005342  ... -0.000801   \n",
       "17          0.019456          -0.178554  0.066708  ...  0.024865   \n",
       "18          0.020524          -0.284088 -0.456845  ... -0.175113   \n",
       "19          0.051500          -0.335696 -0.087794  ... -0.125474   \n",
       "20          0.037274           0.010767 -0.192555  ... -0.152428   \n",
       "21          0.050285          -0.130691  0.186272  ...  0.186240   \n",
       "22          0.033704          -0.365538  0.032471  ...  0.011600   \n",
       "23          0.024370          -0.590230 -0.126739  ... -0.068533   \n",
       "24          0.020942          -0.251102  0.478816  ...  0.215860   \n",
       "25          0.015591           1.193771  0.093057  ...  0.027078   \n",
       "26          0.016830           0.210213  0.068673  ...  0.022704   \n",
       "27          0.020689           0.042492 -0.119917  ... -0.052348   \n",
       "28          0.018784           0.819410 -0.079841  ... -0.036036   \n",
       "29          0.024521          -0.432317 -0.052053  ... -0.032359   \n",
       "30          0.018667           0.009255 -0.053582  ... -0.024210   \n",
       "31          0.021243          -2.407801 -0.050759  ... -0.029512   \n",
       "32          0.014265           1.084984  0.142295  ...  0.037404   \n",
       "33          0.013322          -0.854400 -0.229559  ... -0.063979   \n",
       "34          0.019133           0.457169  0.163445  ...  0.063907   \n",
       "35          0.016311           0.109464  0.220724  ...  0.071830   \n",
       "36          0.011486           0.460151  0.377920  ...  0.093796   \n",
       "37          0.016625          -1.208602 -0.233845  ... -0.073694   \n",
       "38          0.011159          -0.319110  0.070744  ...  0.014706   \n",
       "39          0.018418          -0.323141 -0.022526  ... -0.012628   \n",
       "40          0.013600           0.531282  0.315799  ...  0.096767   \n",
       "41          0.013544          -0.364063 -0.208150  ... -0.056558   \n",
       "42          0.010980          -0.043075  0.191883  ...  0.046071   \n",
       "43          0.010727           0.960212  0.182432  ...  0.042701   \n",
       "44          0.011294           0.956637  0.433843  ...  0.101379   \n",
       "45          0.012836           0.171295 -0.026400  ... -0.009561   \n",
       "46          0.021835           3.178360  0.133483  ...  0.055359   \n",
       "47          0.010612           1.008367  0.309251  ...  0.070033   \n",
       "48          0.014740          -0.237913  0.060830  ...  0.016786   \n",
       "49          0.024464          -2.053341 -0.033623  ... -0.020980   \n",
       "\n",
       "    next_month_return  cum_ret6  cum_ret12         asset  netIncome_x  \\\n",
       "0            0.122369  0.207149   0.550332           NaN          NaN   \n",
       "1            0.093134  0.225078   1.268206           NaN          NaN   \n",
       "2            0.054376  0.235717   1.237475  7.574000e+09          NaN   \n",
       "3           -0.107557  0.465642   0.985761  7.574000e+09          NaN   \n",
       "4           -0.121446  0.118949   0.775096  7.574000e+09          NaN   \n",
       "5           -0.017587 -0.084969   0.399803  7.612000e+09          NaN   \n",
       "6           -0.034372 -0.003568   0.202842  7.612000e+09          NaN   \n",
       "7            0.237301 -0.142721   0.050233  7.612000e+09          NaN   \n",
       "8            0.042853 -0.029660   0.199065  7.612000e+09          NaN   \n",
       "9            0.006322 -0.040264   0.406629  9.100000e+09          NaN   \n",
       "10           0.183038  0.082200   0.210927  9.100000e+09          NaN   \n",
       "11           0.009655  0.457263   0.333440  7.612000e+09          NaN   \n",
       "12           0.005977  0.497673   0.492330  7.612000e+09          NaN   \n",
       "13           0.064163  0.560252   0.337571  7.612000e+09          NaN   \n",
       "14           0.114560  0.341924   0.302123  9.696000e+09          NaN   \n",
       "15          -0.000801  0.434195   0.376448  9.696000e+09          NaN   \n",
       "16           0.024865  0.424044   0.541100  9.696000e+09          NaN   \n",
       "17          -0.175113  0.233647   0.797749  8.649000e+09          NaN   \n",
       "18          -0.125474  0.007889   0.509488  8.649000e+09          NaN   \n",
       "19          -0.152428 -0.123812   0.367075  8.649000e+09          NaN   \n",
       "20           0.186240 -0.302144  -0.063530  9.696000e+09          NaN   \n",
       "21           0.011600 -0.257263   0.065229  9.696000e+09          NaN   \n",
       "22          -0.068533 -0.248045   0.070817  9.696000e+09          NaN   \n",
       "23           0.215860 -0.316572  -0.156891  9.696000e+09          NaN   \n",
       "24           0.027078  0.007353   0.015300  9.696000e+09          NaN   \n",
       "25           0.022704  0.183076   0.036597  9.696000e+09          NaN   \n",
       "26          -0.052348  0.427531  -0.003789  9.057000e+09          NaN   \n",
       "27          -0.036036  0.140413  -0.152973  9.057000e+09          NaN   \n",
       "28          -0.032359  0.086711  -0.182842  9.057000e+09          NaN   \n",
       "29          -0.024210  0.128915  -0.228468  9.413000e+09          NaN   \n",
       "30          -0.029512 -0.093988  -0.087326  9.413000e+09          NaN   \n",
       "31           0.037404 -0.143907   0.012822  9.413000e+09          NaN   \n",
       "32          -0.063979 -0.131602   0.239665  9.057000e+09          NaN   \n",
       "33           0.063907 -0.142261  -0.021824  9.057000e+09          NaN   \n",
       "34           0.071830 -0.053331   0.028755  9.057000e+09          NaN   \n",
       "35           0.093796  0.048599   0.183779  1.053600e+10          NaN   \n",
       "36          -0.073694  0.175410   0.064935  1.053600e+10          NaN   \n",
       "37           0.014706  0.121899  -0.039551  1.053600e+10          NaN   \n",
       "38          -0.012628  0.097352  -0.047061  1.053600e+10          NaN   \n",
       "39           0.096767  0.157554  -0.007121  1.053600e+10          NaN   \n",
       "40          -0.056558  0.193306   0.129666  1.053600e+10          NaN   \n",
       "41           0.046071  0.050368   0.101414  1.053600e+10          NaN   \n",
       "42           0.042701  0.004537   0.180743  1.053600e+10          NaN   \n",
       "43           0.101379  0.130762   0.268600  1.053600e+10          NaN   \n",
       "44          -0.009561  0.227348   0.346833  1.027800e+10          NaN   \n",
       "45           0.055359  0.231161   0.425136  1.027800e+10          NaN   \n",
       "46           0.070033  0.184679   0.413685  1.027800e+10          NaN   \n",
       "47           0.016786  0.343640   0.411315  1.053600e+10          NaN   \n",
       "48          -0.020980  0.306025   0.311951  1.053600e+10          NaN   \n",
       "49          -0.017741  0.226262   0.386610  1.053600e+10          NaN   \n",
       "\n",
       "    netIncome_y   liabilities  currentAsset  currentLiablities  \n",
       "0           NaN           NaN           NaN                NaN  \n",
       "1           NaN           NaN           NaN                NaN  \n",
       "2           NaN  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "3           NaN  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "4           NaN  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "5           NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "6           NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "7           NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "8           NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "9           NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "10          NaN  5.098000e+09  3.961000e+09       1.123000e+09  \n",
       "11          NaN  6.460000e+09  6.169000e+09       3.083000e+09  \n",
       "12          NaN  6.460000e+09  6.169000e+09       3.083000e+09  \n",
       "13          NaN  6.460000e+09  6.169000e+09       3.083000e+09  \n",
       "14          NaN  4.705000e+09  6.169000e+09       1.406000e+09  \n",
       "15          NaN  4.705000e+09  6.169000e+09       1.406000e+09  \n",
       "16          NaN  4.705000e+09  6.169000e+09       1.406000e+09  \n",
       "17          NaN  4.688000e+09  5.096000e+09       3.083000e+09  \n",
       "18          NaN  4.688000e+09  5.096000e+09       3.083000e+09  \n",
       "19          NaN  4.688000e+09  5.096000e+09       3.083000e+09  \n",
       "20          NaN  4.553000e+09  5.223000e+09       1.505000e+09  \n",
       "21          NaN  4.553000e+09  5.223000e+09       1.505000e+09  \n",
       "22          NaN  4.553000e+09  5.223000e+09       1.505000e+09  \n",
       "23          NaN  4.741000e+09  6.169000e+09       1.837000e+09  \n",
       "24          NaN  4.741000e+09  6.169000e+09       1.837000e+09  \n",
       "25          NaN  4.741000e+09  6.169000e+09       1.837000e+09  \n",
       "26          NaN  4.600000e+09  5.569000e+09       1.837000e+09  \n",
       "27          NaN  4.600000e+09  5.569000e+09       1.837000e+09  \n",
       "28          NaN  4.600000e+09  5.569000e+09       1.837000e+09  \n",
       "29          NaN  4.741000e+09  6.010000e+09       1.837000e+09  \n",
       "30          NaN  4.741000e+09  6.010000e+09       1.837000e+09  \n",
       "31          NaN  4.741000e+09  6.010000e+09       1.837000e+09  \n",
       "32          NaN  4.741000e+09  4.211000e+09       1.837000e+09  \n",
       "33          NaN  4.741000e+09  4.211000e+09       1.837000e+09  \n",
       "34          NaN  4.741000e+09  4.211000e+09       1.837000e+09  \n",
       "35          NaN  4.741000e+09  4.629000e+09       1.893000e+09  \n",
       "36          NaN  4.741000e+09  4.629000e+09       1.893000e+09  \n",
       "37          NaN  4.741000e+09  4.629000e+09       1.893000e+09  \n",
       "38          NaN  5.302000e+09  4.712000e+09       1.846000e+09  \n",
       "39          NaN  5.302000e+09  4.712000e+09       1.846000e+09  \n",
       "40          NaN  5.302000e+09  4.712000e+09       1.846000e+09  \n",
       "41          NaN  5.351000e+09  4.818000e+09       1.893000e+09  \n",
       "42          NaN  5.351000e+09  4.818000e+09       1.893000e+09  \n",
       "43          NaN  5.351000e+09  4.818000e+09       1.893000e+09  \n",
       "44          NaN  5.488000e+09  4.629000e+09       1.550000e+09  \n",
       "45          NaN  5.488000e+09  4.629000e+09       1.550000e+09  \n",
       "46          NaN  5.488000e+09  4.629000e+09       1.550000e+09  \n",
       "47          NaN  5.397000e+09  4.629000e+09       1.893000e+09  \n",
       "48          NaN  5.397000e+09  4.629000e+09       1.893000e+09  \n",
       "49          NaN  5.397000e+09  4.629000e+09       1.893000e+09  \n",
       "\n",
       "[50 rows x 21 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lc_data4=all_lc_data3[(all_lc_data3['year'] >= 2010) & (all_lc_data3['year'] <= 2022)]\n",
    "all_lc_data4.sort_values(by=['symbol','year','month'])\n",
    "final_data3 = pd.merge(final_data3, all_lc_data4, how='left', on=['symbol', 'year', 'month'])\n",
    "final_data4 = final_data3[(final_data3['year'] >= 2010) & (final_data3['year'] <= 2022)]\n",
    "final_data4 = final_data4.fillna(method='ffill').reset_index()\n",
    "\n",
    "final_data4.drop(columns=['index'],inplace=True)\n",
    "final_data4.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_data4.drop(columns=['netIncome_x','netIncome_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>currentAsset</th>\n",
       "      <th>currentLiablities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>3.961000e+09</td>\n",
       "      <td>2.549000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73641</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>156.529999</td>\n",
       "      <td>154.786163</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.131837</td>\n",
       "      <td>-0.429848</td>\n",
       "      <td>180.516296</td>\n",
       "      <td>-0.142536</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>-0.188785</td>\n",
       "      <td>-0.229898</td>\n",
       "      <td>1.390000e+10</td>\n",
       "      <td>9.190000e+09</td>\n",
       "      <td>6.930000e+09</td>\n",
       "      <td>3.051000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73642</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>148.289993</td>\n",
       "      <td>146.637955</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.549872</td>\n",
       "      <td>-0.143875</td>\n",
       "      <td>154.786163</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>-0.210869</td>\n",
       "      <td>-0.231280</td>\n",
       "      <td>1.390000e+10</td>\n",
       "      <td>9.190000e+09</td>\n",
       "      <td>6.930000e+09</td>\n",
       "      <td>3.051000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73643</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>150.779999</td>\n",
       "      <td>149.417023</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>-0.199821</td>\n",
       "      <td>0.058510</td>\n",
       "      <td>146.637955</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.145965</td>\n",
       "      <td>-0.297473</td>\n",
       "      <td>1.390000e+10</td>\n",
       "      <td>9.190000e+09</td>\n",
       "      <td>6.930000e+09</td>\n",
       "      <td>3.051000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73644</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>154.139999</td>\n",
       "      <td>152.746674</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>-1.137458</td>\n",
       "      <td>0.046623</td>\n",
       "      <td>149.417023</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>-0.094653</td>\n",
       "      <td>-0.300707</td>\n",
       "      <td>1.367400e+10</td>\n",
       "      <td>9.012000e+09</td>\n",
       "      <td>6.551000e+09</td>\n",
       "      <td>2.880000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73645</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>146.550003</td>\n",
       "      <td>145.225266</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.433639</td>\n",
       "      <td>-0.147044</td>\n",
       "      <td>152.746674</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>0.131893</td>\n",
       "      <td>-0.144040</td>\n",
       "      <td>-0.395053</td>\n",
       "      <td>1.367400e+10</td>\n",
       "      <td>9.012000e+09</td>\n",
       "      <td>6.551000e+09</td>\n",
       "      <td>2.880000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73646 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      symbol  year  month       Date       Close   adj_close  \\\n",
       "0          A  2010      1 2010-01-29   20.050072   18.079800   \n",
       "1          A  2010      2 2010-02-26   22.503576   20.292213   \n",
       "2          A  2010      3 2010-03-31   24.599428   22.182100   \n",
       "3          A  2010      4 2010-04-30   25.937054   23.388283   \n",
       "4          A  2010      5 2010-05-28   23.147352   20.872721   \n",
       "...      ...   ...    ...        ...         ...         ...   \n",
       "73641    ZTS  2022      8 2022-08-31  156.529999  154.786163   \n",
       "73642    ZTS  2022      9 2022-09-30  148.289993  146.637955   \n",
       "73643    ZTS  2022     10 2022-10-31  150.779999  149.417023   \n",
       "73644    ZTS  2022     11 2022-11-30  154.139999  152.746674   \n",
       "73645    ZTS  2022     12 2022-12-30  146.550003  145.225266   \n",
       "\n",
       "       avrg_return_daily  std_return_daily  skew_return_daily    Sharpe  \\\n",
       "0              -0.005306          0.014345          -1.057651 -0.369864   \n",
       "1               0.006162          0.012060           0.795518  0.511000   \n",
       "2               0.003922          0.009486           0.943496  0.413428   \n",
       "3               0.002628          0.014793           0.484652  0.177654   \n",
       "4              -0.005176          0.032369           0.345697 -0.159907   \n",
       "...                  ...               ...                ...       ...   \n",
       "73641          -0.006552          0.015242           0.131837 -0.429848   \n",
       "73642          -0.002436          0.016930           0.549872 -0.143875   \n",
       "73643           0.001047          0.017897          -0.199821  0.058510   \n",
       "73644           0.001700          0.036468          -1.137458  0.046623   \n",
       "73645          -0.002287          0.015551           0.433639 -0.147044   \n",
       "\n",
       "       prev_price    return  next_month_return  cum_ret6  cum_ret12  \\\n",
       "0       20.040653 -0.097844           0.122369  0.207149   0.550332   \n",
       "1       18.079800  0.122369           0.093134  0.225078   1.268206   \n",
       "2       20.292213  0.093134           0.054376  0.235717   1.237475   \n",
       "3       22.182100  0.054376          -0.107557  0.465642   0.985761   \n",
       "4       23.388283 -0.107557          -0.121446  0.118949   0.775096   \n",
       "...           ...       ...                ...       ...        ...   \n",
       "73641  180.516296 -0.142536          -0.052642 -0.188785  -0.229898   \n",
       "73642  154.786163 -0.052642           0.018952 -0.210869  -0.231280   \n",
       "73643  146.637955  0.018952           0.022284 -0.145965  -0.297473   \n",
       "73644  149.417023  0.022284          -0.049241 -0.094653  -0.300707   \n",
       "73645  152.746674 -0.049241           0.131893 -0.144040  -0.395053   \n",
       "\n",
       "              asset   liabilities  currentAsset  currentLiablities  \n",
       "0               NaN           NaN           NaN                NaN  \n",
       "1               NaN           NaN           NaN                NaN  \n",
       "2      7.574000e+09  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "3      7.574000e+09  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "4      7.574000e+09  5.098000e+09  3.961000e+09       2.549000e+09  \n",
       "...             ...           ...           ...                ...  \n",
       "73641  1.390000e+10  9.190000e+09  6.930000e+09       3.051000e+09  \n",
       "73642  1.390000e+10  9.190000e+09  6.930000e+09       3.051000e+09  \n",
       "73643  1.390000e+10  9.190000e+09  6.930000e+09       3.051000e+09  \n",
       "73644  1.367400e+10  9.012000e+09  6.551000e+09       2.880000e+09  \n",
       "73645  1.367400e+10  9.012000e+09  6.551000e+09       2.880000e+09  \n",
       "\n",
       "[73646 rows x 19 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final_data5['ROA']=final_data5['netIncome']/final_data5['asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data4['CR']=final_data4['currentAsset']/final_data4['currentLiablities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data4['DR']=final_data4['liabilities']/final_data4['asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Close','avrg_return_daily','std_return_daily','skew_return_daily','Sharpe','return','cum_ret6','cum_ret12','CR','DR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=final_data4[features]\n",
    "y=final_data4['next_month_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8,test_size=0.25)\n",
    "_avrg=X_train.mean()\n",
    "_std=X_train.std()\n",
    "X_train=(X_train - _avrg)/ (_std)\n",
    "X_test=(X_test - _avrg)/ (_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['CR']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Impute missing values in X_train\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose other strategies as well\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Define Ridge regression model\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "parameter = {'alpha': [a for a in range(1000, 200000, 100)]}\n",
    "\n",
    "# Perform GridSearchCV with Ridge model\n",
    "my_ridge = GridSearchCV(ridge_model, param_grid=parameter, return_train_score=True, cv=5).fit(X_train_imputed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1900)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1900)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1900)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.01617195743579647\n",
      "Test R^2: 0.016398453176121097\n",
      "Train MSE: 0.007058692555299072\n",
      "Test MSE: 0.0067377570818543606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['CR']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['CR']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Replace infinite values with a large finite value\n",
    "X_train_imputed = np.where(np.isfinite(X_train_imputed), X_train_imputed, 1e10)\n",
    "X_test_imputed = np.where(np.isfinite(X_test_imputed), X_test_imputed, 1e10)\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Define Ridge regression model\n",
    "ridge_model = Ridge(alpha=19)\n",
    "\n",
    "# Fit the Ridge model\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Train R^2:\", ridge_model.score(X_train_scaled, y_train))\n",
    "print(\"Test R^2:\", ridge_model.score(X_test_scaled, y_test))\n",
    "print(\"Train MSE:\", mean_squared_error(y_train, ridge_model.predict(X_train_scaled)))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, ridge_model.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7976931348623157e+308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'max_leaf_nodes': 6, 'min_samples_leaf': 6, 'min_samples_split': 20}\n",
      "Best Score: 0.022652394119179763\n"
     ]
    }
   ],
   "source": [
    "X_train = np.where(np.isfinite(X_train), X_train, np.nan)\n",
    "print(np.max(np.abs(X_train)))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth': [3], 'min_samples_leaf': [6], 'min_samples_split': [20], 'max_leaf_nodes': [6]}\n",
    "model = DecisionTreeRegressor()\n",
    "my_dfr = GridSearchCV(model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", my_dfr.best_params_)\n",
    "print(\"Best Score:\", my_dfr.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter set {'max_depth': 3} raised an exception:\n",
      "Parameter grid for parameter 'max_depth' needs to be a list or a numpy array, but got 3 (of type int) instead. Single values need to be wrapped in a list with one element.\n",
      "Parameter set {'min_samples_leaf': 6} raised an exception:\n",
      "Parameter grid for parameter 'min_samples_leaf' needs to be a list or a numpy array, but got 6 (of type int) instead. Single values need to be wrapped in a list with one element.\n",
      "Parameter set {'min_samples_split': 20} raised an exception:\n",
      "Parameter grid for parameter 'min_samples_split' needs to be a list or a numpy array, but got 20 (of type int) instead. Single values need to be wrapped in a list with one element.\n",
      "Parameter set {'max_leaf_nodes': 6} raised an exception:\n",
      "Parameter grid for parameter 'max_leaf_nodes' needs to be a list or a numpy array, but got 6 (of type int) instead. Single values need to be wrapped in a list with one element.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3],\n",
    "    'min_samples_leaf': [6],\n",
    "    'min_samples_split': [20],\n",
    "    'max_leaf_nodes': [6]\n",
    "}\n",
    "\n",
    "_model = DecisionTreeRegressor()\n",
    "\n",
    "# Try each parameter setting separately to identify the problematic one\n",
    "for param_name, param_values in parameters.items():\n",
    "    for param_value in param_values:\n",
    "        param_set = {param_name: param_value}\n",
    "        try:\n",
    "            my_dfr = GridSearchCV(_model, param_grid=param_set, return_train_score=True, cv=5).fit(X_train, y_train)\n",
    "            print(f\"Parameter set {param_set} works without issues.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Parameter set {param_set} raised an exception:\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3, max_leaf_nodes=6, min_samples_leaf=6,\n",
       "                      min_samples_split=20)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: False\n",
      "Infinite values in X_train: False\n",
      "NaN values in y_train: False\n",
      "Infinite values in y_train: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 0.028577021524121782\n",
      "Testing R-squared: -0.0002734376761412971\n",
      "Mean Squared Error on Training Set: 0.006969689670912845\n",
      "Mean Squared Error on Test Set: 0.006851961000118275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check for NaN or Infinite Values in X_train\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train).any())\n",
    "print(\"Infinite values in X_train:\", np.isinf(X_train).any())\n",
    "\n",
    "# Handle Missing Values (if any)\n",
    "# You can use a method like mean imputation\n",
    "# X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "# Scale or Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Check Target Values (y_train)\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).any())\n",
    "print(\"Infinite values in y_train:\", np.isinf(y_train).any())\n",
    "\n",
    "# Handle Outliers (if any)\n",
    "# You can use winsorization or other outlier handling techniques\n",
    "\n",
    "# Define the DecisionTreeRegressor parameters\n",
    "parameters = {\n",
    "    'max_depth': [3],\n",
    "    'min_samples_leaf': [6],\n",
    "    'min_samples_split': [20],\n",
    "    'max_leaf_nodes': [6]\n",
    "}\n",
    "\n",
    "# Create the DecisionTreeRegressor model\n",
    "_model = DecisionTreeRegressor()\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "my_dfr = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on training and test sets\n",
    "print(\"Training R-squared:\", my_dfr.score(X_train_scaled, y_train))\n",
    "print(\"Testing R-squared:\", my_dfr.score(X_test, y_test))\n",
    "\n",
    "# Print Mean Squared Error on training and test sets\n",
    "print(\"Mean Squared Error on Training Set:\", mean_squared_error(y_train, my_dfr.predict(X_train_scaled)))\n",
    "print(\"Mean Squared Error on Test Set:\", mean_squared_error(y_test, my_dfr.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: False\n",
      "NaN values in y_train: False\n",
      "NaN values in X_train_imputed: False\n",
      "Infinite values in X_train_imputed: False\n",
      "NaN values in X_train_scaled: False\n",
      "Infinite values in X_train_scaled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: [8]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 0.044416339458773546\n",
      "Best parameters: {'max_depth': 6, 'max_leaf_nodes': 12, 'min_samples_leaf': 6, 'min_samples_split': 50, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Check for NaN values in the original data\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train).any())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).any())\n",
    "\n",
    "# Use SimpleImputer to fill NaN values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "# Check for NaN or infinite values after imputation and scaling\n",
    "print(\"NaN values in X_train_imputed:\", np.isnan(X_train_imputed).any())\n",
    "print(\"Infinite values in X_train_imputed:\", np.isinf(X_train_imputed).any())\n",
    "print(\"NaN values in X_train_scaled:\", np.isnan(X_train_scaled).any())\n",
    "print(\"Infinite values in X_train_scaled:\", np.isinf(X_train_scaled).any())\n",
    "\n",
    "# Define the parameter grid for RandomForestRegressor\n",
    "parameters = {\n",
    "    'n_estimators': [50, 60, 100],\n",
    "    'max_depth': [3, 4, 6],\n",
    "    'min_samples_leaf': [6, 20],\n",
    "    'min_samples_split': [20, 50],\n",
    "    'max_leaf_nodes': [6, 12]\n",
    "}\n",
    "\n",
    "# Create a RandomForestRegressor instance\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "my_rfr = GridSearchCV(rf_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on training and test sets\n",
    "print(\"Training R-squared:\", my_rfr.score(X_train_scaled, y_train))\n",
    "print(\"Best parameters:\", my_rfr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=6, max_leaf_nodes=12, min_samples_leaf=6,\n",
       "                      min_samples_split=50, n_estimators=50)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: False\n",
      "NaN values in y_train: False\n",
      "NaN values in X_test: Close                False\n",
      "avrg_return_daily    False\n",
      "std_return_daily     False\n",
      "skew_return_daily    False\n",
      "Sharpe               False\n",
      "return               False\n",
      "cum_ret6             False\n",
      "cum_ret12            False\n",
      "CR                   False\n",
      "DR                   False\n",
      "dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: [8]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: [8]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 0.042389442827793444\n",
      "Testing R-squared: 0.0216392814548505\n",
      "Training MSE: 0.006870589389960527\n",
      "Testing MSE: 0.006701856947329547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Check for NaN values in the original data\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train_finite).any())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train_finite).any())\n",
    "print(\"NaN values in X_test:\", np.isnan(X_test).any())  # Add this line\n",
    "\n",
    "# Use SimpleImputer to fill NaN values with the mean of each column\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train_imputed = imputer.fit_transform(X_train_finite)\n",
    "X_test_imputed = imputer.transform(X_test)  # Use the same imputer for the test set\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Create and fit the RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(n_estimators=5, max_depth=6, min_samples_leaf=6, min_samples_split=50, max_leaf_nodes=12)\n",
    "rfr_model.fit(X_train_scaled, y_train_finite)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Training R-squared:\", rfr_model.score(X_train_scaled, y_train_finite))\n",
    "print(\"Testing R-squared:\", rfr_model.score(X_test_scaled, y_test))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train_finite, rfr_model.predict(X_train_scaled)))\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, rfr_model.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [      -inf       -inf       -inf 0.00482339 0.00313839 0.00253865\n",
      "       -inf       -inf       -inf]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:987: RuntimeWarning: invalid value encountered in subtract\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [      -inf       -inf       -inf 0.00742742 0.003312   0.00366105\n",
      "       -inf       -inf       -inf]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'solver': ['lbfgs'],  # Wrap the single value in a list\n",
    "    'alpha': [0],  # Wrap the single value in a list\n",
    "    'hidden_layer_sizes': [(100), (10, 10), (10, 20)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0, hidden_layer_sizes=100,\n",
       "             max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf -1452288139928737.8\n",
      "inf\n",
      "9948301455294.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1005: RuntimeWarning: overflow encountered in square\n",
      "  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPRegressor(solver='lbfgs', alpha=0, hidden_layer_sizes=100, max_iter=1000).fit(X_train, y_train)\n",
    "print(mlp_model.score(X_train, y_train), mlp_model.score(X_test, y_test))\n",
    "\n",
    "print(mean_squared_error(y_train, mlp_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test, mlp_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:276: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_stochastic_optimizers.py:285: RuntimeWarning: invalid value encountered in divide\n",
      "  -self.learning_rate * m / (np.sqrt(v) + self.epsilon)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "215 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "215 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -1.37290425e-01 -1.41592032e-01 -5.89213943e-02 -1.00052888e-01\n",
      " -1.38127704e-02 -4.47448141e-03 -1.05353676e-02 -4.90201501e-02\n",
      "  1.87708873e-04 -5.22150607e-02 -2.70075817e-02 -8.69378785e-02\n",
      " -1.03924537e-02 -3.38205450e-02 -2.45986418e-02 -1.70516889e-01\n",
      "  6.20567385e-04  2.27564528e-03 -3.53844679e-02 -2.56421573e-02\n",
      "  2.76550473e-05  5.28567048e-03 -3.13417641e-02 -7.42215641e-02\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.1392356  -0.13946998 -0.03944039 -0.11468893 -0.01208329  0.00447642\n",
      " -0.01080173 -0.04475662  0.00097434 -0.04182906 -0.03023962 -0.08094742\n",
      " -0.00735953 -0.0261281  -0.02501536 -0.16601087  0.00082589  0.01312106\n",
      " -0.03367254 -0.02759544 -0.00087325  0.01033107 -0.02879274 -0.07085978\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 20), (10, 10)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000],\n",
    "    'learning_rate_init': [0.01, 0.1],\n",
    "    'batch_size': [20, 50]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp1 = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.01,\n",
       "             max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.01,\n",
       "             max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0, batch_size=50,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate_init=0.01,\n",
       "             max_iter=1000)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016760458553819912 0.0003230679190108221\n",
      "0.007054470223467839\n",
      "0.006847874884341943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp1_model=MLPRegressor(alpha=0,hidden_layer_sizes=(10,10),activation='logistic',max_iter=1000,learning_rate_init=0.01,batch_size=50).fit(X_train,y_train)\n",
    "print(mlp1_model.score(X_train,y_train),mlp1_model.score(X_test,y_test))\n",
    "\n",
    "print(mean_squared_error(y_train,mlp1_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp1_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik=companyData.iloc[0,3]\n",
    "type(cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cik', 'entityName', 'facts'])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json',headers=headers )\n",
    "\n",
    "#review data\n",
    "companyFacts.json().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The aggregate market value of the voting and non-voting common equity held by non-affiliates computed by reference to the price at which the common equity was last sold, or the average bid and asked price of such common equity, as of the last business day of the registrant's most recently completed second fiscal quarter.\""
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['dei']['EntityPublicFloat']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AccountsPayable', 'AccountsPayableCurrent', 'AccountsReceivableNetCurrent', 'AccruedIncomeTaxesCurrent', 'AccruedIncomeTaxesNoncurrent', 'AccruedLiabilities', 'AccruedLiabilitiesCurrent', 'AccruedMarketingCostsCurrent', 'AccumulatedDepreciationDepletionAndAmortizationPropertyPlantAndEquipment', 'AccumulatedOtherComprehensiveIncomeLossAvailableForSaleSecuritiesAdjustmentNetOfTax', 'AccumulatedOtherComprehensiveIncomeLossCumulativeChangesInNetGainLossFromCashFlowHedgesEffectNetOfTax', 'AccumulatedOtherComprehensiveIncomeLossForeignCurrencyTranslationAdjustmentNetOfTax', 'AccumulatedOtherComprehensiveIncomeLossNetOfTax', 'AdjustmentsToAdditionalPaidInCapitalSharebasedCompensationRequisiteServicePeriodRecognitionValue', 'AdjustmentsToAdditionalPaidInCapitalTaxEffectFromShareBasedCompensation', 'AdvertisingExpense', 'AllocatedShareBasedCompensationExpense', 'AllowanceForDoubtfulAccountsReceivableCurrent', 'AmortizationOfIntangibleAssets', 'AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount', 'Assets', 'AssetsCurrent', 'AssetsNoncurrent', 'AvailableForSaleDebtSecuritiesAccumulatedGrossUnrealizedGainBeforeTax', 'AvailableForSaleDebtSecuritiesAccumulatedGrossUnrealizedLossBeforeTax', 'AvailableForSaleDebtSecuritiesAmortizedCostBasis', 'AvailableForSaleSecurities', 'AvailableForSaleSecuritiesAccumulatedGrossUnrealizedGainBeforeTax', 'AvailableForSaleSecuritiesAccumulatedGrossUnrealizedLossBeforeTax', 'AvailableForSaleSecuritiesAmortizedCost', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPosition12MonthsOrLongerAccumulatedLoss', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPositionAccumulatedLoss', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPositionFairValue', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPositionLessThan12MonthsAccumulatedLoss', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPositionLessThanTwelveMonthsFairValue', 'AvailableForSaleSecuritiesContinuousUnrealizedLossPositionTwelveMonthsOrLongerFairValue', 'AvailableForSaleSecuritiesCurrent', 'AvailableForSaleSecuritiesDebtMaturitiesRollingAfterYearTenFairValue', 'AvailableForSaleSecuritiesDebtMaturitiesRollingYearSixThroughTenFairValue', 'AvailableForSaleSecuritiesDebtMaturitiesRollingYearTwoThroughFiveFairValue', 'AvailableForSaleSecuritiesDebtMaturitiesSingleMaturityDate', 'AvailableForSaleSecuritiesDebtSecurities', 'AvailableForSaleSecuritiesDebtSecuritiesCurrent', 'AvailableForSaleSecuritiesDebtSecuritiesNoncurrent', 'AvailableForSaleSecuritiesFairValueDisclosure', 'AvailableForSaleSecuritiesGrossUnrealizedLosses1', 'AvailableForSaleSecuritiesNoncurrent', 'AvailableforsaleSecuritiesGrossUnrealizedGain', 'BusinessAcquisitionCostOfAcquiredEntityPurchasePrice', 'BusinessAcquisitionPurchasePriceAllocationAmortizableIntangibleAssets', 'BusinessAcquisitionPurchasePriceAllocationGoodwillAmount', 'BusinessAcquisitionPurchasePriceAllocationLiabilitiesAssumed', 'BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill', 'BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedLiabilities', 'CapitalExpendituresIncurredButNotYetPaid', 'CapitalizedComputerSoftwareAdditions', 'CapitalizedComputerSoftwareAmortization', 'Cash', 'CashAndCashEquivalentsAtCarryingValue', 'CashAndCashEquivalentsPeriodIncreaseDecrease', 'CashCashEquivalentsRestrictedCashAndRestrictedCashEquivalents', 'CashCashEquivalentsRestrictedCashAndRestrictedCashEquivalentsPeriodIncreaseDecreaseIncludingExchangeRateEffect', 'CashEquivalentsAtCarryingValue', 'ChangeInUnrealizedGainLossOnFairValueHedgingInstruments', 'CollateralAlreadyPostedAggregateFairValue', 'CommercialPaper', 'CommitmentsAndContingencies', 'CommonStockDividendsPerShareCashPaid', 'CommonStockDividendsPerShareDeclared', 'CommonStockNoParValue', 'CommonStockParOrStatedValuePerShare', 'CommonStockSharesAuthorized', 'CommonStockSharesIssued', 'CommonStockSharesOutstanding', 'CommonStocksIncludingAdditionalPaidInCapital', 'CommonStockValue', 'ComprehensiveIncomeNetOfTax', 'ContractWithCustomerLiability', 'ContractWithCustomerLiabilityCurrent', 'ContractWithCustomerLiabilityRevenueRecognized', 'CostOfGoodsAndServicesSold', 'CostOfGoodsAndServicesSoldDepreciation', 'CostOfReimbursableExpense', 'CumulativeEffectOfInitialAdoptionOfFIN48', 'CumulativeEffectOfInitialAdoptionOfNewAccountingPrinciple', 'CurrentFederalTaxExpenseBenefit', 'CurrentForeignTaxExpenseBenefit', 'CurrentStateAndLocalTaxExpenseBenefit', 'DebtInstrumentCarryingAmount', 'DebtInstrumentUnamortizedDiscount', 'DebtInstrumentUnamortizedDiscountPremiumAndDebtIssuanceCostsNet', 'DebtInstrumentUnamortizedDiscountPremiumNet', 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPosition12MonthsOrLonger', 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPosition12MonthsOrLongerAccumulatedLoss', 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPositionLessThan12Months', 'DebtSecuritiesAvailableForSaleContinuousUnrealizedLossPositionLessThan12MonthsAccumulatedLoss', 'DebtSecuritiesAvailableForSaleUnrealizedLossPosition', 'DebtSecuritiesAvailableForSaleUnrealizedLossPositionAccumulatedLoss', 'DecreaseInUnrecognizedTaxBenefitsIsReasonablyPossible', 'DeferredFederalIncomeTaxExpenseBenefit', 'DeferredForeignIncomeTaxExpenseBenefit', 'DeferredIncomeTaxExpenseBenefit', 'DeferredIncomeTaxLiabilities', 'DeferredIncomeTaxLiabilitiesNet', 'DeferredRevenueCurrent', 'DeferredRevenueNoncurrent', 'DeferredStateAndLocalIncomeTaxExpenseBenefit', 'DeferredTaxAssetsDeferredIncome', 'DeferredTaxAssetsGoodwillAndIntangibleAssets', 'DeferredTaxAssetsGross', 'DeferredTaxAssetsLiabilitiesNet', 'DeferredTaxAssetsLiabilitiesNetCurrent', 'DeferredTaxAssetsNet', 'DeferredTaxAssetsNetCurrent', 'DeferredTaxAssetsOther', 'DeferredTaxAssetsPropertyPlantAndEquipment', 'DeferredTaxAssetsTaxCreditCarryforwards', 'DeferredTaxAssetsTaxCreditCarryforwardsForeign', 'DeferredTaxAssetsTaxCreditCarryforwardsResearch', 'DeferredTaxAssetsTaxDeferredExpenseCompensationAndBenefitsShareBasedCompensationCost', 'DeferredTaxAssetsTaxDeferredExpenseReservesAndAccruals', 'DeferredTaxAssetsUnrealizedLossesOnAvailableforSaleSecuritiesGross', 'DeferredTaxAssetsValuationAllowance', 'DeferredTaxLiabilities', 'DeferredTaxLiabilitiesLeasingArrangements', 'DeferredTaxLiabilitiesNoncurrent', 'DeferredTaxLiabilitiesOther', 'DeferredTaxLiabilitiesOtherComprehensiveIncome', 'DeferredTaxLiabilitiesUndistributedForeignEarnings', 'DeferredTaxLiabilityNotRecognizedAmountOfUnrecognizedDeferredTaxLiabilityUndistributedEarningsOfForeignSubsidiaries', 'DefinedContributionPlanCostRecognized', 'DefinedContributionPlanMaximumAnnualContributionPerEmployeeAmount', 'DefinedContributionPlanMaximumAnnualContributionsPerEmployeeAmount', 'Depreciation', 'DepreciationAmortizationAndAccretionNet', 'DepreciationAndAmortization', 'DepreciationDepletionAndAmortization', 'DerivativeCollateralObligationToReturnCash', 'DerivativeFairValueOfDerivativeNet', 'DerivativeInstrumentsGainLossReclassifiedFromAccumulatedOCIIntoIncomeEffectivePortionNet', 'DerivativeInstrumentsGainLossRecognizedInIncomeIneffectivePortionAndAmountExcludedFromEffectivenessTestingNet', 'DerivativeInstrumentsGainLossRecognizedInOtherComprehensiveIncomeEffectivePortionNet', 'DerivativeInstrumentsNotDesignatedAsHedgingInstrumentsGainLossNet', 'Dividends', 'EarningsPerShareBasic', 'EarningsPerShareDiluted', 'EffectiveIncomeTaxRateContinuingOperations', 'EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate', 'EffectiveIncomeTaxRateReconciliationForeignIncomeTaxRateDifferential', 'EffectiveIncomeTaxRateReconciliationShareBasedCompensationExcessTaxBenefitAmount', 'EffectiveIncomeTaxRateReconciliationTaxCutsAndJobsActOf2017Amount', 'EmployeeRelatedLiabilitiesCurrent', 'EmployeeServiceShareBasedCompensationCashFlowEffectCashUsedToSettleAwards', 'EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized', 'EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition', 'EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense', 'EmployeeServiceShareBasedCompensationUnrecognizedCompensationCostsOnNonvestedAwards', 'EmployeeServiceShareBasedCompensationUnrecognizedCompensationCostsOnNonvestedAwardsWeightedAveragePeriodOfRecognition', 'EquitySecuritiesWithoutReadilyDeterminableFairValueAmount', 'ExcessTaxBenefitFromShareBasedCompensationFinancingActivities', 'FairValueAssetsMeasuredOnRecurringBasisCashAndCashEquivalents', 'FairValueAssetsMeasuredOnRecurringBasisDerivativeFinancialInstrumentsAssets', 'FairValueHedgesAtFairValueNet', 'FairValueLiabilitiesMeasuredOnRecurringBasisDerivativeFinancialInstrumentsLiabilities', 'FederalIncomeTaxExpenseBenefitContinuingOperations', 'FinanceLeaseLiability', 'FinanceLeaseLiabilityCurrent', 'FinanceLeaseLiabilityNoncurrent', 'FinanceLeaseLiabilityPaymentsDue', 'FinanceLeaseLiabilityPaymentsDueAfterYearFive', 'FinanceLeaseLiabilityPaymentsDueNextTwelveMonths', 'FinanceLeaseLiabilityPaymentsDueYearFive', 'FinanceLeaseLiabilityPaymentsDueYearFour', 'FinanceLeaseLiabilityPaymentsDueYearThree', 'FinanceLeaseLiabilityPaymentsDueYearTwo', 'FinanceLeaseLiabilityPaymentsRemainderOfFiscalYear', 'FinanceLeaseLiabilityUndiscountedExcessAmount', 'FinanceLeaseRightOfUseAsset', 'FiniteLivedIntangibleAssetsAccumulatedAmortization', 'FiniteLivedIntangibleAssetsAmortizationExpense', 'FiniteLivedIntangibleAssetsAmortizationExpenseAfterYearFive', 'FiniteLivedIntangibleAssetsAmortizationExpenseNextTwelveMonths', 'FiniteLivedIntangibleAssetsAmortizationExpenseYearFive', 'FiniteLivedIntangibleAssetsAmortizationExpenseYearFour', 'FiniteLivedIntangibleAssetsAmortizationExpenseYearThree', 'FiniteLivedIntangibleAssetsAmortizationExpenseYearTwo', 'FiniteLivedIntangibleAssetsGross', 'FiniteLivedIntangibleAssetsNet', 'FiniteLivedIntangibleAssetsUsefulLifeMaximum', 'FiniteLivedIntangibleAssetsUsefulLifeMinimum', 'ForeignCurrencyDerivativeAssetsAtFairValue', 'ForeignCurrencyDerivativeInstrumentsNotDesignatedAsHedgingInstrumentsAssetAtFairValue', 'ForeignCurrencyDerivativeInstrumentsNotDesignatedAsHedgingInstrumentsLiabilityAtFairValue', 'ForeignCurrencyDerivativeLiabilitiesAtFairValue', 'ForeignIncomeTaxExpenseBenefitContinuingOperations', 'FurnitureAndFixturesGross', 'FutureAmortizationExpenseYearFive', 'FutureAmortizationExpenseYearFour', 'FutureAmortizationExpenseYearOne', 'FutureAmortizationExpenseYearThree', 'FutureAmortizationExpenseYearTwo', 'GainLossFromComponentsExcludedFromAssessmentOfFairValueHedgeEffectivenessNet', 'GainLossOnSaleOfPropertyPlantEquipment', 'Goodwill', 'GoodwillAcquiredDuringPeriod', 'GoodwillImpairmentLoss', 'GrossProfit', 'HeldToMaturitySecurities', 'ImpairmentOfIntangibleAssetsExcludingGoodwill', 'ImpairmentOfIntangibleAssetsIndefinitelivedExcludingGoodwill', 'IncomeLossFromContinuingOperationsBeforeIncomeTaxesExtraordinaryItemsNoncontrollingInterest', 'IncomeLossFromContinuingOperationsBeforeIncomeTaxesForeign', 'IncomeLossFromContinuingOperationsBeforeIncomeTaxesMinorityInterestAndIncomeLossFromEquityMethodInvestments', 'IncomeTaxExaminationInterestExpense', 'IncomeTaxExpenseBenefit', 'IncomeTaxesPaidNet', 'IncomeTaxReconciliationDeductionsQualifiedProductionActivities', 'IncomeTaxReconciliationForeignIncomeTaxRateDifferential', 'IncomeTaxReconciliationIncomeTaxExpenseBenefitAtFederalStatutoryIncomeTaxRate', 'IncomeTaxReconciliationNondeductibleExpenseShareBasedCompensationCost', 'IncomeTaxReconciliationOtherAdjustments', 'IncomeTaxReconciliationOtherReconcilingItems', 'IncomeTaxReconciliationStateAndLocalIncomeTaxes', 'IncomeTaxReconciliationTaxContingenciesDomestic', 'IncomeTaxReconciliationTaxCreditsResearch', 'IncomeTaxReconciliationTaxSettlementsDomestic', 'IncreaseDecreaseInAccountsPayable', 'IncreaseDecreaseInAccountsReceivable', 'IncreaseDecreaseInContractWithCustomerLiability', 'IncreaseDecreaseInDeferredRevenue', 'IncreaseDecreaseInInventories', 'IncreaseDecreaseInOtherOperatingAssets', 'IncreaseDecreaseInOtherOperatingLiabilities', 'IncreaseDecreaseInOtherReceivables', 'IndefiniteLivedIntangibleAssetsExcludingGoodwill', 'IntangibleAssetsGrossExcludingGoodwill', 'IntangibleAssetsNetExcludingGoodwill', 'InterestCostsIncurred', 'InterestExpense', 'InterestExpenseDebt', 'InterestPaid', 'InterestPaidNet', 'InventoryFinishedGoodsNetOfReserves', 'InventoryNet', 'InventoryPartsAndComponentsNetOfReserves', 'InvestmentIncomeInterestAndDividend', 'LeaseAndRentalExpense', 'LeaseholdImprovementsGross', 'LesseeOperatingLeaseLiabilityPaymentsDue', 'LesseeOperatingLeaseLiabilityPaymentsDueAfterYearFive', 'LesseeOperatingLeaseLiabilityPaymentsDueNextTwelveMonths', 'LesseeOperatingLeaseLiabilityPaymentsDueYearFive', 'LesseeOperatingLeaseLiabilityPaymentsDueYearFour', 'LesseeOperatingLeaseLiabilityPaymentsDueYearThree', 'LesseeOperatingLeaseLiabilityPaymentsDueYearTwo', 'LesseeOperatingLeaseLiabilityPaymentsRemainderOfFiscalYear', 'LesseeOperatingLeaseLiabilityUndiscountedExcessAmount', 'Liabilities', 'LiabilitiesAndStockholdersEquity', 'LiabilitiesCurrent', 'LiabilitiesNoncurrent', 'LongTermDebt', 'LongTermDebtCurrent', 'LongTermDebtMaturitiesRepaymentsOfPrincipalAfterYearFive', 'LongTermDebtMaturitiesRepaymentsOfPrincipalInNextTwelveMonths', 'LongTermDebtMaturitiesRepaymentsOfPrincipalInYearFive', 'LongTermDebtMaturitiesRepaymentsOfPrincipalInYearFour', 'LongTermDebtMaturitiesRepaymentsOfPrincipalInYearThree', 'LongTermDebtMaturitiesRepaymentsOfPrincipalInYearTwo', 'LongTermDebtMaturitiesRepaymentsOfPrincipalRemainderOfFiscalYear', 'LongTermDebtNoncurrent', 'LongTermPurchaseCommitmentAmount', 'MarketableSecuritiesCurrent', 'MarketableSecuritiesNoncurrent', 'MarketableSecuritiesRealizedGainLoss', 'MarketingExpense', 'NetCashProvidedByUsedInFinancingActivities', 'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations', 'NetCashProvidedByUsedInInvestingActivities', 'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations', 'NetCashProvidedByUsedInOperatingActivities', 'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations', 'NetIncomeLoss', 'NoncurrentAssets', 'NonoperatingIncomeExpense', 'NontradeReceivablesCurrent', 'NotionalAmountOfForeignCurrencyDerivativeInstrumentsNotDesignatedAsHedgingInstruments', 'NumberOfStores', 'OciBeforeReclassificationsBeforeTaxAttributableToParent', 'OperatingExpenses', 'OperatingIncomeLoss', 'OperatingLeaseCost', 'OperatingLeaseLiability', 'OperatingLeaseLiabilityCurrent', 'OperatingLeaseLiabilityNoncurrent', 'OperatingLeasePayments', 'OperatingLeaseRightOfUseAsset', 'OperatingLeasesFutureMinimumPaymentsDue', 'OperatingLeasesFutureMinimumPaymentsDueCurrent', 'OperatingLeasesFutureMinimumPaymentsDueInFiveYears', 'OperatingLeasesFutureMinimumPaymentsDueInFourYears', 'OperatingLeasesFutureMinimumPaymentsDueInThreeYears', 'OperatingLeasesFutureMinimumPaymentsDueInTwoYears', 'OperatingLeasesFutureMinimumPaymentsDueThereafter', 'OperatingLeasesRentExpenseNet', 'OtherAccruedLiabilitiesCurrent', 'OtherAccruedLiabilitiesNoncurrent', 'OtherAssetsCurrent', 'OtherAssetsNoncurrent', 'OtherComprehensiveIncomeAvailableForSaleSecuritiesAdjustmentNetOfTaxPeriodIncreaseDecrease', 'OtherComprehensiveIncomeDerivativesQualifyingAsHedgesNetOfTaxPeriodIncreaseDecrease', 'OtherComprehensiveIncomeForeignCurrencyTransactionAndTranslationAdjustmentNetOfTaxPeriodIncreaseDecrease', 'OtherComprehensiveIncomeLossAvailableForSaleSecuritiesAdjustmentNetOfTax', 'OtherComprehensiveIncomeLossBeforeReclassificationsBeforeTax', 'OtherComprehensiveIncomeLossBeforeReclassificationsNetOfTax', 'OtherComprehensiveIncomeLossCashFlowHedgeGainLossBeforeReclassificationAndTax', 'OtherComprehensiveIncomeLossCashFlowHedgeGainLossReclassificationAfterTax', 'OtherComprehensiveIncomeLossCashFlowHedgeGainLossReclassificationBeforeTax', 'OtherComprehensiveIncomeLossDerivativeExcludedComponentIncreaseDecreaseBeforeAdjustmentsAndTax', 'OtherComprehensiveIncomeLossDerivativesQualifyingAsHedgesNetOfTax', 'OtherComprehensiveIncomeLossForeignCurrencyTransactionAndTranslationAdjustmentNetOfTax', 'OtherComprehensiveIncomeLossForeignCurrencyTranslationAdjustmentTax', 'OtherComprehensiveIncomeLossNetOfTax', 'OtherComprehensiveIncomeLossNetOfTaxPortionAttributableToParent', 'OtherComprehensiveIncomeLossReclassificationAdjustmentForSaleOfSecuritiesIncludedInNetIncomeNetOfTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIForSaleOfSecuritiesBeforeTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIForSaleOfSecuritiesNetOfTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIForSaleOfSecuritiesTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIOnDerivativesBeforeTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIOnDerivativesNetOfTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentFromAOCIOnDerivativesTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentOnDerivativesIncludedInNetIncomeNetOfTax', 'OtherComprehensiveIncomeLossReclassificationAdjustmentOnDerivativesIncludedInNetIncomeTax', 'OtherComprehensiveIncomeLossTax', 'OtherComprehensiveIncomeLossTaxPortionAttributableToParent1', 'OtherComprehensiveIncomeReclassificationAdjustmentOnDerivativesIncludedInNetIncomeNetOfTax', 'OtherComprehensiveIncomeReclassificationAdjustmentOnDerivativesIncludedInNetIncomeTax', 'OtherComprehensiveIncomeUnrealizedGainLossOnDerivativesArisingDuringPeriodNetOfTax', 'OtherComprehensiveIncomeUnrealizedGainLossOnDerivativesArisingDuringPeriodTax', 'OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodNetOfTax', 'OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodTax', 'OtherDeferredCreditsCurrent', 'OtherLiabilitiesCurrent', 'OtherLiabilitiesNoncurrent', 'OtherNoncashIncomeExpense', 'OtherNonoperatingIncomeExpense', 'OtherPrepaidExpenseCurrent', 'OtherShortTermBorrowings', 'PaymentsForProceedsFromOtherInvestingActivities', 'PaymentsForRepurchaseOfCommonStock', 'PaymentsOfDividends', 'PaymentsOfDividendsCommonStock', 'PaymentsRelatedToTaxWithholdingForShareBasedCompensation', 'PaymentsToAcquireAvailableForSaleSecurities', 'PaymentsToAcquireAvailableForSaleSecuritiesDebt', 'PaymentsToAcquireBusinessesNetOfCashAcquired', 'PaymentsToAcquireIntangibleAssets', 'PaymentsToAcquireOtherInvestments', 'PaymentsToAcquireProductiveAssets', 'PaymentsToAcquirePropertyPlantAndEquipment', 'PreferredStockSharesAuthorized', 'PrepaidExpenseOtherNoncurrent', 'ProceedsFromIssuanceOfCommonStock', 'ProceedsFromIssuanceOfLongTermDebt', 'ProceedsFromMaturitiesPrepaymentsAndCallsOfAvailableForSaleSecurities', 'ProceedsFromOtherShortTermDebt', 'ProceedsFromPaymentsForOtherFinancingActivities', 'ProceedsFromRepaymentsOfCommercialPaper', 'ProceedsFromRepaymentsOfShortTermDebt', 'ProceedsFromRepaymentsOfShortTermDebtMaturingInMoreThanThreeMonths', 'ProceedsFromRepaymentsOfShortTermDebtMaturingInThreeMonthsOrLess', 'ProceedsFromSaleAndMaturityOfOtherInvestments', 'ProceedsFromSaleOfAvailableForSaleSecurities', 'ProceedsFromSaleOfAvailableForSaleSecuritiesDebt', 'ProceedsFromShortTermDebtMaturingInMoreThanThreeMonths', 'ProductWarrantyAccrualClassifiedCurrent', 'ProductWarrantyAccrualPayments', 'ProductWarrantyAccrualWarrantiesIssued', 'ProductWarrantyExpense', 'PropertyPlantAndEquipmentGross', 'PropertyPlantAndEquipmentNet', 'ReclassificationFromAccumulatedOtherComprehensiveIncomeCurrentPeriodBeforeTax', 'ReclassificationFromAccumulatedOtherComprehensiveIncomeCurrentPeriodNetOfTax', 'ReclassificationFromAociCurrentPeriodBeforeTaxAttributableToParent', 'RepaymentsOfLongTermDebt', 'RepaymentsOfOtherShortTermDebt', 'RepaymentsOfShortTermDebtMaturingInMoreThanThreeMonths', 'ResearchAndDevelopmentExpense', 'RestrictedCash', 'RestrictedCashAndCashEquivalentsAtCarryingValue', 'RestrictedCashAndCashEquivalentsNoncurrent', 'RestrictedInvestments', 'RetainedEarningsAccumulatedDeficit', 'RevenueFromContractWithCustomerExcludingAssessedTax', 'Revenues', 'SalesRevenueNet', 'SalesRevenueServicesGross', 'SecuritiesSoldUnderAgreementsToRepurchaseFairValueOfCollateral', 'SegmentReportingInformationOperatingIncomeLoss', 'SegmentReportingReconcilingItemsAssets', 'SegmentReportingSegmentAssets', 'SellingGeneralAndAdministrativeExpense', 'ShareBasedCompensation', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsForfeitedInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsForfeitedInPeriodWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsForfeituresWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedIntrinsicValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardFairValueAssumptionsExpectedDividendRate', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardFairValueAssumptionsExpectedTerm', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardFairValueAssumptionsRiskFreeInterestRate', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardFairValueAssumptionsWeightedAverageVolatilityRate', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisableIntrinsicValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisableNumber', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisableWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisableWeightedAverageRemainingContractualTerm', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsForfeituresInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsForfeituresInPeriodWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsOtherIncreasesDecreasesInPeriod', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsOutstandingIntrinsicValue', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsOutstandingNumber', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsOutstandingWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsOutstandingWeightedAverageRemainingContractualTerm', 'ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsVestedAndExpectedToVestOutstandingNumber', 'ShareBasedCompensationArrangementsByShareBasedPaymentAwardOptionsExercisesInPeriodWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementsByShareBasedPaymentAwardOptionsForfeituresInPeriodWeightedAverageExercisePrice', 'ShareBasedCompensationArrangementsByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageExercisePrice', 'SharebasedCompensationArrangementBySharebasedPaymentAwardEquityInstrumentsOtherThanOptionsAggregateIntrinsicValueNonvested', 'SharebasedCompensationArrangementBySharebasedPaymentAwardOptionsExercisableIntrinsicValue1', 'SharebasedCompensationArrangementBySharebasedPaymentAwardOptionsOutstandingWeightedAverageRemainingContractualTerm1', 'SharesPaidForTaxWithholdingForShareBasedCompensation', 'ShortTermDebtWeightedAverageInterestRate', 'SignificantChangeInUnrecognizedTaxBenefitsIsReasonablyPossibleEstimatedRangeOfChangeLowerBound', 'SignificantChangeInUnrecognizedTaxBenefitsIsReasonablyPossibleEstimatedRangeOfChangeUpperBound', 'StandardProductWarrantyAccrual', 'StandardProductWarrantyAccrualPayments', 'StandardProductWarrantyAccrualWarrantiesIssued', 'StateAndLocalIncomeTaxExpenseBenefitContinuingOperations', 'StockholdersEquity', 'StockholdersEquityNoteStockSplitConversionRatio1', 'StockIssuedDuringPeriodSharesStockOptionsExercised', 'StockIssuedDuringPeriodValueAcquisitions', 'StockIssuedDuringPeriodValueShareBasedCompensation', 'StockRepurchasedAndRetiredDuringPeriodShares', 'StockRepurchasedAndRetiredDuringPeriodValue', 'StockRepurchaseProgramAuthorizedAmount', 'StockRepurchaseProgramAuthorizedAmount1', 'TaxAdjustmentsSettlementsAndUnusualProvisions', 'TaxesPayableCurrent', 'TranslationAdjustmentForNetInvestmentHedgeNetOfTax', 'TreasuryStockValueAcquiredCostMethod', 'UndistributedEarningsOfForeignSubsidiaries', 'UnrecognizedTaxBenefits', 'UnrecognizedTaxBenefitsDecreasesResultingFromPriorPeriodTaxPositions', 'UnrecognizedTaxBenefitsDecreasesResultingFromSettlementsWithTaxingAuthorities', 'UnrecognizedTaxBenefitsIncomeTaxPenaltiesAndInterestAccrued', 'UnrecognizedTaxBenefitsIncomeTaxPenaltiesAndInterestExpense', 'UnrecognizedTaxBenefitsIncreasesResultingFromCurrentPeriodTaxPositions', 'UnrecognizedTaxBenefitsIncreasesResultingFromPriorPeriodTaxPositions', 'UnrecognizedTaxBenefitsPeriodIncreaseDecrease', 'UnrecognizedTaxBenefitsReductionsResultingFromLapseOfApplicableStatuteOfLimitations', 'UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate', 'UnrecordedUnconditionalPurchaseObligationBalanceOnFifthAnniversary', 'UnrecordedUnconditionalPurchaseObligationBalanceOnFirstAnniversary', 'UnrecordedUnconditionalPurchaseObligationBalanceOnFourthAnniversary', 'UnrecordedUnconditionalPurchaseObligationBalanceOnSecondAnniversary', 'UnrecordedUnconditionalPurchaseObligationBalanceOnThirdAnniversary', 'UnrecordedUnconditionalPurchaseObligationBalanceSheetAmount', 'UnrecordedUnconditionalPurchaseObligationDueAfterFiveYears', 'VariableLeaseCost', 'WeightedAverageNumberDilutedSharesOutstandingAdjustment', 'WeightedAverageNumberOfDilutedSharesOutstanding', 'WeightedAverageNumberOfSharesOutstandingBasic', 'DeferredTaxAssetsOtherComprehensiveLoss', 'EffectiveIncomeTaxRateReconciliationFdiiAmount', 'DebtSecuritiesAvailableForSaleRestricted', 'InventoryWorkInProcessAndRawMaterialsNetOfReserves', 'UnrecordedUnconditionalPurchaseObligationDueInRemainderOfFiscalYear', 'InventoryRawMaterialsAndPurchasedPartsNetOfReserves', 'HedgedAssetFairValueHedge', 'HedgedLiabilityFairValueHedge', 'DeferredIncomeTaxAssetsNet', 'DeferredTaxLiabilitiesPropertyPlantAndEquipment', 'IncrementalCommonSharesAttributableToShareBasedPaymentArrangements', 'OtherAssetsMiscellaneousNoncurrent'])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['us-gaap'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'description', 'units'])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['us-gaap']['Assets'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>39572000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>39572000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>36171000000</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>36171000000</td>\n",
       "      <td>0001193125-10-238044</td>\n",
       "      <td>2010</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>CY2008Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>48140000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2009Q2I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>352755000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2022Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>346747000000</td>\n",
       "      <td>0000320193-23-000006</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>CY2022Q4I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>332160000000</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>CY2023Q1I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>335038000000</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>CY2023Q2I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>352583000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2023Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            end           val                  accn    fy  fp    form  \\\n",
       "0    2008-09-27   39572000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "1    2008-09-27   39572000000  0001193125-09-214859  2009  FY    10-K   \n",
       "2    2008-09-27   36171000000  0001193125-10-012091  2009  FY  10-K/A   \n",
       "3    2008-09-27   36171000000  0001193125-10-238044  2010  FY    10-K   \n",
       "4    2009-06-27   48140000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "..          ...           ...                   ...   ...  ..     ...   \n",
       "119  2022-09-24  352755000000  0000320193-23-000106  2023  FY    10-K   \n",
       "120  2022-12-31  346747000000  0000320193-23-000006  2023  Q1    10-Q   \n",
       "121  2023-04-01  332160000000  0000320193-23-000064  2023  Q2    10-Q   \n",
       "122  2023-07-01  335038000000  0000320193-23-000077  2023  Q3    10-Q   \n",
       "123  2023-09-30  352583000000  0000320193-23-000106  2023  FY    10-K   \n",
       "\n",
       "          filed      frame symbol  \n",
       "0    2009-07-22        NaN   AAPL  \n",
       "1    2009-10-27        NaN   AAPL  \n",
       "2    2010-01-25        NaN   AAPL  \n",
       "3    2010-10-27  CY2008Q3I   AAPL  \n",
       "4    2009-07-22  CY2009Q2I   AAPL  \n",
       "..          ...        ...    ...  \n",
       "119  2023-11-03  CY2022Q3I   AAPL  \n",
       "120  2023-02-03  CY2022Q4I   AAPL  \n",
       "121  2023-05-05  CY2023Q1I   AAPL  \n",
       "122  2023-08-04  CY2023Q2I   AAPL  \n",
       "123  2023-11-03  CY2023Q3I   AAPL  \n",
       "\n",
       "[124 rows x 9 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_asset=pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['Assets']['units']['USD'])\n",
    "_symb=companyData[ companyData['cik_str10']==cik ]['ticker']\n",
    "symb=_symb[0]\n",
    "apple_asset['symbol']=symb\n",
    "apple_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>18542000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>18542000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>13874000000</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>CY2008Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>22252000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2009Q2I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-09-26</td>\n",
       "      <td>26019000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>302083000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2022Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>290020000000</td>\n",
       "      <td>0000320193-23-000006</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>CY2022Q4I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>270002000000</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>CY2023Q1I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>274764000000</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>CY2023Q2I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>290437000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2023Q3I</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            end           val                  accn    fy  fp    form  \\\n",
       "0    2008-09-27   18542000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "1    2008-09-27   18542000000  0001193125-09-214859  2009  FY    10-K   \n",
       "2    2008-09-27   13874000000  0001193125-10-012091  2009  FY  10-K/A   \n",
       "3    2009-06-27   22252000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "4    2009-09-26   26019000000  0001193125-09-214859  2009  FY    10-K   \n",
       "..          ...           ...                   ...   ...  ..     ...   \n",
       "117  2022-09-24  302083000000  0000320193-23-000106  2023  FY    10-K   \n",
       "118  2022-12-31  290020000000  0000320193-23-000006  2023  Q1    10-Q   \n",
       "119  2023-04-01  270002000000  0000320193-23-000064  2023  Q2    10-Q   \n",
       "120  2023-07-01  274764000000  0000320193-23-000077  2023  Q3    10-Q   \n",
       "121  2023-09-30  290437000000  0000320193-23-000106  2023  FY    10-K   \n",
       "\n",
       "          filed      frame symbol  \n",
       "0    2009-07-22        NaN   AAPL  \n",
       "1    2009-10-27        NaN   AAPL  \n",
       "2    2010-01-25  CY2008Q3I   AAPL  \n",
       "3    2009-07-22  CY2009Q2I   AAPL  \n",
       "4    2009-10-27        NaN   AAPL  \n",
       "..          ...        ...    ...  \n",
       "117  2023-11-03  CY2022Q3I   AAPL  \n",
       "118  2023-02-03  CY2022Q4I   AAPL  \n",
       "119  2023-05-05  CY2023Q1I   AAPL  \n",
       "120  2023-08-04  CY2023Q2I   AAPL  \n",
       "121  2023-11-03  CY2023Q3I   AAPL  \n",
       "\n",
       "[122 rows x 9 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_liabilities=pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['Liabilities']['units']['USD'])\n",
    "apple_liabilities['symbol']=symb\n",
    "apple_liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>2007-09-29</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>2007-09-29</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>CY2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-03-30</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2008Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>CY2023Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>CY2023Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start         end   val                  accn    fy  fp    form  \\\n",
       "0    2006-10-01  2007-09-29  4.04  0001193125-09-214859  2009  FY    10-K   \n",
       "1    2006-10-01  2007-09-29  4.04  0001193125-10-012091  2009  FY  10-K/A   \n",
       "2    2007-09-30  2008-06-28  4.20  0001193125-09-153165  2009  Q3    10-Q   \n",
       "3    2008-03-30  2008-06-28  1.21  0001193125-09-153165  2009  Q3    10-Q   \n",
       "4    2007-09-30  2008-09-27  5.48  0001193125-09-214859  2009  FY    10-K   \n",
       "..          ...         ...   ...                   ...   ...  ..     ...   \n",
       "297  2022-09-25  2023-04-01  3.42  0000320193-23-000064  2023  Q2    10-Q   \n",
       "298  2023-01-01  2023-04-01  1.53  0000320193-23-000064  2023  Q2    10-Q   \n",
       "299  2022-09-25  2023-07-01  4.69  0000320193-23-000077  2023  Q3    10-Q   \n",
       "300  2023-04-02  2023-07-01  1.27  0000320193-23-000077  2023  Q3    10-Q   \n",
       "301  2022-09-25  2023-09-30  6.16  0000320193-23-000106  2023  FY    10-K   \n",
       "\n",
       "          filed     frame  \n",
       "0    2009-10-27       NaN  \n",
       "1    2010-01-25    CY2007  \n",
       "2    2009-07-22       NaN  \n",
       "3    2009-07-22  CY2008Q2  \n",
       "4    2009-10-27       NaN  \n",
       "..          ...       ...  \n",
       "297  2023-05-05       NaN  \n",
       "298  2023-05-05  CY2023Q1  \n",
       "299  2023-08-04       NaN  \n",
       "300  2023-08-04  CY2023Q2  \n",
       "301  2023-11-03    CY2023  \n",
       "\n",
       "[302 rows x 9 columns]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['EarningsPerShareBasic']['units']['USD/shares'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>2016-09-24</td>\n",
       "      <td>215639000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>78351000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2016Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>52896000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>45408000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>229234000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>52579000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>88293000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>61137000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>53265000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>265595000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>62900000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start         end           val                  accn    fy  fp  \\\n",
       "0   2015-09-27  2016-09-24  215639000000  0000320193-18-000145  2018  FY   \n",
       "1   2016-09-25  2016-12-31   78351000000  0000320193-18-000145  2018  FY   \n",
       "2   2017-01-01  2017-04-01   52896000000  0000320193-18-000145  2018  FY   \n",
       "3   2017-04-02  2017-07-01   45408000000  0000320193-18-000145  2018  FY   \n",
       "4   2016-09-25  2017-09-30  229234000000  0000320193-18-000145  2018  FY   \n",
       "5   2017-07-02  2017-09-30   52579000000  0000320193-18-000145  2018  FY   \n",
       "6   2017-10-01  2017-12-30   88293000000  0000320193-18-000145  2018  FY   \n",
       "7   2017-12-31  2018-03-31   61137000000  0000320193-18-000145  2018  FY   \n",
       "8   2018-04-01  2018-06-30   53265000000  0000320193-18-000145  2018  FY   \n",
       "9   2017-10-01  2018-09-29  265595000000  0000320193-18-000145  2018  FY   \n",
       "10  2018-07-01  2018-09-29   62900000000  0000320193-18-000145  2018  FY   \n",
       "\n",
       "    form       filed     frame  \n",
       "0   10-K  2018-11-05    CY2016  \n",
       "1   10-K  2018-11-05  CY2016Q4  \n",
       "2   10-K  2018-11-05  CY2017Q1  \n",
       "3   10-K  2018-11-05  CY2017Q2  \n",
       "4   10-K  2018-11-05    CY2017  \n",
       "5   10-K  2018-11-05  CY2017Q3  \n",
       "6   10-K  2018-11-05  CY2017Q4  \n",
       "7   10-K  2018-11-05  CY2018Q1  \n",
       "8   10-K  2018-11-05  CY2018Q2  \n",
       "9   10-K  2018-11-05    CY2018  \n",
       "10  10-K  2018-11-05  CY2018Q3  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['Revenues']['units']['USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>32311000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>32311000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>30006000000</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>CY2008Q3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>35170000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2009Q2I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-09-26</td>\n",
       "      <td>36265000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>135405000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2022Q3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>128777000000</td>\n",
       "      <td>0000320193-23-000006</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>CY2022Q4I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>112913000000</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>CY2023Q1I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>122659000000</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>CY2023Q2I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>143566000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2023Q3I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            end           val                  accn    fy  fp    form  \\\n",
       "0    2008-09-27   32311000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "1    2008-09-27   32311000000  0001193125-09-214859  2009  FY    10-K   \n",
       "2    2008-09-27   30006000000  0001193125-10-012091  2009  FY  10-K/A   \n",
       "3    2009-06-27   35170000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "4    2009-09-26   36265000000  0001193125-09-214859  2009  FY    10-K   \n",
       "..          ...           ...                   ...   ...  ..     ...   \n",
       "117  2022-09-24  135405000000  0000320193-23-000106  2023  FY    10-K   \n",
       "118  2022-12-31  128777000000  0000320193-23-000006  2023  Q1    10-Q   \n",
       "119  2023-04-01  112913000000  0000320193-23-000064  2023  Q2    10-Q   \n",
       "120  2023-07-01  122659000000  0000320193-23-000077  2023  Q3    10-Q   \n",
       "121  2023-09-30  143566000000  0000320193-23-000106  2023  FY    10-K   \n",
       "\n",
       "          filed      frame  \n",
       "0    2009-07-22        NaN  \n",
       "1    2009-10-27        NaN  \n",
       "2    2010-01-25  CY2008Q3I  \n",
       "3    2009-07-22  CY2009Q2I  \n",
       "4    2009-10-27        NaN  \n",
       "..          ...        ...  \n",
       "117  2023-11-03  CY2022Q3I  \n",
       "118  2023-02-03  CY2022Q4I  \n",
       "119  2023-05-05  CY2023Q1I  \n",
       "120  2023-08-04  CY2023Q2I  \n",
       "121  2023-11-03  CY2023Q3I  \n",
       "\n",
       "[122 rows x 8 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['AssetsCurrent']['units']['USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>14092000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>14092000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>11361000000</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>CY2008Q3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>16661000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2009Q2I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-09-26</td>\n",
       "      <td>19282000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>153982000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2022Q3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>137286000000</td>\n",
       "      <td>0000320193-23-000006</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>CY2022Q4I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>120075000000</td>\n",
       "      <td>0000320193-23-000064</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>CY2023Q1I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>124963000000</td>\n",
       "      <td>0000320193-23-000077</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>CY2023Q2I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>145308000000</td>\n",
       "      <td>0000320193-23-000106</td>\n",
       "      <td>2023</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>CY2023Q3I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            end           val                  accn    fy  fp    form  \\\n",
       "0    2008-09-27   14092000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "1    2008-09-27   14092000000  0001193125-09-214859  2009  FY    10-K   \n",
       "2    2008-09-27   11361000000  0001193125-10-012091  2009  FY  10-K/A   \n",
       "3    2009-06-27   16661000000  0001193125-09-153165  2009  Q3    10-Q   \n",
       "4    2009-09-26   19282000000  0001193125-09-214859  2009  FY    10-K   \n",
       "..          ...           ...                   ...   ...  ..     ...   \n",
       "117  2022-09-24  153982000000  0000320193-23-000106  2023  FY    10-K   \n",
       "118  2022-12-31  137286000000  0000320193-23-000006  2023  Q1    10-Q   \n",
       "119  2023-04-01  120075000000  0000320193-23-000064  2023  Q2    10-Q   \n",
       "120  2023-07-01  124963000000  0000320193-23-000077  2023  Q3    10-Q   \n",
       "121  2023-09-30  145308000000  0000320193-23-000106  2023  FY    10-K   \n",
       "\n",
       "          filed      frame  \n",
       "0    2009-07-22        NaN  \n",
       "1    2009-10-27        NaN  \n",
       "2    2010-01-25  CY2008Q3I  \n",
       "3    2009-07-22  CY2009Q2I  \n",
       "4    2009-10-27        NaN  \n",
       "..          ...        ...  \n",
       "117  2023-11-03  CY2022Q3I  \n",
       "118  2023-02-03  CY2022Q4I  \n",
       "119  2023-05-05  CY2023Q1I  \n",
       "120  2023-08-04  CY2023Q2I  \n",
       "121  2023-11-03  CY2023Q3I  \n",
       "\n",
       "[122 rows x 8 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['LiabilitiesCurrent']['units']['USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>2016-09-24</td>\n",
       "      <td>215639000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>78351000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2016Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>52896000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>45408000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>229234000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>52579000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>88293000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2017Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>61137000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>53265000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>265595000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>62900000000</td>\n",
       "      <td>0000320193-18-000145</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>CY2018Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start         end           val                  accn    fy  fp  \\\n",
       "0   2015-09-27  2016-09-24  215639000000  0000320193-18-000145  2018  FY   \n",
       "1   2016-09-25  2016-12-31   78351000000  0000320193-18-000145  2018  FY   \n",
       "2   2017-01-01  2017-04-01   52896000000  0000320193-18-000145  2018  FY   \n",
       "3   2017-04-02  2017-07-01   45408000000  0000320193-18-000145  2018  FY   \n",
       "4   2016-09-25  2017-09-30  229234000000  0000320193-18-000145  2018  FY   \n",
       "5   2017-07-02  2017-09-30   52579000000  0000320193-18-000145  2018  FY   \n",
       "6   2017-10-01  2017-12-30   88293000000  0000320193-18-000145  2018  FY   \n",
       "7   2017-12-31  2018-03-31   61137000000  0000320193-18-000145  2018  FY   \n",
       "8   2018-04-01  2018-06-30   53265000000  0000320193-18-000145  2018  FY   \n",
       "9   2017-10-01  2018-09-29  265595000000  0000320193-18-000145  2018  FY   \n",
       "10  2018-07-01  2018-09-29   62900000000  0000320193-18-000145  2018  FY   \n",
       "\n",
       "    form       filed     frame  \n",
       "0   10-K  2018-11-05    CY2016  \n",
       "1   10-K  2018-11-05  CY2016Q4  \n",
       "2   10-K  2018-11-05  CY2017Q1  \n",
       "3   10-K  2018-11-05  CY2017Q2  \n",
       "4   10-K  2018-11-05    CY2017  \n",
       "5   10-K  2018-11-05  CY2017Q3  \n",
       "6   10-K  2018-11-05  CY2017Q4  \n",
       "7   10-K  2018-11-05  CY2018Q1  \n",
       "8   10-K  2018-11-05  CY2018Q2  \n",
       "9   10-K  2018-11-05    CY2018  \n",
       "10  10-K  2018-11-05  CY2018Q3  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['Revenues']['units']['USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Revenue, Net (Deprecated 2018-01-31)'"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['us-gaap']['SalesRevenueNet']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>val</th>\n",
       "      <th>accn</th>\n",
       "      <th>fy</th>\n",
       "      <th>fp</th>\n",
       "      <th>form</th>\n",
       "      <th>filed</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>2007-09-29</td>\n",
       "      <td>24578000000</td>\n",
       "      <td>0001193125-10-012091</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>CY2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>2007-09-29</td>\n",
       "      <td>24006000000</td>\n",
       "      <td>0001193125-09-214859</td>\n",
       "      <td>2009</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2009-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>24584000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-03-30</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>7464000000</td>\n",
       "      <td>0001193125-09-153165</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2009-07-22</td>\n",
       "      <td>CY2008Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>2008-09-27</td>\n",
       "      <td>37491000000</td>\n",
       "      <td>0001193125-10-238044</td>\n",
       "      <td>2010</td>\n",
       "      <td>FY</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>CY2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>88293000000</td>\n",
       "      <td>0000320193-18-000007</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q1</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>CY2017Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>149430000000</td>\n",
       "      <td>0000320193-18-000070</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>61137000000</td>\n",
       "      <td>0000320193-18-000070</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q2</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>CY2018Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>202695000000</td>\n",
       "      <td>0000320193-18-000100</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>53265000000</td>\n",
       "      <td>0000320193-18-000100</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q3</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>CY2018Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start         end           val                  accn    fy  fp  \\\n",
       "0    2006-10-01  2007-09-29   24578000000  0001193125-10-012091  2009  FY   \n",
       "1    2006-10-01  2007-09-29   24006000000  0001193125-09-214859  2009  FY   \n",
       "2    2007-09-30  2008-06-28   24584000000  0001193125-09-153165  2009  Q3   \n",
       "3    2008-03-30  2008-06-28    7464000000  0001193125-09-153165  2009  Q3   \n",
       "4    2007-09-30  2008-09-27   37491000000  0001193125-10-238044  2010  FY   \n",
       "..          ...         ...           ...                   ...   ...  ..   \n",
       "205  2017-10-01  2017-12-30   88293000000  0000320193-18-000007  2018  Q1   \n",
       "206  2017-10-01  2018-03-31  149430000000  0000320193-18-000070  2018  Q2   \n",
       "207  2017-12-31  2018-03-31   61137000000  0000320193-18-000070  2018  Q2   \n",
       "208  2017-10-01  2018-06-30  202695000000  0000320193-18-000100  2018  Q3   \n",
       "209  2018-04-01  2018-06-30   53265000000  0000320193-18-000100  2018  Q3   \n",
       "\n",
       "       form       filed     frame  \n",
       "0    10-K/A  2010-01-25    CY2007  \n",
       "1      10-K  2009-10-27       NaN  \n",
       "2      10-Q  2009-07-22       NaN  \n",
       "3      10-Q  2009-07-22  CY2008Q2  \n",
       "4      10-K  2010-10-27    CY2008  \n",
       "..      ...         ...       ...  \n",
       "205    10-Q  2018-02-02  CY2017Q4  \n",
       "206    10-Q  2018-05-02       NaN  \n",
       "207    10-Q  2018-05-02  CY2018Q1  \n",
       "208    10-Q  2018-08-01       NaN  \n",
       "209    10-Q  2018-08-01  CY2018Q2  \n",
       "\n",
       "[210 rows x 9 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(companyFacts.json()['facts']['us-gaap']['SalesRevenueNet']['units']['USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NetIncomeLoss'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'NetIncomeLoss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sum of the carrying amounts as of the balance sheet date of all assets that are expected to be realized in cash, sold, or consumed within one year (or the normal operating cycle, if longer). Assets are probable future economic benefits obtained or controlled by an entity as a result of past transactions or events.'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['us-gaap']['AssetsCurrent']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The amount of net income (loss) for the period per each share of common stock or unit outstanding during the reporting period.'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyFacts.json()['facts']['us-gaap']['EarningsPerShareBasic']['description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for share price we will take closing price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y=_df['next_month_return']\n",
    "X_train,X_test,y_train,y_test=train_test_split(_df,_y,random_state=8,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>60%</th>\n",
       "      <th>70%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.067680</td>\n",
       "      <td>-0.103129</td>\n",
       "      <td>-0.030129</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.035314</td>\n",
       "      <td>0.050722</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.402289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.070544</td>\n",
       "      <td>0.070144</td>\n",
       "      <td>-0.223545</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.024305</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.051873</td>\n",
       "      <td>0.064146</td>\n",
       "      <td>0.076538</td>\n",
       "      <td>0.091137</td>\n",
       "      <td>0.112272</td>\n",
       "      <td>0.146784</td>\n",
       "      <td>0.447819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.038165</td>\n",
       "      <td>0.084212</td>\n",
       "      <td>-0.190801</td>\n",
       "      <td>-0.053777</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.050789</td>\n",
       "      <td>0.065693</td>\n",
       "      <td>0.086353</td>\n",
       "      <td>0.145953</td>\n",
       "      <td>0.530917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-0.064902</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>-0.270521</td>\n",
       "      <td>-0.133351</td>\n",
       "      <td>-0.109330</td>\n",
       "      <td>-0.092800</td>\n",
       "      <td>-0.077423</td>\n",
       "      <td>-0.065148</td>\n",
       "      <td>-0.054343</td>\n",
       "      <td>-0.043204</td>\n",
       "      <td>-0.027465</td>\n",
       "      <td>-0.002583</td>\n",
       "      <td>0.248939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>323.0</td>\n",
       "      <td>-0.053420</td>\n",
       "      <td>0.059950</td>\n",
       "      <td>-0.256732</td>\n",
       "      <td>-0.131072</td>\n",
       "      <td>-0.097591</td>\n",
       "      <td>-0.078647</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>-0.050336</td>\n",
       "      <td>-0.036117</td>\n",
       "      <td>-0.021721</td>\n",
       "      <td>-0.003402</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.149206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>376.0</td>\n",
       "      <td>-0.093197</td>\n",
       "      <td>0.063382</td>\n",
       "      <td>-0.291853</td>\n",
       "      <td>-0.167320</td>\n",
       "      <td>-0.139237</td>\n",
       "      <td>-0.120786</td>\n",
       "      <td>-0.106662</td>\n",
       "      <td>-0.093080</td>\n",
       "      <td>-0.078505</td>\n",
       "      <td>-0.067533</td>\n",
       "      <td>-0.052507</td>\n",
       "      <td>-0.023162</td>\n",
       "      <td>0.366568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>0.097766</td>\n",
       "      <td>-0.349332</td>\n",
       "      <td>-0.025305</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.056639</td>\n",
       "      <td>0.075825</td>\n",
       "      <td>0.096055</td>\n",
       "      <td>0.111315</td>\n",
       "      <td>0.143338</td>\n",
       "      <td>0.167205</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.486796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.075074</td>\n",
       "      <td>0.075227</td>\n",
       "      <td>-0.144326</td>\n",
       "      <td>-0.009603</td>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.088426</td>\n",
       "      <td>0.100750</td>\n",
       "      <td>0.123392</td>\n",
       "      <td>0.163858</td>\n",
       "      <td>0.406559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>373.0</td>\n",
       "      <td>-0.048980</td>\n",
       "      <td>0.057208</td>\n",
       "      <td>-0.367334</td>\n",
       "      <td>-0.118396</td>\n",
       "      <td>-0.085971</td>\n",
       "      <td>-0.067712</td>\n",
       "      <td>-0.056382</td>\n",
       "      <td>-0.047158</td>\n",
       "      <td>-0.034639</td>\n",
       "      <td>-0.018923</td>\n",
       "      <td>-0.004027</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.076729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.078207</td>\n",
       "      <td>0.094688</td>\n",
       "      <td>-0.164478</td>\n",
       "      <td>-0.035004</td>\n",
       "      <td>-0.002475</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>0.067135</td>\n",
       "      <td>0.094964</td>\n",
       "      <td>0.118156</td>\n",
       "      <td>0.148339</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>0.563291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  count      mean       std       min       10%       20%  \\\n",
       "0    2010      1  311.0  0.043726  0.067680 -0.103129 -0.030129 -0.007188   \n",
       "1    2010      2  310.0  0.070544  0.070144 -0.223545 -0.000129  0.024305   \n",
       "2    2010      3  328.0  0.038165  0.084212 -0.190801 -0.053777 -0.014974   \n",
       "3    2010      4  338.0 -0.064902  0.062564 -0.270521 -0.133351 -0.109330   \n",
       "4    2010      5  323.0 -0.053420  0.059950 -0.256732 -0.131072 -0.097591   \n",
       "..    ...    ...    ...       ...       ...       ...       ...       ...   \n",
       "151  2022      8  376.0 -0.093197  0.063382 -0.291853 -0.167320 -0.139237   \n",
       "152  2022      9  367.0  0.095183  0.097766 -0.349332 -0.025305  0.019600   \n",
       "153  2022     10  368.0  0.075074  0.075227 -0.144326 -0.009603  0.019972   \n",
       "154  2022     11  373.0 -0.048980  0.057208 -0.367334 -0.118396 -0.085971   \n",
       "155  2022     12  386.0  0.078207  0.094688 -0.164478 -0.035004 -0.002475   \n",
       "\n",
       "          30%       40%       50%       60%       70%       80%       90%  \\\n",
       "0    0.009896  0.022731  0.035314  0.050722  0.068601  0.084570  0.120999   \n",
       "1    0.038383  0.051873  0.064146  0.076538  0.091137  0.112272  0.146784   \n",
       "2    0.002544  0.016971  0.037680  0.050789  0.065693  0.086353  0.145953   \n",
       "3   -0.092800 -0.077423 -0.065148 -0.054343 -0.043204 -0.027465 -0.002583   \n",
       "4   -0.078647 -0.064000 -0.050336 -0.036117 -0.021721 -0.003402  0.013331   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "151 -0.120786 -0.106662 -0.093080 -0.078505 -0.067533 -0.052507 -0.023162   \n",
       "152  0.056639  0.075825  0.096055  0.111315  0.143338  0.167205  0.199393   \n",
       "153  0.039638  0.057356  0.072254  0.088426  0.100750  0.123392  0.163858   \n",
       "154 -0.067712 -0.056382 -0.047158 -0.034639 -0.018923 -0.004027  0.020512   \n",
       "155  0.026056  0.050547  0.067135  0.094964  0.118156  0.148339  0.197392   \n",
       "\n",
       "          max  \n",
       "0    0.402289  \n",
       "1    0.447819  \n",
       "2    0.530917  \n",
       "3    0.248939  \n",
       "4    0.149206  \n",
       "..        ...  \n",
       "151  0.366568  \n",
       "152  0.486796  \n",
       "153  0.406559  \n",
       "154  0.076729  \n",
       "155  0.563291  \n",
       "\n",
       "[156 rows x 16 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_decile=X_train.groupby(['year','month'])['next_month_return'].describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "_decile.reset_index().drop(columns=['count','mean','std','min','max'],inplace=True)\n",
    "_decile.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.merge(X_train,_decile, on=['year','month'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decile_rank(row):\n",
    "    if row['next_month_return'] < row[\"10%\"]:\n",
    "        return 1\n",
    "    elif row['next_month_return'] < row[\"20%\"]:\n",
    "        return 2\n",
    "    elif row['next_month_return'] < row[\"30%\"]:\n",
    "        return 3\n",
    "    elif row['next_month_return'] < row[\"40%\"]:\n",
    "        return 4\n",
    "    elif row['next_month_return'] < row[\"50%\"]:\n",
    "        return 5\n",
    "    elif row['next_month_return'] < row[\"60%\"]:\n",
    "        return 6\n",
    "    elif row['next_month_return'] < row[\"70%\"]:\n",
    "        return 7\n",
    "    elif row['next_month_return'] < row[\"80%\"]:\n",
    "        return 8\n",
    "    elif row['next_month_return'] < row[\"90%\"]:\n",
    "        return 9\n",
    "    elif row['next_month_return'] > row[\"90%\"]:\n",
    "        return 10\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['decile_rank']=X_train.apply(decile_rank,axis=1)\n",
    "X_train=X_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.merge(X_test,_decile,how='left',on=['year','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['decile_rank']=X_test.apply(decile_rank,axis=1)\n",
    "X_test=X_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.0\n",
       "1        4.0\n",
       "2        4.0\n",
       "3        9.0\n",
       "4        8.0\n",
       "        ... \n",
       "55229    6.0\n",
       "55230    5.0\n",
       "55231    1.0\n",
       "55232    5.0\n",
       "55233    3.0\n",
       "Name: decile_rank, Length: 55217, dtype: float64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['Close','avrg_return_daily','std_return_daily','skew_return_daily','Sharpe','return','cum_ret6','cum_ret12']\n",
    "y_train=X_train['decile_rank']\n",
    "y_test=X_test['decile_rank']\n",
    "X_train=X_train[features]\n",
    "X_test=X_test[features]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "_avg = X_train.mean()\n",
    "_std = X_train.std()\n",
    "X_train = (X_train - _avg)/(_std)\n",
    "X_test = (X_test- _avg)/(_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['lbfgs'],\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 10), (10, 20)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=0, hidden_layer_sizes=(10, 20),\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;identity&#x27;, alpha=0, hidden_layer_sizes=(10, 20),\n",
       "             max_iter=1000, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='identity', alpha=0, hidden_layer_sizes=(10, 20),\n",
       "             max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009809063823009723 4.5056330231108e-05\n"
     ]
    }
   ],
   "source": [
    "mlp_model=MLPRegressor(solver='lbfgs',alpha=0,hidden_layer_sizes=(10,20),activation='identity',max_iter=1000).fit(X_train,y_train)\n",
    "print(mlp_model.score(X_train,y_train),mlp_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.270926892718107\n",
      "8.255800659768823\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,mlp_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:110: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta *= 1 - Z\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:175: RuntimeWarning: invalid value encountered in add\n",
      "  activations[i + 1] += self.intercepts_[i]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:175: RuntimeWarning: invalid value encountered in add\n",
      "  activations[i + 1] += self.intercepts_[i]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:339: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:233: RuntimeWarning: invalid value encountered in multiply\n",
      "  coef_grads[layer] += self.alpha * self.coefs_[layer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "40 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-2.68400071e-03 -4.80867789e-03             nan -1.05563720e-01\n",
      "             nan -1.16342249e-03             nan -1.08794635e+02\n",
      " -2.03500876e-03 -1.35623609e-03             nan -2.81134953e-02\n",
      " -1.77712353e-03 -3.42822569e-03             nan -3.93050582e-02\n",
      " -4.35625047e-04 -4.17719616e-04             nan -1.12785220e-02\n",
      " -5.15195466e-04 -3.18604871e-03             nan -5.92419245e-03\n",
      "  6.50070362e-04 -5.64467039e-03             nan -4.27712812e-03\n",
      " -1.16630401e-03 -5.74433114e-03 -1.98103247e-02 -2.12923913e-02\n",
      " -3.31118314e-03 -3.41521001e-03 -6.51538351e-03 -1.88814111e-02\n",
      " -3.68773408e-03 -5.92702044e-03 -1.83084759e-02 -1.83286906e-03\n",
      "  8.96417223e-04 -4.60611275e-03 -9.12396493e-03 -1.27783185e-02\n",
      "  8.27442142e-04 -4.58778685e-04 -1.39205295e-03 -6.35308676e-03\n",
      " -2.62372363e-03 -1.87608449e-04             nan -1.68407632e-03\n",
      " -1.94395935e-03  1.44983898e-04 -1.73391798e-02 -7.19183621e-03\n",
      " -3.06158744e-03 -1.03396070e-03 -2.40795191e-02 -5.95831830e-03\n",
      "  1.42255451e-03  8.58398777e-04             nan -2.59306836e-03\n",
      " -3.41797572e-03 -3.27404138e-05 -1.39365538e-02 -3.19395344e-03\n",
      " -3.28879658e-04  1.31509567e-03 -6.39378214e-03 -1.20769032e-03]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jampa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [-3.36326328e-03 -5.06921923e-03             nan -1.02818391e-01\n",
      "             nan -7.98957183e-04             nan -1.19948492e+02\n",
      " -1.76226671e-03 -1.13556481e-03             nan -2.87963672e-02\n",
      " -7.80109204e-04 -3.28433427e-03             nan -3.86680397e-02\n",
      "  1.65476212e-04  3.41594518e-05             nan -1.07589960e-02\n",
      " -1.20398244e-04 -1.44293628e-03             nan -5.55721984e-03\n",
      "  2.29594554e-03  1.05552743e-02             nan -3.30410993e-03\n",
      "  4.47019307e-03  9.26243336e-03 -1.49231844e-02 -2.27205454e-02\n",
      "  1.24265247e-03  8.57838904e-03 -4.80055250e-03 -1.86435040e-02\n",
      " -7.63446755e-04  1.33824394e-02 -9.39451362e-03 -1.46198174e-03\n",
      "  3.98053644e-03  8.27975653e-03 -4.09062207e-03 -1.27734784e-02\n",
      "  3.98708983e-03  9.11086784e-03  4.16356397e-03 -5.53838814e-03\n",
      " -5.83537445e-05  1.93722802e-03             nan -1.09229755e-03\n",
      "  5.78624537e-04  1.03674197e-03 -1.74207288e-02 -7.35254974e-03\n",
      " -3.74409736e-04 -3.12445785e-04 -2.17588091e-02 -4.83447732e-03\n",
      "  7.73795436e-03  3.49160723e-03             nan -2.35679901e-03\n",
      "  7.46828144e-03  2.66881878e-03 -1.37326661e-02 -2.45220914e-03\n",
      "  5.49994531e-03  2.71442631e-03 -6.99838702e-03 -1.53307312e-03]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0],\n",
    "    'hidden_layer_sizes': [(100), (10, 20), (10, 10)],\n",
    "    'activation': ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [1000],\n",
    "    'learning_rate_init': [0.01, 0.1],\n",
    "    'batch_size': [20, 50]\n",
    "}\n",
    "\n",
    "_model = MLPRegressor()\n",
    "my_mlp1 = GridSearchCV(_model, param_grid=parameters, return_train_score=True, cv=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(alpha=0, batch_size=50, hidden_layer_sizes=100,\n",
       "             learning_rate_init=0.01, max_iter=1000, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0, batch_size=50, hidden_layer_sizes=100,\n",
       "             learning_rate_init=0.01, max_iter=1000, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(alpha=0, batch_size=50, hidden_layer_sizes=100,\n",
       "             learning_rate_init=0.01, max_iter=1000, solver='sgd')"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0077242650822496595 0.0015158146622553659\n"
     ]
    }
   ],
   "source": [
    "mlp1_model=MLPRegressor(solver='sgd',alpha=0,hidden_layer_sizes=100,max_iter=1000,learning_rate_init=0.01,batch_size=50).fit(X_train,y_train)\n",
    "print(mlp1_model.score(X_train,y_train),mlp1_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.215098303279762\n",
      "8.243657825049366\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_train,mlp1_model.predict(X_train)))\n",
    "print(mean_squared_error(y_test,mlp1_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: A\n",
      "Data processed successfully for symbol: AAL\n",
      "Data processed successfully for symbol: AAPL\n",
      "Data processed successfully for symbol: ABBV\n",
      "Data processed successfully for symbol: ABNB\n",
      "Data processed successfully for symbol: ABT\n",
      "Data processed successfully for symbol: ACGL\n",
      "Data processed successfully for symbol: ACN\n",
      "Data processed successfully for symbol: ADBE\n",
      "Data processed successfully for symbol: ADI\n",
      "Data processed successfully for symbol: ADM\n",
      "Data processed successfully for symbol: ADP\n",
      "Data processed successfully for symbol: ADSK\n",
      "Data processed successfully for symbol: AEE\n",
      "Data processed successfully for symbol: AEP\n",
      "Data processed successfully for symbol: AES\n",
      "Data processed successfully for symbol: AFL\n",
      "Data processed successfully for symbol: AIG\n",
      "Data processed successfully for symbol: AIZ\n",
      "Data processed successfully for symbol: AJG\n",
      "Data processed successfully for symbol: AKAM\n",
      "Data processed successfully for symbol: ALB\n",
      "Data processed successfully for symbol: ALGN\n",
      "Data processed successfully for symbol: ALK\n",
      "Data processed successfully for symbol: ALL\n",
      "Data processed successfully for symbol: ALLE\n",
      "Data processed successfully for symbol: AMAT\n",
      "Data processed successfully for symbol: AMCR\n",
      "Data processed successfully for symbol: AMD\n",
      "Data processed successfully for symbol: AME\n",
      "Data processed successfully for symbol: AMGN\n",
      "Data processed successfully for symbol: AMP\n",
      "Data processed successfully for symbol: AMT\n",
      "Data processed successfully for symbol: AMZN\n",
      "Data processed successfully for symbol: ANET\n",
      "Data processed successfully for symbol: ANSS\n",
      "Data processed successfully for symbol: AON\n",
      "Data processed successfully for symbol: AOS\n",
      "Failed to fetch data for symbol: APA\n",
      "Data processed successfully for symbol: APD\n",
      "Data processed successfully for symbol: APH\n",
      "Data processed successfully for symbol: APTV\n",
      "Data processed successfully for symbol: ARE\n",
      "Data processed successfully for symbol: ATO\n",
      "Data processed successfully for symbol: AVB\n",
      "Data processed successfully for symbol: AVGO\n",
      "Data processed successfully for symbol: AVY\n",
      "Data processed successfully for symbol: AWK\n",
      "Data processed successfully for symbol: AXON\n",
      "Data processed successfully for symbol: AXP\n",
      "Data processed successfully for symbol: AZO\n",
      "Data processed successfully for symbol: BA\n",
      "Data processed successfully for symbol: BAC\n",
      "Data processed successfully for symbol: BALL\n",
      "Data processed successfully for symbol: BAX\n",
      "Data processed successfully for symbol: BBWI\n",
      "Data processed successfully for symbol: BBY\n",
      "Data processed successfully for symbol: BDX\n",
      "Data processed successfully for symbol: BEN\n",
      "Failed to fetch data for symbol: BG\n",
      "Data processed successfully for symbol: BIIB\n",
      "Data processed successfully for symbol: BIO\n",
      "Data processed successfully for symbol: BK\n",
      "Data processed successfully for symbol: BKNG\n",
      "Data processed successfully for symbol: BKR\n",
      "Data processed successfully for symbol: BLK\n",
      "Data processed successfully for symbol: BMY\n",
      "Data processed successfully for symbol: BR\n",
      "Data processed successfully for symbol: BRO\n",
      "Data processed successfully for symbol: BSX\n",
      "Data processed successfully for symbol: BWA\n",
      "Data processed successfully for symbol: BX\n",
      "Data processed successfully for symbol: BXP\n",
      "Data processed successfully for symbol: C\n",
      "Data processed successfully for symbol: CAG\n",
      "Data processed successfully for symbol: CAH\n",
      "Data processed successfully for symbol: CARR\n",
      "Data processed successfully for symbol: CAT\n",
      "Data processed successfully for symbol: CB\n",
      "Data processed successfully for symbol: CBOE\n",
      "Data processed successfully for symbol: CBRE\n",
      "Data processed successfully for symbol: CCI\n",
      "Data processed successfully for symbol: CCL\n",
      "Data processed successfully for symbol: CDAY\n",
      "Data processed successfully for symbol: CDNS\n",
      "Data processed successfully for symbol: CDW\n",
      "Data processed successfully for symbol: CE\n",
      "Data processed successfully for symbol: CF\n",
      "Data processed successfully for symbol: CFG\n",
      "Data processed successfully for symbol: CHD\n",
      "Data processed successfully for symbol: CHRW\n",
      "Data processed successfully for symbol: CHTR\n",
      "Failed to fetch data for symbol: CI\n",
      "Data processed successfully for symbol: CINF\n",
      "Data processed successfully for symbol: CL\n",
      "Data processed successfully for symbol: CLX\n",
      "Failed to fetch data for symbol: CMA\n",
      "Data processed successfully for symbol: CMCSA\n",
      "Data processed successfully for symbol: CME\n",
      "Data processed successfully for symbol: CMG\n",
      "Data processed successfully for symbol: CMI\n",
      "Data processed successfully for symbol: CMS\n",
      "Data processed successfully for symbol: CNC\n",
      "Data processed successfully for symbol: CNP\n",
      "Data processed successfully for symbol: COF\n",
      "Data processed successfully for symbol: COO\n",
      "Data processed successfully for symbol: COP\n",
      "Data processed successfully for symbol: COR\n",
      "Data processed successfully for symbol: COST\n",
      "Data processed successfully for symbol: CPB\n",
      "Data processed successfully for symbol: CPRT\n",
      "Data processed successfully for symbol: CPT\n",
      "Data processed successfully for symbol: CRL\n",
      "Data processed successfully for symbol: CRM\n",
      "Data processed successfully for symbol: CSCO\n",
      "Data processed successfully for symbol: CSGP\n",
      "Data processed successfully for symbol: CSX\n",
      "Data processed successfully for symbol: CTAS\n",
      "Data processed successfully for symbol: CTLT\n",
      "Data processed successfully for symbol: CTRA\n",
      "Data processed successfully for symbol: CTSH\n",
      "Data processed successfully for symbol: CTVA\n",
      "Data processed successfully for symbol: CVS\n",
      "Data processed successfully for symbol: CVX\n",
      "Data processed successfully for symbol: CZR\n",
      "Data processed successfully for symbol: D\n",
      "Data processed successfully for symbol: DAL\n",
      "Data processed successfully for symbol: DD\n",
      "Data processed successfully for symbol: DE\n",
      "Data processed successfully for symbol: DFS\n",
      "Data processed successfully for symbol: DG\n",
      "Data processed successfully for symbol: DGX\n",
      "Data processed successfully for symbol: DHI\n",
      "Data processed successfully for symbol: DHR\n",
      "Data processed successfully for symbol: DIS\n",
      "Data processed successfully for symbol: DLR\n",
      "Data processed successfully for symbol: DLTR\n",
      "Data processed successfully for symbol: DOV\n",
      "Data processed successfully for symbol: DOW\n",
      "Data processed successfully for symbol: DPZ\n",
      "Data processed successfully for symbol: DRI\n",
      "Data processed successfully for symbol: DTE\n",
      "Data processed successfully for symbol: DUK\n",
      "Data processed successfully for symbol: DVA\n",
      "Data processed successfully for symbol: DVN\n",
      "Data processed successfully for symbol: DXCM\n",
      "Data processed successfully for symbol: EA\n",
      "Data processed successfully for symbol: EBAY\n",
      "Data processed successfully for symbol: ECL\n",
      "Data processed successfully for symbol: ED\n",
      "Data processed successfully for symbol: EFX\n",
      "Data processed successfully for symbol: EG\n",
      "Data processed successfully for symbol: EIX\n",
      "Data processed successfully for symbol: EL\n",
      "Data processed successfully for symbol: ELV\n",
      "Data processed successfully for symbol: EMN\n",
      "Data processed successfully for symbol: EMR\n",
      "Data processed successfully for symbol: ENPH\n",
      "Data processed successfully for symbol: EOG\n",
      "Data processed successfully for symbol: EPAM\n",
      "Data processed successfully for symbol: EQIX\n",
      "Data processed successfully for symbol: EQR\n",
      "Data processed successfully for symbol: EQT\n",
      "Data processed successfully for symbol: ES\n",
      "Data processed successfully for symbol: ESS\n",
      "Data processed successfully for symbol: ETN\n",
      "Data processed successfully for symbol: ETR\n",
      "Data processed successfully for symbol: ETSY\n",
      "Data processed successfully for symbol: EVRG\n",
      "Data processed successfully for symbol: EW\n",
      "Data processed successfully for symbol: EXC\n",
      "Data processed successfully for symbol: EXPD\n",
      "Data processed successfully for symbol: EXPE\n",
      "Data processed successfully for symbol: EXR\n",
      "Data processed successfully for symbol: F\n",
      "Data processed successfully for symbol: FANG\n",
      "Data processed successfully for symbol: FAST\n",
      "Data processed successfully for symbol: FCX\n",
      "Data processed successfully for symbol: FDS\n",
      "Data processed successfully for symbol: FDX\n",
      "Data processed successfully for symbol: FE\n",
      "Data processed successfully for symbol: FFIV\n",
      "Data processed successfully for symbol: FI\n",
      "Data processed successfully for symbol: FICO\n",
      "Data processed successfully for symbol: FIS\n",
      "Data processed successfully for symbol: FITB\n",
      "Data processed successfully for symbol: FLT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: FMC\n",
      "Failed to fetch data for symbol: FOX\n",
      "Failed to fetch data for symbol: FOXA\n",
      "Data processed successfully for symbol: FRT\n",
      "Data processed successfully for symbol: FSLR\n",
      "Data processed successfully for symbol: FTNT\n",
      "Failed to fetch data for symbol: FTV\n",
      "Data processed successfully for symbol: GD\n",
      "Data processed successfully for symbol: GE\n",
      "Data processed successfully for symbol: GEN\n",
      "Data processed successfully for symbol: GILD\n",
      "Data processed successfully for symbol: GIS\n",
      "Data processed successfully for symbol: GL\n",
      "Data processed successfully for symbol: GLW\n",
      "Data processed successfully for symbol: GM\n",
      "Data processed successfully for symbol: GNRC\n",
      "Data processed successfully for symbol: GOOG\n",
      "Data processed successfully for symbol: GOOGL\n",
      "Data processed successfully for symbol: GPC\n",
      "Data processed successfully for symbol: GPN\n",
      "Data processed successfully for symbol: GRMN\n",
      "Data processed successfully for symbol: GS\n",
      "Data processed successfully for symbol: GWW\n",
      "Data processed successfully for symbol: HAL\n",
      "Data processed successfully for symbol: HAS\n",
      "Data processed successfully for symbol: HBAN\n",
      "Data processed successfully for symbol: HCA\n",
      "Data processed successfully for symbol: HD\n",
      "Data processed successfully for symbol: HES\n",
      "Data processed successfully for symbol: HIG\n",
      "Data processed successfully for symbol: HII\n",
      "Data processed successfully for symbol: HLT\n",
      "Data processed successfully for symbol: HOLX\n",
      "Data processed successfully for symbol: HON\n",
      "Data processed successfully for symbol: HPE\n",
      "Data processed successfully for symbol: HPQ\n",
      "Data processed successfully for symbol: HRL\n",
      "Data processed successfully for symbol: HSIC\n",
      "Data processed successfully for symbol: HST\n",
      "Data processed successfully for symbol: HSY\n",
      "Data processed successfully for symbol: HUBB\n",
      "Data processed successfully for symbol: HUM\n",
      "Data processed successfully for symbol: HWM\n",
      "Data processed successfully for symbol: IBM\n",
      "Data processed successfully for symbol: ICE\n",
      "Data processed successfully for symbol: IDXX\n",
      "Data processed successfully for symbol: IEX\n",
      "Data processed successfully for symbol: IFF\n",
      "Data processed successfully for symbol: ILMN\n",
      "Data processed successfully for symbol: INCY\n",
      "Data processed successfully for symbol: INTC\n",
      "Data processed successfully for symbol: INTU\n",
      "Data processed successfully for symbol: INVH\n",
      "Data processed successfully for symbol: IP\n",
      "Data processed successfully for symbol: IPG\n",
      "Data processed successfully for symbol: IQV\n",
      "Data processed successfully for symbol: IR\n",
      "Data processed successfully for symbol: IRM\n",
      "Data processed successfully for symbol: ISRG\n",
      "Data processed successfully for symbol: IT\n",
      "Failed to fetch data for symbol: ITW\n",
      "Data processed successfully for symbol: IVZ\n",
      "Data processed successfully for symbol: J\n",
      "Data processed successfully for symbol: JBHT\n",
      "Data processed successfully for symbol: JCI\n",
      "Data processed successfully for symbol: JKHY\n",
      "Data processed successfully for symbol: JNJ\n",
      "Data processed successfully for symbol: JNPR\n",
      "Data processed successfully for symbol: JPM\n",
      "Data processed successfully for symbol: K\n",
      "Data processed successfully for symbol: KDP\n",
      "Data processed successfully for symbol: KEY\n",
      "Failed to fetch data for symbol: KEYS\n",
      "Data processed successfully for symbol: KHC\n",
      "Data processed successfully for symbol: KIM\n",
      "Data processed successfully for symbol: KLAC\n",
      "Data processed successfully for symbol: KMB\n",
      "Data processed successfully for symbol: KMI\n",
      "Data processed successfully for symbol: KMX\n",
      "Data processed successfully for symbol: KO\n",
      "Data processed successfully for symbol: KR\n",
      "Data processed successfully for symbol: L\n",
      "Data processed successfully for symbol: LDOS\n",
      "Data processed successfully for symbol: LEN\n",
      "Data processed successfully for symbol: LH\n",
      "Data processed successfully for symbol: LHX\n",
      "Data processed successfully for symbol: LIN\n",
      "Data processed successfully for symbol: LKQ\n",
      "Data processed successfully for symbol: LLY\n",
      "Data processed successfully for symbol: LMT\n",
      "Data processed successfully for symbol: LNT\n",
      "Data processed successfully for symbol: LOW\n",
      "Data processed successfully for symbol: LRCX\n",
      "Data processed successfully for symbol: LULU\n",
      "Data processed successfully for symbol: LUV\n",
      "Data processed successfully for symbol: LVS\n",
      "Data processed successfully for symbol: LW\n",
      "Data processed successfully for symbol: LYB\n",
      "Data processed successfully for symbol: LYV\n",
      "Data processed successfully for symbol: MA\n",
      "Data processed successfully for symbol: MAA\n",
      "Data processed successfully for symbol: MAR\n",
      "Data processed successfully for symbol: MAS\n",
      "Data processed successfully for symbol: MCD\n",
      "Data processed successfully for symbol: MCHP\n",
      "Data processed successfully for symbol: MCK\n",
      "Data processed successfully for symbol: MCO\n",
      "Data processed successfully for symbol: MDLZ\n",
      "Data processed successfully for symbol: MDT\n",
      "Data processed successfully for symbol: MET\n",
      "Data processed successfully for symbol: META\n",
      "Data processed successfully for symbol: MGM\n",
      "Data processed successfully for symbol: MHK\n",
      "Data processed successfully for symbol: MKC\n",
      "Data processed successfully for symbol: MKTX\n",
      "Data processed successfully for symbol: MLM\n",
      "Data processed successfully for symbol: MMC\n",
      "Data processed successfully for symbol: MMM\n",
      "Failed to fetch data for symbol: MNST\n",
      "Data processed successfully for symbol: MO\n",
      "Data processed successfully for symbol: MOH\n",
      "Data processed successfully for symbol: MOS\n",
      "Data processed successfully for symbol: MPC\n",
      "Data processed successfully for symbol: MPWR\n",
      "Data processed successfully for symbol: MRK\n",
      "Data processed successfully for symbol: MRNA\n",
      "Data processed successfully for symbol: MRO\n",
      "Data processed successfully for symbol: MS\n",
      "Data processed successfully for symbol: MSCI\n",
      "Data processed successfully for symbol: MSFT\n",
      "Data processed successfully for symbol: MSI\n",
      "Data processed successfully for symbol: MTB\n",
      "Data processed successfully for symbol: MTCH\n",
      "Data processed successfully for symbol: MTD\n",
      "Data processed successfully for symbol: MU\n",
      "Data processed successfully for symbol: NCLH\n",
      "Data processed successfully for symbol: NDAQ\n",
      "Data processed successfully for symbol: NDSN\n",
      "Data processed successfully for symbol: NEE\n",
      "Data processed successfully for symbol: NEM\n",
      "Data processed successfully for symbol: NFLX\n",
      "Data processed successfully for symbol: NI\n",
      "Data processed successfully for symbol: NKE\n",
      "Data processed successfully for symbol: NOC\n",
      "Data processed successfully for symbol: NOW\n",
      "Data processed successfully for symbol: NRG\n",
      "Data processed successfully for symbol: NSC\n",
      "Data processed successfully for symbol: NTAP\n",
      "Data processed successfully for symbol: NTRS\n",
      "Data processed successfully for symbol: NUE\n",
      "Data processed successfully for symbol: NVDA\n",
      "Data processed successfully for symbol: NVR\n",
      "Data processed successfully for symbol: NWS\n",
      "Data processed successfully for symbol: NWSA\n",
      "Data processed successfully for symbol: NXPI\n",
      "Data processed successfully for symbol: O\n",
      "Data processed successfully for symbol: ODFL\n",
      "Data processed successfully for symbol: OKE\n",
      "Data processed successfully for symbol: OMC\n",
      "Data processed successfully for symbol: ON\n",
      "Data processed successfully for symbol: ORCL\n",
      "Data processed successfully for symbol: ORLY\n",
      "Data processed successfully for symbol: OTIS\n",
      "Data processed successfully for symbol: OXY\n",
      "Data processed successfully for symbol: PANW\n",
      "Data processed successfully for symbol: PARA\n",
      "Data processed successfully for symbol: PAYC\n",
      "Data processed successfully for symbol: PAYX\n",
      "Data processed successfully for symbol: PCAR\n",
      "Data processed successfully for symbol: PCG\n",
      "Data processed successfully for symbol: PEAK\n",
      "Data processed successfully for symbol: PEG\n",
      "Data processed successfully for symbol: PEP\n",
      "Data processed successfully for symbol: PFE\n",
      "Data processed successfully for symbol: PFG\n",
      "Data processed successfully for symbol: PG\n",
      "Data processed successfully for symbol: PGR\n",
      "Data processed successfully for symbol: PH\n",
      "Data processed successfully for symbol: PHM\n",
      "Data processed successfully for symbol: PKG\n",
      "Data processed successfully for symbol: PLD\n",
      "Data processed successfully for symbol: PM\n",
      "Data processed successfully for symbol: PNC\n",
      "Data processed successfully for symbol: PNR\n",
      "Data processed successfully for symbol: PNW\n",
      "Data processed successfully for symbol: PODD\n",
      "Data processed successfully for symbol: POOL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully for symbol: PPG\n",
      "Data processed successfully for symbol: PPL\n",
      "Data processed successfully for symbol: PRU\n",
      "Data processed successfully for symbol: PSA\n",
      "Data processed successfully for symbol: PSX\n",
      "Data processed successfully for symbol: PTC\n",
      "Data processed successfully for symbol: PWR\n",
      "Data processed successfully for symbol: PXD\n",
      "Data processed successfully for symbol: PYPL\n",
      "Data processed successfully for symbol: QCOM\n",
      "Data processed successfully for symbol: QRVO\n",
      "Data processed successfully for symbol: RCL\n",
      "Data processed successfully for symbol: REG\n",
      "Data processed successfully for symbol: REGN\n",
      "Data processed successfully for symbol: RF\n",
      "Data processed successfully for symbol: RHI\n",
      "Data processed successfully for symbol: RJF\n",
      "Data processed successfully for symbol: RL\n",
      "Data processed successfully for symbol: RMD\n",
      "Data processed successfully for symbol: ROK\n",
      "Data processed successfully for symbol: ROL\n",
      "Data processed successfully for symbol: ROP\n",
      "Data processed successfully for symbol: ROST\n",
      "Data processed successfully for symbol: RSG\n",
      "Data processed successfully for symbol: RTX\n",
      "Data processed successfully for symbol: RVTY\n",
      "Data processed successfully for symbol: SBAC\n",
      "Data processed successfully for symbol: SBUX\n",
      "Data processed successfully for symbol: SCHW\n",
      "Data processed successfully for symbol: SEDG\n",
      "Data processed successfully for symbol: SEE\n",
      "Data processed successfully for symbol: SHW\n",
      "Data processed successfully for symbol: SJM\n",
      "Data processed successfully for symbol: SLB\n",
      "Data processed successfully for symbol: SNA\n",
      "Data processed successfully for symbol: SNPS\n",
      "Data processed successfully for symbol: SO\n",
      "Failed to fetch data for symbol: SPG\n",
      "Data processed successfully for symbol: SPGI\n",
      "Data processed successfully for symbol: SRE\n",
      "Data processed successfully for symbol: STE\n",
      "Data processed successfully for symbol: STLD\n",
      "Data processed successfully for symbol: STT\n",
      "Data processed successfully for symbol: STX\n",
      "Data processed successfully for symbol: STZ\n",
      "Data processed successfully for symbol: SWK\n",
      "Data processed successfully for symbol: SWKS\n",
      "Data processed successfully for symbol: SYF\n",
      "Data processed successfully for symbol: SYK\n",
      "Data processed successfully for symbol: SYY\n",
      "Data processed successfully for symbol: T\n",
      "Data processed successfully for symbol: TAP\n",
      "Data processed successfully for symbol: TDG\n",
      "Data processed successfully for symbol: TDY\n",
      "Data processed successfully for symbol: TECH\n",
      "Data processed successfully for symbol: TEL\n",
      "Data processed successfully for symbol: TER\n",
      "Data processed successfully for symbol: TFC\n",
      "Data processed successfully for symbol: TFX\n",
      "Data processed successfully for symbol: TGT\n",
      "Data processed successfully for symbol: TJX\n",
      "Data processed successfully for symbol: TMO\n",
      "Data processed successfully for symbol: TMUS\n",
      "Data processed successfully for symbol: TPR\n",
      "Data processed successfully for symbol: TRGP\n",
      "Data processed successfully for symbol: TRMB\n",
      "Data processed successfully for symbol: TROW\n",
      "Data processed successfully for symbol: TRV\n",
      "Data processed successfully for symbol: TSCO\n",
      "Data processed successfully for symbol: TSLA\n",
      "Data processed successfully for symbol: TSN\n",
      "Data processed successfully for symbol: TT\n",
      "Data processed successfully for symbol: TTWO\n",
      "Data processed successfully for symbol: TXN\n",
      "Data processed successfully for symbol: TXT\n",
      "Data processed successfully for symbol: TYL\n",
      "Data processed successfully for symbol: UAL\n",
      "Data processed successfully for symbol: UDR\n",
      "Data processed successfully for symbol: UHS\n",
      "Data processed successfully for symbol: ULTA\n",
      "Data processed successfully for symbol: UNH\n",
      "Data processed successfully for symbol: UNP\n",
      "Data processed successfully for symbol: UPS\n",
      "Data processed successfully for symbol: URI\n",
      "Data processed successfully for symbol: USB\n",
      "Data processed successfully for symbol: V\n",
      "Data processed successfully for symbol: VFC\n",
      "Data processed successfully for symbol: VICI\n",
      "Data processed successfully for symbol: VLO\n",
      "Data processed successfully for symbol: VMC\n",
      "Data processed successfully for symbol: VRSK\n",
      "Data processed successfully for symbol: VRSN\n",
      "Data processed successfully for symbol: VRTX\n",
      "Data processed successfully for symbol: VTR\n",
      "Data processed successfully for symbol: VTRS\n",
      "Data processed successfully for symbol: VZ\n",
      "Data processed successfully for symbol: WAB\n",
      "Failed to fetch data for symbol: WAT\n",
      "Data processed successfully for symbol: WBA\n",
      "Data processed successfully for symbol: WBD\n",
      "Data processed successfully for symbol: WDC\n",
      "Data processed successfully for symbol: WEC\n",
      "Data processed successfully for symbol: WELL\n",
      "Data processed successfully for symbol: WFC\n",
      "Data processed successfully for symbol: WHR\n",
      "Data processed successfully for symbol: WM\n",
      "Data processed successfully for symbol: WMB\n",
      "Data processed successfully for symbol: WMT\n",
      "Data processed successfully for symbol: WRB\n",
      "Data processed successfully for symbol: WRK\n",
      "Data processed successfully for symbol: WST\n",
      "Data processed successfully for symbol: WTW\n",
      "Data processed successfully for symbol: WY\n",
      "Data processed successfully for symbol: WYNN\n",
      "Data processed successfully for symbol: XEL\n",
      "Data processed successfully for symbol: XOM\n",
      "Data processed successfully for symbol: XRAY\n",
      "Data processed successfully for symbol: XYL\n",
      "Data processed successfully for symbol: YUM\n",
      "Data processed successfully for symbol: ZBH\n",
      "Data processed successfully for symbol: ZBRA\n",
      "Data processed successfully for symbol: ZION\n",
      "Data processed successfully for symbol: ZTS\n",
      "Data concatenated successfully.\n",
      "             start         end         val                  accn      fy  fp  \\\n",
      "0       2015-11-01  2016-01-31   121000000  0001090872-17-000004  2017.0  Q1   \n",
      "1       2015-11-01  2016-04-30   212000000  0001090872-17-000008  2017.0  Q2   \n",
      "2       2016-02-01  2016-04-30    91000000  0001090872-17-000008  2017.0  Q2   \n",
      "3       2015-11-01  2016-07-31   336000000  0001090872-17-000013  2017.0  Q3   \n",
      "4       2016-05-01  2016-07-31   124000000  0001090872-17-000013  2017.0  Q3   \n",
      "...            ...         ...         ...                   ...     ...  ..   \n",
      "105410  2023-01-01  2023-03-31   552000000  0001555280-23-000150  2023.0  Q1   \n",
      "105411  2023-01-01  2023-06-30  1223000000  0001555280-23-000205  2023.0  Q2   \n",
      "105412  2023-04-01  2023-06-30   671000000  0001555280-23-000205  2023.0  Q2   \n",
      "105413  2023-01-01  2023-09-30  1819000000  0001555280-23-000247  2023.0  Q3   \n",
      "105414  2023-07-01  2023-09-30   596000000  0001555280-23-000247  2023.0  Q3   \n",
      "\n",
      "        form       filed     frame symbol  \n",
      "0       10-Q  2017-03-08  CY2015Q4      A  \n",
      "1       10-Q  2017-06-06       NaN      A  \n",
      "2       10-Q  2017-06-06  CY2016Q1      A  \n",
      "3       10-Q  2017-09-06       NaN      A  \n",
      "4       10-Q  2017-09-06  CY2016Q2      A  \n",
      "...      ...         ...       ...    ...  \n",
      "105410  10-Q  2023-05-04  CY2023Q1    ZTS  \n",
      "105411  10-Q  2023-08-08       NaN    ZTS  \n",
      "105412  10-Q  2023-08-08  CY2023Q2    ZTS  \n",
      "105413  10-Q  2023-11-02       NaN    ZTS  \n",
      "105414  10-Q  2023-11-02  CY2023Q3    ZTS  \n",
      "\n",
      "[105415 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3035898058.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_netIncome_data2['filed'] = pd.to_datetime(all_netIncome_data2['filed'])\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3035898058.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_netIncome_data2['year'] = all_netIncome_data2['filed'].dt.year\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3035898058.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_netIncome_data2['month'] = all_netIncome_data2['filed'].dt.month\n",
      "C:\\Users\\jampa\\AppData\\Local\\Temp\\ipykernel_14056\\3035898058.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_netIncome_data2['day']=all_netIncome_data2['filed'].dt.day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed successfully.\n",
      "       year  month  netIncome symbol\n",
      "0      2017      3  121000000      A\n",
      "1      2017      6   91000000      A\n",
      "2      2017      9  124000000      A\n",
      "3      2018      3  168000000      A\n",
      "4      2018      5  164000000      A\n",
      "...     ...    ...        ...    ...\n",
      "20353  2022      8  512000000    ZTS\n",
      "20354  2022     11  552000000    ZTS\n",
      "20355  2023      5  595000000    ZTS\n",
      "20356  2023      8  529000000    ZTS\n",
      "20357  2023     11  529000000    ZTS\n",
      "\n",
      "[20358 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>avrg_return_daily</th>\n",
       "      <th>std_return_daily</th>\n",
       "      <th>skew_return_daily</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>prev_price</th>\n",
       "      <th>return</th>\n",
       "      <th>next_month_return</th>\n",
       "      <th>cum_ret6</th>\n",
       "      <th>cum_ret12</th>\n",
       "      <th>asset</th>\n",
       "      <th>netIncome_x</th>\n",
       "      <th>netIncome_y</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>netIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>20.050072</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-1.057651</td>\n",
       "      <td>-0.369864</td>\n",
       "      <td>20.040653</td>\n",
       "      <td>-0.097844</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.550332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.795518</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>18.079800</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>24.599428</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>20.292213</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.235717</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>25.937054</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.484652</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>22.182100</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>0.465642</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>23.147352</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.345697</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>23.388283</td>\n",
       "      <td>-0.107557</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>7.574000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>20.336195</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>-0.678421</td>\n",
       "      <td>-0.237074</td>\n",
       "      <td>20.872721</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>19.978540</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>-0.095339</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>18.337812</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>-0.003568</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>19.291845</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>1.112051</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>18.015299</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>-0.142721</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>23.869814</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.547784</td>\n",
       "      <td>17.396082</td>\n",
       "      <td>0.237301</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>-0.029660</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>24.892704</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.983643</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>21.524183</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>25.050072</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>22.446566</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.210927</td>\n",
       "      <td>9.100000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>29.635193</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.632311</td>\n",
       "      <td>22.588463</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.333440</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-1.215774</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>26.723019</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.497673</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>30.100143</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.026238</td>\n",
       "      <td>-0.276730</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>26.981022</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>7.612000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.460000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>1.589836</td>\n",
       "      <td>0.115230</td>\n",
       "      <td>27.142279</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>35.701000</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.339112</td>\n",
       "      <td>28.883820</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>35.672390</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>32.192753</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.424044</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.705000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>36.559372</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>32.166958</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>0.797749</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>30.157368</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.284088</td>\n",
       "      <td>-0.456845</td>\n",
       "      <td>32.966778</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>26.373390</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.335696</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>27.193878</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.367075</td>\n",
       "      <td>8.649000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>22.353361</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.192555</td>\n",
       "      <td>23.781748</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>-0.302144</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>26.516453</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.130691</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>20.156755</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.065229</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2011-11-30</td>\n",
       "      <td>26.824034</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.365538</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>23.910744</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.070817</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>24.985695</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>-0.590230</td>\n",
       "      <td>-0.126739</td>\n",
       "      <td>24.188101</td>\n",
       "      <td>-0.068533</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>-0.316572</td>\n",
       "      <td>-0.156891</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>30.379112</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.251102</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>22.530416</td>\n",
       "      <td>0.215860</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>31.201717</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>1.193771</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>27.393835</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.036597</td>\n",
       "      <td>9.696000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>31.838341</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.210213</td>\n",
       "      <td>0.068673</td>\n",
       "      <td>28.135605</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>30.171675</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>-0.119917</td>\n",
       "      <td>28.774385</td>\n",
       "      <td>-0.052348</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>-0.152973</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>29.084406</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>-0.079841</td>\n",
       "      <td>27.268116</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>-0.182842</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.600000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>28.068670</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.052053</td>\n",
       "      <td>26.285479</td>\n",
       "      <td>-0.032359</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.228468</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>25.434919</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>26.580830</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-2.407801</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>24.819136</td>\n",
       "      <td>-0.029512</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.143907</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>9.413000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>27.503576</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>1.084984</td>\n",
       "      <td>0.142295</td>\n",
       "      <td>24.086683</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.131602</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>25.743919</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.854400</td>\n",
       "      <td>-0.229559</td>\n",
       "      <td>24.987616</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.142261</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>27.389128</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>23.388926</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>9.057000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>29.284693</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.109464</td>\n",
       "      <td>0.220724</td>\n",
       "      <td>24.883636</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>32.031475</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>26.671030</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.175410</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>29.670959</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>-1.208602</td>\n",
       "      <td>-0.233845</td>\n",
       "      <td>29.172663</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.121899</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.741000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>30.021460</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>27.022825</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>-0.047061</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>29.642345</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>27.420221</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>0.157554</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>32.510731</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.531282</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>27.073946</td>\n",
       "      <td>0.096767</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.193306</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.302000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>30.586552</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>-0.364063</td>\n",
       "      <td>-0.208150</td>\n",
       "      <td>29.693800</td>\n",
       "      <td>-0.056558</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>31.995708</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.191883</td>\n",
       "      <td>28.014383</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>33.361946</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>29.305031</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.351000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>36.659515</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.956637</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>30.556374</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.346833</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>36.309013</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.171295</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>33.654156</td>\n",
       "      <td>-0.009561</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>38.319027</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>3.178360</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>33.332394</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>1.027800e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.488000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>40.908440</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>1.008367</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>35.177631</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>41.595135</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>-0.237913</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>37.641235</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>0.306025</td>\n",
       "      <td>0.311951</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>37.470112</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>-2.053341</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>38.273094</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.017741</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.386610</td>\n",
       "      <td>1.053600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.397000e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  year  month       Date      Close  adj_close  avrg_return_daily  \\\n",
       "0       A  2010      1 2010-01-29  20.050072  18.079800          -0.005306   \n",
       "1       A  2010      2 2010-02-26  22.503576  20.292213           0.006162   \n",
       "2       A  2010      3 2010-03-31  24.599428  22.182100           0.003922   \n",
       "3       A  2010      4 2010-04-30  25.937054  23.388283           0.002628   \n",
       "4       A  2010      5 2010-05-28  23.147352  20.872721          -0.005176   \n",
       "5       A  2010      6 2010-06-30  20.336195  18.337812          -0.005598   \n",
       "6       A  2010      7 2010-07-30  19.978540  18.015299          -0.000649   \n",
       "7       A  2010      8 2010-08-31  19.291845  17.396082          -0.001236   \n",
       "8       A  2010      9 2010-09-30  23.869814  21.524183           0.010359   \n",
       "9       A  2010     10 2010-10-29  24.892704  22.446566           0.002081   \n",
       "10      A  2010     11 2010-11-30  25.050072  22.588463           0.000434   \n",
       "11      A  2010     12 2010-12-31  29.635193  26.723019           0.007740   \n",
       "12      A  2011      1 2011-01-31  29.921316  26.981022           0.000613   \n",
       "13      A  2011      2 2011-02-28  30.100143  27.142279           0.000641   \n",
       "14      A  2011      3 2011-03-31  32.031475  28.883820           0.003029   \n",
       "15      A  2011      4 2011-04-29  35.701000  32.192753           0.005564   \n",
       "16      A  2011      5 2011-05-31  35.672390  32.166958           0.000087   \n",
       "17      A  2011      6 2011-06-30  36.559372  32.966778           0.001298   \n",
       "18      A  2011      7 2011-07-29  30.157368  27.193878          -0.009376   \n",
       "19      A  2011      8 2011-08-31  26.373390  23.781748          -0.004521   \n",
       "20      A  2011      9 2011-09-30  22.353361  20.156755          -0.007177   \n",
       "21      A  2011     10 2011-10-31  26.516453  23.910744           0.009367   \n",
       "22      A  2011     11 2011-11-30  26.824034  24.188101           0.001094   \n",
       "23      A  2011     12 2011-12-30  24.985695  22.530416          -0.003089   \n",
       "24      A  2012      1 2012-01-31  30.379112  27.393835           0.010027   \n",
       "25      A  2012      2 2012-02-29  31.201717  28.135605           0.001451   \n",
       "26      A  2012      3 2012-03-30  31.838341  28.774385           0.001156   \n",
       "27      A  2012      4 2012-04-30  30.171675  27.268116          -0.002481   \n",
       "28      A  2012      5 2012-05-31  29.084406  26.285479          -0.001500   \n",
       "29      A  2012      6 2012-06-29  28.068670  25.434919          -0.001276   \n",
       "30      A  2012      7 2012-07-31  27.389128  24.819136          -0.001000   \n",
       "31      A  2012      8 2012-08-31  26.580830  24.086683          -0.001078   \n",
       "32      A  2012      9 2012-09-28  27.503576  24.987616           0.002030   \n",
       "33      A  2012     10 2012-10-31  25.743919  23.388926          -0.003058   \n",
       "34      A  2012     11 2012-11-30  27.389128  24.883636           0.003127   \n",
       "35      A  2012     12 2012-12-31  29.284693  26.671030           0.003600   \n",
       "36      A  2013      1 2013-01-31  32.031475  29.172663           0.004341   \n",
       "37      A  2013      2 2013-02-28  29.670959  27.022825          -0.003888   \n",
       "38      A  2013      3 2013-03-28  30.021460  27.420221           0.000789   \n",
       "39      A  2013      4 2013-04-30  29.642345  27.073946          -0.000415   \n",
       "40      A  2013      5 2013-05-31  32.510731  29.693800           0.004295   \n",
       "41      A  2013      6 2013-06-28  30.586552  28.014383          -0.002819   \n",
       "42      A  2013      7 2013-07-31  31.995708  29.305031           0.002107   \n",
       "43      A  2013      8 2013-08-30  33.361946  30.556374           0.001957   \n",
       "44      A  2013      9 2013-09-30  36.659515  33.654156           0.004900   \n",
       "45      A  2013     10 2013-10-31  36.309013  33.332394          -0.000339   \n",
       "46      A  2013     11 2013-11-29  38.319027  35.177631           0.002915   \n",
       "47      A  2013     12 2013-12-31  40.908440  37.641235           0.003282   \n",
       "48      A  2014      1 2014-01-31  41.595135  38.273094           0.000897   \n",
       "49      A  2014      2 2014-02-28  40.722462  37.470112          -0.000823   \n",
       "\n",
       "    std_return_daily  skew_return_daily    Sharpe  prev_price    return  \\\n",
       "0           0.014345          -1.057651 -0.369864   20.040653 -0.097844   \n",
       "1           0.012060           0.795518  0.511000   18.079800  0.122369   \n",
       "2           0.009486           0.943496  0.413428   20.292213  0.093134   \n",
       "3           0.014793           0.484652  0.177654   22.182100  0.054376   \n",
       "4           0.032369           0.345697 -0.159907   23.388283 -0.107557   \n",
       "5           0.023612          -0.678421 -0.237074   20.872721 -0.121446   \n",
       "6           0.020241          -0.095339 -0.032066   18.337812 -0.017587   \n",
       "7           0.027381           1.112051 -0.045157   18.015299 -0.034372   \n",
       "8           0.018911           0.418899  0.547784   17.396082  0.237301   \n",
       "9           0.013007          -0.983643  0.160000   21.524183  0.042853   \n",
       "10          0.016767          -0.075015  0.025889   22.446566  0.006322   \n",
       "11          0.012241           0.452720  0.632311   22.588463  0.183038   \n",
       "12          0.016586          -1.215774  0.036945   26.723019  0.009655   \n",
       "13          0.026238          -0.276730  0.024438   26.981022  0.005977   \n",
       "14          0.026290           1.589836  0.115230   27.142279  0.064163   \n",
       "15          0.016409           0.475558  0.339112   28.883820  0.114560   \n",
       "16          0.016232           0.514109  0.005342   32.192753 -0.000801   \n",
       "17          0.019456          -0.178554  0.066708   32.166958  0.024865   \n",
       "18          0.020524          -0.284088 -0.456845   32.966778 -0.175113   \n",
       "19          0.051500          -0.335696 -0.087794   27.193878 -0.125474   \n",
       "20          0.037274           0.010767 -0.192555   23.781748 -0.152428   \n",
       "21          0.050285          -0.130691  0.186272   20.156755  0.186240   \n",
       "22          0.033704          -0.365538  0.032471   23.910744  0.011600   \n",
       "23          0.024370          -0.590230 -0.126739   24.188101 -0.068533   \n",
       "24          0.020942          -0.251102  0.478816   22.530416  0.215860   \n",
       "25          0.015591           1.193771  0.093057   27.393835  0.027078   \n",
       "26          0.016830           0.210213  0.068673   28.135605  0.022704   \n",
       "27          0.020689           0.042492 -0.119917   28.774385 -0.052348   \n",
       "28          0.018784           0.819410 -0.079841   27.268116 -0.036036   \n",
       "29          0.024521          -0.432317 -0.052053   26.285479 -0.032359   \n",
       "30          0.018667           0.009255 -0.053582   25.434919 -0.024210   \n",
       "31          0.021243          -2.407801 -0.050759   24.819136 -0.029512   \n",
       "32          0.014265           1.084984  0.142295   24.086683  0.037404   \n",
       "33          0.013322          -0.854400 -0.229559   24.987616 -0.063979   \n",
       "34          0.019133           0.457169  0.163445   23.388926  0.063907   \n",
       "35          0.016311           0.109464  0.220724   24.883636  0.071830   \n",
       "36          0.011486           0.460151  0.377920   26.671030  0.093796   \n",
       "37          0.016625          -1.208602 -0.233845   29.172663 -0.073694   \n",
       "38          0.011159          -0.319110  0.070744   27.022825  0.014706   \n",
       "39          0.018418          -0.323141 -0.022526   27.420221 -0.012628   \n",
       "40          0.013600           0.531282  0.315799   27.073946  0.096767   \n",
       "41          0.013544          -0.364063 -0.208150   29.693800 -0.056558   \n",
       "42          0.010980          -0.043075  0.191883   28.014383  0.046071   \n",
       "43          0.010727           0.960212  0.182432   29.305031  0.042701   \n",
       "44          0.011294           0.956637  0.433843   30.556374  0.101379   \n",
       "45          0.012836           0.171295 -0.026400   33.654156 -0.009561   \n",
       "46          0.021835           3.178360  0.133483   33.332394  0.055359   \n",
       "47          0.010612           1.008367  0.309251   35.177631  0.070033   \n",
       "48          0.014740          -0.237913  0.060830   37.641235  0.016786   \n",
       "49          0.024464          -2.053341 -0.033623   38.273094 -0.020980   \n",
       "\n",
       "    next_month_return  cum_ret6  cum_ret12         asset  netIncome_x  \\\n",
       "0            0.122369  0.207149   0.550332           NaN          NaN   \n",
       "1            0.093134  0.225078   1.268206           NaN          NaN   \n",
       "2            0.054376  0.235717   1.237475  7.574000e+09          NaN   \n",
       "3           -0.107557  0.465642   0.985761  7.574000e+09          NaN   \n",
       "4           -0.121446  0.118949   0.775096  7.574000e+09          NaN   \n",
       "5           -0.017587 -0.084969   0.399803  7.612000e+09          NaN   \n",
       "6           -0.034372 -0.003568   0.202842  7.612000e+09          NaN   \n",
       "7            0.237301 -0.142721   0.050233  7.612000e+09          NaN   \n",
       "8            0.042853 -0.029660   0.199065  7.612000e+09          NaN   \n",
       "9            0.006322 -0.040264   0.406629  9.100000e+09          NaN   \n",
       "10           0.183038  0.082200   0.210927  9.100000e+09          NaN   \n",
       "11           0.009655  0.457263   0.333440  7.612000e+09          NaN   \n",
       "12           0.005977  0.497673   0.492330  7.612000e+09          NaN   \n",
       "13           0.064163  0.560252   0.337571  7.612000e+09          NaN   \n",
       "14           0.114560  0.341924   0.302123  9.696000e+09          NaN   \n",
       "15          -0.000801  0.434195   0.376448  9.696000e+09          NaN   \n",
       "16           0.024865  0.424044   0.541100  9.696000e+09          NaN   \n",
       "17          -0.175113  0.233647   0.797749  8.649000e+09          NaN   \n",
       "18          -0.125474  0.007889   0.509488  8.649000e+09          NaN   \n",
       "19          -0.152428 -0.123812   0.367075  8.649000e+09          NaN   \n",
       "20           0.186240 -0.302144  -0.063530  9.696000e+09          NaN   \n",
       "21           0.011600 -0.257263   0.065229  9.696000e+09          NaN   \n",
       "22          -0.068533 -0.248045   0.070817  9.696000e+09          NaN   \n",
       "23           0.215860 -0.316572  -0.156891  9.696000e+09          NaN   \n",
       "24           0.027078  0.007353   0.015300  9.696000e+09          NaN   \n",
       "25           0.022704  0.183076   0.036597  9.696000e+09          NaN   \n",
       "26          -0.052348  0.427531  -0.003789  9.057000e+09          NaN   \n",
       "27          -0.036036  0.140413  -0.152973  9.057000e+09          NaN   \n",
       "28          -0.032359  0.086711  -0.182842  9.057000e+09          NaN   \n",
       "29          -0.024210  0.128915  -0.228468  9.413000e+09          NaN   \n",
       "30          -0.029512 -0.093988  -0.087326  9.413000e+09          NaN   \n",
       "31           0.037404 -0.143907   0.012822  9.413000e+09          NaN   \n",
       "32          -0.063979 -0.131602   0.239665  9.057000e+09          NaN   \n",
       "33           0.063907 -0.142261  -0.021824  9.057000e+09          NaN   \n",
       "34           0.071830 -0.053331   0.028755  9.057000e+09          NaN   \n",
       "35           0.093796  0.048599   0.183779  1.053600e+10          NaN   \n",
       "36          -0.073694  0.175410   0.064935  1.053600e+10          NaN   \n",
       "37           0.014706  0.121899  -0.039551  1.053600e+10          NaN   \n",
       "38          -0.012628  0.097352  -0.047061  1.053600e+10          NaN   \n",
       "39           0.096767  0.157554  -0.007121  1.053600e+10          NaN   \n",
       "40          -0.056558  0.193306   0.129666  1.053600e+10          NaN   \n",
       "41           0.046071  0.050368   0.101414  1.053600e+10          NaN   \n",
       "42           0.042701  0.004537   0.180743  1.053600e+10          NaN   \n",
       "43           0.101379  0.130762   0.268600  1.053600e+10          NaN   \n",
       "44          -0.009561  0.227348   0.346833  1.027800e+10          NaN   \n",
       "45           0.055359  0.231161   0.425136  1.027800e+10          NaN   \n",
       "46           0.070033  0.184679   0.413685  1.027800e+10          NaN   \n",
       "47           0.016786  0.343640   0.411315  1.053600e+10          NaN   \n",
       "48          -0.020980  0.306025   0.311951  1.053600e+10          NaN   \n",
       "49          -0.017741  0.226262   0.386610  1.053600e+10          NaN   \n",
       "\n",
       "    netIncome_y   liabilities  netIncome  \n",
       "0           NaN           NaN        NaN  \n",
       "1           NaN           NaN        NaN  \n",
       "2           NaN  5.098000e+09        NaN  \n",
       "3           NaN  5.098000e+09        NaN  \n",
       "4           NaN  5.098000e+09        NaN  \n",
       "5           NaN  5.098000e+09        NaN  \n",
       "6           NaN  5.098000e+09        NaN  \n",
       "7           NaN  5.098000e+09        NaN  \n",
       "8           NaN  5.098000e+09        NaN  \n",
       "9           NaN  5.098000e+09        NaN  \n",
       "10          NaN  5.098000e+09        NaN  \n",
       "11          NaN  6.460000e+09        NaN  \n",
       "12          NaN  6.460000e+09        NaN  \n",
       "13          NaN  6.460000e+09        NaN  \n",
       "14          NaN  4.705000e+09        NaN  \n",
       "15          NaN  4.705000e+09        NaN  \n",
       "16          NaN  4.705000e+09        NaN  \n",
       "17          NaN  4.688000e+09        NaN  \n",
       "18          NaN  4.688000e+09        NaN  \n",
       "19          NaN  4.688000e+09        NaN  \n",
       "20          NaN  4.553000e+09        NaN  \n",
       "21          NaN  4.553000e+09        NaN  \n",
       "22          NaN  4.553000e+09        NaN  \n",
       "23          NaN  4.741000e+09        NaN  \n",
       "24          NaN  4.741000e+09        NaN  \n",
       "25          NaN  4.741000e+09        NaN  \n",
       "26          NaN  4.600000e+09        NaN  \n",
       "27          NaN  4.600000e+09        NaN  \n",
       "28          NaN  4.600000e+09        NaN  \n",
       "29          NaN  4.741000e+09        NaN  \n",
       "30          NaN  4.741000e+09        NaN  \n",
       "31          NaN  4.741000e+09        NaN  \n",
       "32          NaN  4.741000e+09        NaN  \n",
       "33          NaN  4.741000e+09        NaN  \n",
       "34          NaN  4.741000e+09        NaN  \n",
       "35          NaN  4.741000e+09        NaN  \n",
       "36          NaN  4.741000e+09        NaN  \n",
       "37          NaN  4.741000e+09        NaN  \n",
       "38          NaN  5.302000e+09        NaN  \n",
       "39          NaN  5.302000e+09        NaN  \n",
       "40          NaN  5.302000e+09        NaN  \n",
       "41          NaN  5.351000e+09        NaN  \n",
       "42          NaN  5.351000e+09        NaN  \n",
       "43          NaN  5.351000e+09        NaN  \n",
       "44          NaN  5.488000e+09        NaN  \n",
       "45          NaN  5.488000e+09        NaN  \n",
       "46          NaN  5.488000e+09        NaN  \n",
       "47          NaN  5.397000e+09        NaN  \n",
       "48          NaN  5.397000e+09        NaN  \n",
       "49          NaN  5.397000e+09        NaN  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "all_netIncome_data = pd.DataFrame()\n",
    "\n",
    "for symb in symbols:\n",
    "    _cik = companyData[companyData['ticker'] == symb]['cik_str10']\n",
    "    \n",
    "    # Check if CIK is available\n",
    "    if not _cik.empty:\n",
    "        cik = _cik.iloc[0]\n",
    "        \n",
    "        # Fetch company facts\n",
    "        companyFacts = requests.get(f'https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json', headers=headers)\n",
    "        \n",
    "        # Check if the request is successful and has the expected structure\n",
    "        if companyFacts.status_code == 200 and 'facts' in companyFacts.json().keys() and 'us-gaap' in companyFacts.json()['facts'].keys() and 'NetIncomeLoss' in companyFacts.json()['facts']['us-gaap'].keys():\n",
    "            \n",
    "            # Extract asset data and create DataFrame\n",
    "            income_data = companyFacts.json()['facts']['us-gaap']['NetIncomeLoss']['units']['USD']\n",
    "            income = pd.DataFrame.from_dict(income_data)\n",
    "            income['symbol'] = symb\n",
    "            \n",
    "            # Concatenate directly to the existing DataFrame\n",
    "            all_netIncome_data = pd.concat([all_netIncome_data, income], ignore_index=True)\n",
    "            \n",
    "            print(f\"Data processed successfully for symbol: {symb}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for symbol: {symb}\")\n",
    "    else:\n",
    "        print(f\"CIK not available for symbol: {symb}\")\n",
    "\n",
    "# Check if there is data\n",
    "if not all_netIncome_data.empty:\n",
    "    print(\"Data concatenated successfully.\")\n",
    "    # Further processing or analysis can be done with 'all_asset_data'\n",
    "else:\n",
    "    print(\"No data available.\")\n",
    "#######################\n",
    "print(all_netIncome_data)\n",
    "all_netIncome_data = all_netIncome_data.loc[all_netIncome_data['form'].isin(['10-K', '10-Q'])]\n",
    "all_netIncome_data['period'] = pd.to_datetime(all_netIncome_data['end']) - pd.to_datetime(all_netIncome_data['start'])\n",
    "all_netIncome_data2 = all_netIncome_data[all_netIncome_data['period'] <= pd.Timedelta(days=92)]\n",
    "all_netIncome_data2['filed'] = pd.to_datetime(all_netIncome_data2['filed'])\n",
    "all_netIncome_data2['year'] = all_netIncome_data2['filed'].dt.year\n",
    "all_netIncome_data2['month'] = all_netIncome_data2['filed'].dt.month\n",
    "all_netIncome_data2['day']=all_netIncome_data2['filed'].dt.day\n",
    "all_netIncome_data2 = all_netIncome_data2.groupby(['symbol','year', 'month']).first().reset_index()\n",
    "features = ['year', 'month', 'val', 'symbol']\n",
    "all_netIncome_data3 = all_netIncome_data2[features2].copy()\n",
    "all_netIncome_data3.rename(columns={'val': 'netIncome'}, inplace=True)\n",
    "\n",
    "print(\"Data processed successfully.\")\n",
    "print(all_netIncome_data3)\n",
    "##########################\n",
    "all_netIncome_data4 = all_netIncome_data3[(all_netIncome_data3['year'] >= 2010) & (all_netIncome_data3['year'] <= 2022)]\n",
    "\n",
    "final_data1 = pd.merge(final_data1, all_netIncome_data4, how='left', on=['symbol', 'year', 'month'])\n",
    "final_data2 = final_data1[(final_data1['year'] >= 2010) & (final_data1['year'] <= 2022)]\n",
    "\n",
    "# Reset the index to avoid alignment issues\n",
    "final_data2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_data2.ffill(inplace=True)\n",
    "final_data2.head(50)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
